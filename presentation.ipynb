{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop\n",
    "\n",
    "Introduction to Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI key from env\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_version = \"2024-06-01\"\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_embeddings = os.getenv(\"AZURE_OPENAI_EMBEDDINGS\")\n",
    "azure_whisper = os.getenv(\"AZURE_OPENAI_WHISPER\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_key = os.getenv(\"AZURE_OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create llm instance\n",
    "\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "\n",
    "## unser llm ohne frontend\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=azure_key,\n",
    "    api_version=azure_version,\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=azure_deployment,\n",
    "    azure_endpoint=azure_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Conferences are structured events where individuals with shared interests gather to discuss topics, share insights, present research, and network. They can vary widely in scale, format, and subject matter, encompassing fields such as business, technology, science, education, and the arts. Here are some key points about conferences:\\n\\n1. **Types of Conferences**:\\n   - **Academic Conferences**: Scholars and researchers present papers and discuss their findings. Examples include the American Association for the Advancement of Science (AAAS) Annual Meeting, and the Association for Computing Machinery (ACM) conferences.\\n   - **Business Conferences**: Focus on industry trends, networking, and professional development. Examples include the World Economic Forum and TED conferences.\\n   - **Technology Conferences**: Highlight innovations, product launches, and tech discussions. Examples include CES (Consumer Electronics Show) and Apple's WWDC (Worldwide Developers Conference).\\n   - **Professional Development Conferences**: Aim at skill-building and career advancement in specific professions.\\n   - **Trade Shows**: Combine conference sessions with exhibitions where companies showcase products and services.\\n\\n2. **Formats**:\\n   - **In-Person Conferences**: Traditional format where attendees gather at a physical location.\\n   - **Virtual Conferences**: Conducted online, allowing remote participation.\\n   - **Hybrid Conferences**: Combine both in-person and virtual elements to accommodate a broader audience.\\n\\n3. **Components of Conferences**:\\n   - **Keynote Speakers**: Renowned experts who deliver main talks.\\n   - **Panel Discussions**: Multiple experts discuss a topic, often with audience Q&A.\\n   - **Workshops**: Interactive sessions focused on skill-building.\\n   - **Poster Sessions**: Presenters display research posters and engage with attendees.\\n   - **Networking Sessions**: Opportunities for attendees to connect informally.\\n\\n4. **Benefits**:\\n   - **Knowledge Sharing**: Dissemination of the latest research, trends, and best practices.\\n   - **Networking**: Building professional relationships and collaborations.\\n   - **Professional Development**: Gaining new skills and insights.\\n   - **Exposure**: Presenting work to a wider audience and gaining recognition.\\n\\n5. **Planning and Logistics**:\\n   - **Venue Selection**: Choosing a location that suits the scale and needs of the event.\\n   - **Agenda Setting**: Developing a schedule that balances sessions, breaks, and networking opportunities.\\n   - **Speaker Coordination**: Inviting and managing speakers and their presentations.\\n   - **Marketing and Promotion**: Publicizing the event to attract attendees.\\n   - **Registration and Ticketing**: Managing participant sign-ups and payments.\\n\\n6. **Challenges**:\\n   - **Logistical Complexity**: Coordinating various aspects such as venue, technology, and catering.\\n   - **Engagement**: Keeping participants actively involved, especially in virtual settings.\\n   - **Technology Issues**: Ensuring reliable tech support for virtual and hybrid events.\\n   - **Cost Management**: Balancing budget constraints with the quality of the event.\\n\\nConferences play a crucial role in advancing knowledge, fostering collaboration, and driving innovation across various fields.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 630, 'prompt_tokens': 14, 'total_tokens': 644, 'completion_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_80a1bad4c7', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-09f1fdc3-e21a-4d4e-aea1-3e090382612d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 630, 'total_tokens': 644})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke llm\n",
    "\n",
    "llm.invoke(\"What do you know about Conferences?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are formal meetings or gatherings where individuals with shared interests, professions, or industries come together to discuss topics of mutual concern, share knowledge, network, and collaborate. They can vary widely in scope, size, and format, but generally, they serve several key purposes:\n",
      "\n",
      "1. **Knowledge Sharing**: Conferences provide a platform for presenting new research, innovations, and developments. Speakers, often experts in their fields, deliver presentations, workshops, and panels to disseminate information.\n",
      "\n",
      "2. **Networking**: Attendees have the opportunity to meet peers, mentors, potential collaborators, and industry leaders. Networking sessions, social events, and informal gatherings facilitate relationship-building.\n",
      "\n",
      "3. **Professional Development**: Many conferences offer training sessions, workshops, and continuing education opportunities to help attendees enhance their skills and stay current in their fields.\n",
      "\n",
      "4. **Industry Trends**: Conferences often highlight emerging trends, technologies, and challenges within an industry, offering insights into future directions and potential opportunities.\n",
      "\n",
      "5. **Exhibition and Sponsorship**: Many conferences include exhibition halls where companies and organizations can showcase their products, services, and innovations. Sponsorships can also provide visibility for brands and support the conference financially.\n",
      "\n",
      "6. **Recognition and Awards**: Conferences often include award ceremonies to recognize outstanding achievements, contributions, and innovations within a field.\n",
      "\n",
      "### Types of Conferences\n",
      "- **Academic Conferences**: Focused on scholarly research and are often organized by universities or academic societies. They typically include paper presentations, poster sessions, and roundtable discussions.\n",
      "- **Professional or Industry Conferences**: Geared towards professionals within a specific industry, such as technology, healthcare, finance, etc. They emphasize practical knowledge, networking, and industry trends.\n",
      "- **Trade Shows and Expos**: Large events that combine conference sessions with exhibition spaces where companies can display their products and services.\n",
      "- **Workshops and Seminars**: Smaller, more focused gatherings that offer in-depth training or exploration of specific topics.\n",
      "- **Virtual Conferences**: Held online, allowing participants to join remotely. They have become increasingly popular, especially in response to global events like the COVID-19 pandemic.\n",
      "\n",
      "### Planning and Organization\n",
      "Organizing a conference involves several key steps:\n",
      "1. **Defining Objectives**: Establishing the goals and purpose of the conference.\n",
      "2. **Selecting a Venue**: Choosing a location that can accommodate the expected number of attendees and the required facilities.\n",
      "3. **Programming**: Developing a schedule of events, selecting speakers, and planning sessions.\n",
      "4. **Marketing and Promotion**: Attracting attendees through various marketing channels, including social media, email campaigns, and partnerships.\n",
      "5. **Logistics**: Managing registrations, accommodations, transportation, and on-site services.\n",
      "6. **Evaluation**: Collecting feedback from attendees to assess the success of the conference and identify areas for improvement.\n",
      "\n",
      "Conferences can be a significant investment of time and resources but are considered valuable for personal and professional growth, industry advancement, and fostering collaboration and innovation.\n"
     ]
    }
   ],
   "source": [
    "# invoke llm\n",
    "\n",
    "# hier kann ich das llm auch direkt fragen\n",
    "answer = llm.invoke(\"What do you know about Conferences?\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are formal meetings or gatherings where individuals, often from a specific field or industry, come together to discuss particular topics, share research, exchange ideas, and network. They can vary widely in size, format, and purpose, and they often include presentations, panel discussions, workshops, and keynote speeches.\n",
      "\n",
      "Types of conferences include:\n",
      "\n",
      "1. **Academic Conferences**: These are typically organized by universities or academic organizations and focus on presenting and discussing research findings. Participants often include scholars, researchers, and students.\n",
      "\n",
      "2. **Professional or Industry Conferences**: These are organized by professional associations or industry groups and focus on topics relevant to a specific industry or profession. They often feature industry leaders, product demonstrations, and continuing education opportunities.\n",
      "\n",
      "3. **Business Conferences**: These are aimed at business professionals and may focus on topics such as management, leadership, marketing, or entrepreneurship. They often include networking sessions and opportunities for business development.\n",
      "\n",
      "4. **Technology Conferences**: These focus on technological advancements and innovations. Participants often include developers, engineers, and tech enthusiasts. Examples include CES (Consumer Electronics Show) and WWDC (Apple Worldwide Developers Conference).\n",
      "\n",
      "5. **Medical Conferences**: These bring together healthcare professionals to discuss the latest research, treatments, and best practices in medicine and healthcare.\n",
      "\n",
      "6. **International Conferences**: These involve participants from various countries and often focus on global issues or specific international collaborations.\n",
      "\n",
      "Conferences serve multiple purposes, including:\n",
      "- Dissemination of new knowledge and research.\n",
      "- Professional development and continuing education.\n",
      "- Networking and collaboration opportunities.\n",
      "- Discussion and debate on current issues and future trends.\n",
      "- Showcasing new products, technologies, or methodologies.\n",
      "\n",
      "Overall, conferences play a vital role in the professional and academic development of individuals and contribute to the advancement of knowledge and practice in various fields.\n"
     ]
    }
   ],
   "source": [
    "# use prompts\n",
    "\n",
    "# hier frage ich ein Prompttemplate ab\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"You are an encyclopedia.\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.invoke({\"input\": \"What are Conferences?\"})\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are also called conventions, symposiums, seminars, summits, forums, congresses, or meetings. Each term might have a slightly different connotation depending on the context and the specific nature of the gathering, but they all refer to assemblies of people who come together to discuss specific topics or issues.\n"
     ]
    }
   ],
   "source": [
    "# reusue prompts\n",
    "\n",
    "answer = chain.invoke({\"input\": \"What are Conferences also called?\"})\n",
    "print(answer.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are also called congresses, symposiums, workshops, or meetings.\n"
     ]
    }
   ],
   "source": [
    "# contexts\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What are Conferences also called?\",\n",
    "        \"context\": \"An academic conference or scientific conference (also congress, symposium, workshop, or meeting) is an event for researchers (not necessarily academics) to present and discuss their scholarly work. Together with academic or scientific journals and preprint archives, conferences provide an important channel for exchange of information between researchers. Further benefits of participating in academic conferences include learning effects in terms of presentation skills and 'academic habitus', receiving feedback from peers for one's own research, the possibility to engage in informal communication with peers about work opportunities and collaborations, and getting an overview of current research in one or more disciplines.\",\n",
    "    }\n",
    ")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are also called congresses, symposiums, workshops, or meetings.\n"
     ]
    }
   ],
   "source": [
    "# documents\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"An academic conference or scientific conference (also congress, symposium, workshop, or meeting) is an event for researchers (not necessarily academics) to present and discuss their scholarly work. Together with academic or scientific journals and preprint archives, conferences provide an important channel for exchange of information between researchers. Further benefits of participating in academic conferences include learning effects in terms of presentation skills and 'academic habitus', receiving feedback from peers for one's own research, the possibility to engage in informal communication with peers about work opportunities and collaborations, and getting an overview of current research in one or more disciplines.\",\n",
    "        metadata={\n",
    "            \"source\": \"wikipedia\"\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Die Data2Day ist eine Konferenz zum fachlichen Austausch zum Thema Data and AI.\",\n",
    "        metadata={\n",
    "            \"source\": \"Drenize\"\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "answer = document_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What are Conferences also called?\",\n",
    "        \"context\": documents,\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, Data2Day is a conference.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"Is Data2Day a conference?\", \n",
    "        \"context\": documents\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are also called congresses, symposiums, workshops, or meetings. The source is the provided context.\n"
     ]
    }
   ],
   "source": [
    "answer = document_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What are Conferences also called and what is the source?\",\n",
    "        \"context\": documents,\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conferences are also called congresses, symposiums, workshops, or meetings. The source for this information is Wikipedia.\n"
     ]
    }
   ],
   "source": [
    "# document prompts\n",
    "\n",
    "document_prompt = ChatPromptTemplate.from_template(\"\"\"Content: {page_content}                             \n",
    "Source: {source}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    document_prompt=document_prompt,\n",
    ")\n",
    "\n",
    "answer = document_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What are Conferences also called and what is the source?\",\n",
    "        \"context\": documents,\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conferences are events for researchers (not necessarily academics) to present and discuss their scholarly work. They provide an important channel for the exchange of information between researchers, offer benefits like learning presentation skills, receiving feedback, engaging in informal communication about work opportunities and collaborations, and getting an overview of current research in one or more disciplines. The source of this information is Wikipedia.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the meaning of conferences and what is the source?\",\n",
    "        \"context\": documents,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/The Managers Path.pdf', 'page': 1}, page_content='Praise\\tfor\\t\\nThe\\tManager’s\\tPath\\nThe\\tManager’s\\tPath\\n\\tgives\\tthe\\tbig\\tpicture\\tperspective\\ton\\twhat\\ta\\tcareer\\tin\\nengineering\\tmanagement\\tlooks\\tlike.\\tCamille\\tprovides\\tvery\\ttactical\\tadvice\\nfor\\teach\\tcareer\\tstage.\\tAnd\\tbecause\\tengineering\\tmanagers\\thave\\ta\\tgreat\\nresponsibility\\tto\\ttheir\\treports\\tto\\tlearn\\thow\\tto\\tmanage\\twell,\\tyou\\tshould\\tread\\nthis\\tbook\\tand\\tlearn\\thow\\tit\\tis\\tdone.\\nThis\\tbook\\tis\\ta\\tpractical\\tguide\\tto\\tunderstanding\\tand\\tpursuing\\ta\\tcareer\\tin\\nEngineering\\tManagement\\n.\\nLiz\\tCrawford,\\tEntrepreneur\\tin\\tResidence,\\tGenacast\\tVentures;\\t\\nformer\\tCTO,\\nBirchbox\\nAs\\tCamille\\tsays\\tin\\tChapter\\t5,\\t“This\\tbook\\tis\\tfor\\tengineering\\tmanagers.\\tIt’s\\nnot\\ta\\tgeneric\\tmanagement\\tbook.”\\tWithout\\thesitation\\tI\\trecommend\\tthis\\nbook\\tfor\\tliterally\\teveryone\\twho\\tworks\\tin\\tor\\taround\\tsoftware\\tengineering,\\nat\\twhatever\\tlevel,\\twhether\\tor\\tnot\\tyou\\tbelieve\\tmanagement\\tis\\tfor\\tyou.\\nIn\\tsoftware\\tengineering\\twe\\toften\\ttreat\\tmanagement\\tas\\tsomething\\tbetween\\na\\tfate\\tto\\tbe\\tavoided,\\tan\\tobstacle,\\tand\\ta\\treward\\tfor\\tbeing\\tthe\\tloudest\\tperson\\nin\\tthe\\troom.\\tIs\\tit\\ta\\tsurprise\\tthat\\tmost\\tof\\tus\\thave\\texperienced\\tpoor\\nmanagement\\tand\\twe\\tstruggle,\\tas\\tan\\tindustry,\\tto\\tbring\\tmanagers\\tup\\tto\\ta\\nlevel\\tslight\\tbetter\\tthan\\tworse-than-useless?\\tCamille’s\\tbook\\tteaches\\tus\\thow\\nto\\tclear\\tthis\\tbar\\tby\\ta\\tconsiderable\\tmargin.\\tShe\\tstarts\\tfrom\\twhere\\twe\\tall\\nstart,\\tas\\ta\\thuman\\twho\\tis\\tbeing\\tmanaged,\\tand\\tworks\\tupward\\tfrom\\tthat\\ncommon\\tground.\\tCamille\\tis\\tone\\tof\\tthe\\tgreat\\tengineering\\tleaders\\tin\\tour\\nindustry.\\tHer\\tadvice\\tis\\tboth\\tpractical\\tand\\tprofound.\\tWhile\\tI\\twish\\tI’d\\thad\\nthis\\tbook\\tearlier\\tin\\tmy\\tcareer,\\tI’m\\tgrateful\\tto\\thave\\tit\\tnow.\\nKellan\\tElliot-McCrea,\\tSVP\\tEngineering,\\tBlink\\tHealth;\\t\\nformer\\tCTO,\\tEtsy\\nI’ve\\tlearned\\tmore\\tfrom\\tCamille\\tabout\\tengineering\\tleadership\\tthan\\talmost\\nanyone.\\tHer\\twriting\\tis\\ta\\tfantastic\\thelp\\tto\\tboth\\tnew\\tand\\texperienced\\nmanagers,\\tthinking\\tthrough\\tnot\\tjust\\thow\\tto\\tget\\tthe\\tjob\\tdone,\\tbut\\thow\\tto\\nfind\\tthe\\tbest\\tapproach\\tfor\\tboth\\tthe\\tbusiness\\tand\\tthe\\tpeople.\\tThis\\twill\\tbe\\ta\\nbook\\tI\\t\\nrecommend\\n\\tto\\tall\\tmanagers\\tfor\\tyears\\tto\\tcome.\\nMarc\\tHedlund,\\tCEO,\\tSkyliner;\\t\\nformer\\tVP\\tEngineering\\tat\\tStripe\\tand\\tEtsy\\nOceanofPDF.com')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##from langchain_community.document_loaders import PyPDFLoader\n",
    "##\n",
    "##file_path = (\n",
    "##    \"/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/The Managers Path.pdf\"\n",
    "##)\n",
    "##loader = PyPDFLoader(file_path)\n",
    "##pages = loader.load_and_split()\n",
    "##\n",
    "##pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Tech Innovators Inc. Team Event Budget Application Guide\n",
      "\n",
      "1. Introduction Organizing team events is a great way to boost morale and foster collaboration. This guide will help you navigate the process of applying for a budget for your team event.\n",
      "\n",
      "2. Plan Your Event\n",
      "\n",
      "Define the Purpose: Clearly outline the purpose of the event (e.g., team building, training, celebration).\n",
      "Set Objectives: Identify the goals you aim to achieve with the event.\n",
      "Draft a Proposal: Prepare a detailed proposal including the event’s purpose, objectives, and expected outcomes.\n",
      "3. Estimate the Budget\n",
      "\n",
      "List Expenses: Itemize all potential expenses, such as venue rental, catering, transportation, materials, and any other costs.\n",
      "Get Quotes: Obtain quotes from vendors to ensure accurate budgeting.\n",
      "Create a Budget Plan: Summarize the total estimated cost and break it down into categories.\n",
      "4. Submit a Budget Request\n",
      "\n",
      "Step 1: Access the HR Portal\n",
      "Log in to the Tech Innovators HR portal using your employee credentials.\n",
      "Step 2: Navigate to the Budget Request Section\n",
      "Click on the “Budget Request” tab in the main menu.\n",
      "Step 3: Fill Out the Request Form\n",
      "Enter the details of your event, including the purpose, objectives, and date.\n",
      "Attach your detailed budget plan and any supporting documents (e.g., vendor quotes).\n",
      "Step 4: Submit the Request\n",
      "Click “Submit” to send your request to the HR and finance departments for approval.\n",
      "5. Review and Approval\n",
      "\n",
      "HR Review: The HR department will review your request to ensure it aligns with company policies and objectives.\n",
      "Finance Review: The finance department will review the budget to ensure it is reasonable and within the allocated funds.\n",
      "Approval Notification: You will receive an email notification once your request is approved or denied.\n",
      "6. Coordinate with HR and Finance\n",
      "\n",
      "Step 1: Follow Up with HR\n",
      "If needed, discuss any questions or concerns with the HR department.\n",
      "Email: hr@techinnovators.com\n",
      "Phone: (123) 456-7890\n",
      "Step 2: Coordinate with Finance\n",
      "Work with the finance department to finalize the budget and ensure funds are allocated.\n",
      "Email: finance@techinnovators.com\n",
      "Phone: (123) 456-7892\n",
      "7. Organize the Event\n",
      "\n",
      "Finalize Details: Confirm all arrangements with vendors and finalize the event schedule.\n",
      "Communicate with Team: Inform your team about the event details, including date, time, location, and any preparations needed.\n",
      "8. Post-Event Reporting\n",
      "\n",
      "Submit Receipts: After the event, submit all receipts and invoices to the finance department for reimbursement.\n",
      "Event Report: Prepare a brief report summarizing the event’s success, including feedback from participants and any lessons learned.\n",
      "9. Contact Information For any questions or assistance with the budget application process, please contact the HR department at hr@techinnovators.com or call (123) 456-7890.' metadata={'source': './Data/Internal/budget.txt'}\n",
      "------------------------\n",
      "page_content='Think Ba y es\n",
      "Ba y esian Statistics Made Simple\n",
      "V ersion 1.0.9' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 0}\n",
      "------------------------\n",
      "page_content='Think Ba y es\n",
      "Ba y esian Statistics Made Simple\n",
      "V ersion 1.0.9\n",
      "Allen B. Do wney\n",
      "Green T ea Press\n",
      "Needham, Massac h usetts' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 2}\n",
      "------------------------\n",
      "page_content='Cop yrigh t © 2012 Allen B. Do wney .\n",
      "Green T ea Press\n",
      "9 W ash burn A v e\n",
      "Needham MA 02492\n",
      "P ermission is gran ted to cop y , distribute, and/or mo dify this do cumen t under\n",
      "the terms of the Creativ e Commons A ttribution-NonCommercial-ShareAlik e\n",
      "4.0 In ternational License, whic h is a v ailable at http://creativecommons.\n",
      "org/licenses/by- nc- sa/4.0/ .\n",
      "The LA T E X source for this b o ok is a v ailable from http://greenteapress.com/\n",
      "thinkbayes .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 3}\n",
      "------------------------\n",
      "page_content='Preface\n",
      "0.1 My theory , whic h is mine\n",
      "The premise of this b o ok, and the other b o oks in the Think X series, is that\n",
      "if y ou kno w ho w to program, y ou can use that skill to learn other topics.\n",
      "Most b o oks on Ba y esian statistics use mathematical notation and presen t ideas\n",
      "in terms of mathematical concepts lik e calculus. This b o ok uses Python co de\n",
      "instead of math, and discrete appro ximations instead of con tin uous math-\n",
      "ematics. As a result, what w ould b e an in tegral in a math b o ok b ecomes a\n",
      "summation, and most op erations on probabilit y distributions are simple lo ops.\n",
      "I think this presen tation is easier to understand, at least for p eople with pro-\n",
      "gramming skills. It is also more general, b ecause when w e mak e mo deling\n",
      "decisions, w e can c ho ose the most appropriate mo del without w orrying to o\n",
      "m uc h ab out whether the mo del lends itself to con v en tional analysis.\n",
      "Also, it pro vides a smo oth dev elopmen t path from simple examples to real-\n",
      "w orld problems. Chapter 3 is a go o d example. It starts with a simple example\n",
      "in v olving dice, one of the staples of basic probabilit y . F rom there it pro ceeds\n",
      "in small steps to the lo comotiv e problem, whic h I b orro w ed from Mosteller's\n",
      "Fifty Chal lenging Pr oblems in Pr ob ability with Solutions , and from there to the\n",
      "German tank problem, a famously successful application of Ba y esian metho ds\n",
      "during W orld W ar I I.\n",
      "0.2 Mo deling and appro ximation\n",
      "Most c hapters in this b o ok are motiv ated b y a real-w orld problem, so they\n",
      "in v olv e some degree of mo deling. Before w e can apply Ba y esian metho ds (or\n",
      "an y other analysis), w e ha v e to mak e decisions ab out whic h parts of the real-\n",
      "w orld system to include in the mo del and whic h details w e can abstract a w a y .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 4}\n",
      "------------------------\n",
      "page_content='vi Chapter 0. Preface\n",
      "F or example, in Chapter 7, the motiv ating problem is to predict the winner of\n",
      "a ho c k ey game. I mo del goal-scoring as a P oisson pro cess, whic h implies that\n",
      "a goal is equally lik ely at an y p oin t in the game. That is not exactly true, but\n",
      "it is probably a go o d enough mo del for most purp oses.\n",
      "In Chapter 12 the motiv ating problem is in terpreting SA T scores (the SA T is\n",
      "a standardized test used for college admissions in the United States). I start\n",
      "with a simple mo del that assumes that all SA T questions are equally di\u001ecult,\n",
      "but in fact the designers of the SA T delib erately include some questions that\n",
      "are relativ ely easy and some that are relativ ely hard. I presen t a second mo del\n",
      "that accoun ts for this asp ect of the design, and sho w that it do esn't ha v e a\n",
      "big e\u001bect on the results after all.\n",
      "I think it is imp ortan t to include mo deling as an explicit part of problem\n",
      "solving b ecause it reminds us to think ab out mo deling errors (that is, errors\n",
      "due to simpli\u001ccations and assumptions of the mo del).\n",
      "Man y of the metho ds in this b o ok are based on discrete distributions, whic h\n",
      "mak es some p eople w orry ab out n umerical errors. But for real-w orld problems,\n",
      "n umerical errors are almost alw a ys smaller than mo deling errors.\n",
      "F urthermore, the discrete approac h often allo ws b etter mo deling decisions, and\n",
      "I w ould rather ha v e an appro ximate solution to a go o d mo del than an exact\n",
      "solution to a bad mo del.\n",
      "On the other hand, con tin uous metho ds sometimes yield p erformance\n",
      "adv an tages\u0016for example b y replacing a linear- or quadratic-time computa-\n",
      "tion with a constan t-time solution.\n",
      "So I recommend a general pro cess with these steps:\n",
      "1. While y ou are exploring a problem, start with simple mo dels and im-\n",
      "plemen t them in co de that is clear, readable, and demonstrably correct.\n",
      "F o cus y our atten tion on go o d mo deling decisions, not optimization.\n",
      "2. Once y ou ha v e a simple mo del w orking, iden tify the biggest sources of\n",
      "error. Y ou migh t need to increase the n um b er of v alues in a discrete\n",
      "appro ximation, or increase the n um b er of iterations in a Mon te Carlo\n",
      "sim ulation, or add details to the mo del.\n",
      "3. If the p erformance of y our solution is go o d enough for y our application,\n",
      "y ou migh t not ha v e to do an y optimization. But if y ou do, there are\n",
      "t w o approac hes to consider. Y ou can review y our co de and lo ok for\n",
      "optimizations; for example, if y ou cac he previously computed results\n",
      "y ou migh t b e able to a v oid redundan t computation. Or y ou can lo ok for\n",
      "analytic metho ds that yield computational shortcuts.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 5}\n",
      "------------------------\n",
      "page_content='0.3. W orking with the co de vii\n",
      "One b ene\u001ct of this pro cess is that Steps 1 and 2 tend to b e fast, so y ou can\n",
      "explore sev eral alternativ e mo dels b efore in v esting hea vily in an y of them.\n",
      "Another b ene\u001ct is that if y ou get to Step 3, y ou will b e starting with a reference\n",
      "implemen tation that is lik ely to b e correct, whic h y ou can use for regression\n",
      "testing (that is, c hec king that the optimized co de yields the same results, at\n",
      "least appro ximately).\n",
      "0.3 W orking with the co de\n",
      "The co de and sound samples used in this b o ok are a v ailable from https://\n",
      "github.com/AllenDowney/ThinkBayes . Git is a v ersion con trol system that\n",
      "allo ws y ou to k eep trac k of the \u001cles that mak e up a pro ject. A collection of\n",
      "\u001cles under Git's con trol is called a \u0010rep ository\u0011. GitHub is a hosting service\n",
      "that pro vides storage for Git rep ositories and a con v enien t w eb in terface.\n",
      "The GitHub homepage for m y rep ository pro vides sev eral w a ys to w ork with\n",
      "the co de:\n",
      " Y ou can create a cop y of m y rep ository on GitHub b y pressing the F o rk\n",
      "button. If y ou don't already ha v e a GitHub accoun t, y ou'll need to\n",
      "create one. After forking, y ou'll ha v e y our o wn rep ository on GitHub\n",
      "that y ou can use to k eep trac k of co de y ou write while w orking on this\n",
      "b o ok. Then y ou can clone the rep o, whic h means that y ou cop y the \u001cles\n",
      "to y our computer.\n",
      " Or y ou could clone m y rep ository . Y ou don't need a GitHub accoun t to\n",
      "do this, but y ou w on't b e able to write y our c hanges bac k to GitHub.\n",
      " If y ou don't w an t to use Git at all, y ou can do wnload the \u001cles in a Zip\n",
      "\u001cle using the button in the lo w er-righ t corner of the GitHub page.\n",
      "The co de for the \u001crst edition of the b o ok w orks with Python 2. If y ou are\n",
      "using Python 3, y ou migh t w an t to use the up dated co de in https://github.\n",
      "com/AllenDowney/ThinkBayes2 instead.\n",
      "I dev elop ed this b o ok using Anaconda from Con tin uum Analytics, whic h is a\n",
      "free Python distribution that includes all the pac k ages y ou'll need to run the\n",
      "co de (and lots more). I found Anaconda easy to install. By default it do es a\n",
      "user-lev el installation, not system-lev el, so y ou don't need administrativ e priv-\n",
      "ileges. Y ou can do wnload Anaconda from http://continuum.io/downloads .\n",
      "If y ou don't w an t to use Anaconda, y ou will need the follo wing pac k ages:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 6}\n",
      "------------------------\n",
      "page_content='viii Chapter 0. Preface\n",
      " NumPy for basic n umerical computation, http://www.numpy.org/ ;\n",
      " SciPy for scien ti\u001cc computation, http://www.scipy.org/ ;\n",
      " matplotlib for visualization, http://matplotlib.org/ .\n",
      "Although these are commonly used pac k ages, they are not included with all\n",
      "Python installations, and they can b e hard to install in some en vironmen ts. If\n",
      "y ou ha v e trouble installing them, I recommend using Anaconda or one of the\n",
      "other Python distributions that include these pac k ages.\n",
      "Man y of the examples in this b o ok use classes and functions de\u001cned in\n",
      "thinkbayes.py . Some of them also use thinkplot.py , whic h pro vides wrap-\n",
      "p ers for some of the functions in pyplot , whic h is part of matplotlib .\n",
      "0.4 Co de st yle\n",
      "Exp erienced Python programmers will notice that the co de in this b o ok do es\n",
      "not comply with PEP 8, whic h is the most common st yle guide for Python\n",
      "( http://www.python.org/dev/peps/pep- 0008/ ).\n",
      "Sp eci\u001ccally , PEP 8 calls for lo w ercase function names with underscores b e-\n",
      "t w een w ords, like_this . In this b o ok and the accompan ying co de, function\n",
      "and metho d names b egin with a capital letter and use camel case, LikeThis .\n",
      "I brok e this rule b ecause I dev elop ed some of the co de while I w as a Visiting\n",
      "Scien tist at Go ogle, so I follo w ed the Go ogle st yle guide, whic h deviates from\n",
      "PEP 8 in a few places. Once I got used to Go ogle st yle, I found that I lik ed\n",
      "it. And at this p oin t, it w ould b e to o m uc h trouble to c hange.\n",
      "Also on the topic of st yle, I write \u0010Ba y es's theorem\u0011 with an s after the ap os-\n",
      "trophe, whic h is preferred in some st yle guides and deprecated in others. I\n",
      "don't ha v e a strong preference. I had to c ho ose one, and this is the one I\n",
      "c hose.\n",
      "And \u001cnally one t yp ographical note: throughout the b o ok, I use PMF and CDF\n",
      "for the mathematical concept of a probabilit y mass function or cum ulativ e\n",
      "distribution function, and Pmf and Cdf to refer to the Python ob jects I use\n",
      "to represen t them.\n",
      "0.5 Prerequisites\n",
      "There are sev eral excellen t mo dules for doing Ba y esian statistics in Python,\n",
      "including pymc and Op enBUGS. I c hose not to use them for this b o ok b ecause' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 7}\n",
      "------------------------\n",
      "page_content='0.5. Prerequisites ix\n",
      "y ou need a fair amoun t of bac kground kno wledge to get started with these\n",
      "mo dules, and I w an t to k eep the prerequisites minimal. If y ou kno w Python\n",
      "and a little bit ab out probabilit y , y ou are ready to start this b o ok.\n",
      "Chapter 1 is ab out probabilit y and Ba y es's theorem; it has no co de. Chap-\n",
      "ter 2 in tro duces Pmf , a thinly disguised Python dictionary I use to represen t\n",
      "a probabilit y mass function (PMF). Then Chapter 3 in tro duces Suite , a kind\n",
      "of Pmf that pro vides a framew ork for doing Ba y esian up dates.\n",
      "In some of the later c hapters, I use analytic distributions including the Gaus-\n",
      "sian (normal) distribution, the exp onen tial and P oisson distributions, and the\n",
      "b eta distribution. In Chapter 15 I break out the less-common Diric hlet dis-\n",
      "tribution, but I explain it as I go along. If y ou are not familiar with these\n",
      "distributions, y ou can read ab out them on Wikip edia. Y ou could also read\n",
      "the companion to this b o ok, Think Stats , or an in tro ductory statistics b o ok\n",
      "(although I'm afraid most of them tak e a mathematical approac h that is not\n",
      "particularly helpful for practical purp oses).\n",
      "Con tributor List\n",
      "If y ou ha v e a suggestion or correction, please send email to\n",
      "downey@al lendowney.c om . If I mak e a c hange based on y our feedbac k,\n",
      "I will add y ou to the con tributor list (unless y ou ask to b e omitted).\n",
      "If y ou include at least part of the sen tence the error app ears in, that mak es it\n",
      "easy for me to searc h. P age and section n um b ers are \u001cne, to o, but not as easy\n",
      "to w ork with. Thanks!\n",
      " First, I ha v e to ac kno wledge Da vid MacKa y's excellen t b o ok, Information\n",
      "The ory, Infer enc e, and L e arning A lgorithms , whic h is where I \u001crst came to\n",
      "understand Ba y esian metho ds. With his p ermission, I use sev eral problems\n",
      "from his b o ok as examples.\n",
      " This b o ok also b ene\u001cted from m y in teractions with Sanjo y Maha jan, esp ecially\n",
      "in fall 2012, when I audited his class on Ba y esian Inference at Olin College.\n",
      " I wrote parts of this b o ok during pro ject nigh ts with the Boston Python User\n",
      "Group, so I w ould lik e to thank them for their compan y and pizza.\n",
      " Olivier Yiptong sen t sev eral helpful suggestions.\n",
      " Y uriy P asic hn yk found sev eral errors.\n",
      " Kristopher Ov erholt sen t a long list of corrections and suggestions.\n",
      " Max Hailp erin suggested a clari\u001ccation in Chapter 1.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 8}\n",
      "------------------------\n",
      "page_content='x Chapter 0. Preface\n",
      " Markus Dobler p oin ted out that dra wing co okies from a b o wl with replacemen t\n",
      "is an unrealistic scenario.\n",
      " In spring 2013, studen ts in m y class, Computational Ba y esian Statistics, made\n",
      "man y helpful corrections and suggestions: Kai Austin, Claire Barnes, Kari\n",
      "Bender, Rac hel Bo y , Kat Mendoza, Arjun Iy er, Ben Kro op, Nathan Lin tz,\n",
      "Kyle McConnaugha y , Alec Radford, Brendan Ritter, and Ev an Simpson.\n",
      " Greg Marra and Matt Aasted help ed me clarify the discussion of The Pric e is\n",
      "R ight problem.\n",
      " Marcus Ogren p oin ted out that the original statemen t of the lo comotiv e prob-\n",
      "lem w as am biguous.\n",
      " Jasmine K wit yn and Dan F auxsmith at O'Reilly Media pro ofread the b o ok\n",
      "and found man y opp ortunities for impro v emen t.\n",
      " Linda P escatore found a t yp o and made some helpful suggestions.\n",
      " T omasz Mi¡sk o sen t man y excellen t corrections and suggestions.\n",
      "Other p eople who sp otted t yp os and small errors include T om P ollard, P aul A.\n",
      "Giannaros, Jonathan Edw ards, George Purkins, Rob ert Marcus, Ram Lim bu, James\n",
      "La wry , Ben Kahle, Je\u001brey La w, and Alv aro Sanc hez.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 9}\n",
      "------------------------\n",
      "page_content='Contents\n",
      "Preface v\n",
      "0.1 My theory , whic h is mine . . . . . . . . . . . . . . . . . . . . v\n",
      "0.2 Mo deling and appro ximation . . . . . . . . . . . . . . . . . . v\n",
      "0.3 W orking with the co de . . . . . . . . . . . . . . . . . . . . . vii\n",
      "0.4 Co de st yle . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii\n",
      "0.5 Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . viii\n",
      "1 Ba y es's Theorem 1\n",
      "1.1 Conditional probabilit y . . . . . . . . . . . . . . . . . . . . . 1\n",
      "1.2 Conjoin t probabilit y . . . . . . . . . . . . . . . . . . . . . . . 2\n",
      "1.3 The co okie problem . . . . . . . . . . . . . . . . . . . . . . . 3\n",
      "1.4 Ba y es's theorem . . . . . . . . . . . . . . . . . . . . . . . . . 3\n",
      "1.5 The diac hronic in terpretation . . . . . . . . . . . . . . . . . 5\n",
      "1.6 The M&M problem . . . . . . . . . . . . . . . . . . . . . . . 6\n",
      "1.7 The Mon t y Hall problem . . . . . . . . . . . . . . . . . . . . 8\n",
      "1.8 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n",
      "2 Computational Statistics 11\n",
      "2.1 Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
      "2.2 The co okie problem . . . . . . . . . . . . . . . . . . . . . . . 12\n",
      "2.3 The Ba y esian framew ork . . . . . . . . . . . . . . . . . . . . 13' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 10}\n",
      "------------------------\n",
      "page_content='xii Con ten ts\n",
      "2.4 The Mon t y Hall problem . . . . . . . . . . . . . . . . . . . . 15\n",
      "2.5 Encapsulating the framew ork . . . . . . . . . . . . . . . . . . 16\n",
      "2.6 The M&M problem . . . . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n",
      "2.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n",
      "3 Estimation 21\n",
      "3.1 The dice problem . . . . . . . . . . . . . . . . . . . . . . . . 21\n",
      "3.2 The lo comotiv e problem . . . . . . . . . . . . . . . . . . . . 22\n",
      "3.3 What ab out that prior? . . . . . . . . . . . . . . . . . . . . . 25\n",
      "3.4 An alternativ e prior . . . . . . . . . . . . . . . . . . . . . . . 25\n",
      "3.5 Credible in terv als . . . . . . . . . . . . . . . . . . . . . . . . 27\n",
      "3.6 Cum ulativ e distribution functions . . . . . . . . . . . . . . . 28\n",
      "3.7 The German tank problem . . . . . . . . . . . . . . . . . . . 29\n",
      "3.8 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n",
      "3.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n",
      "4 More Estimation 33\n",
      "4.1 The Euro problem . . . . . . . . . . . . . . . . . . . . . . . . 33\n",
      "4.2 Summarizing the p osterior . . . . . . . . . . . . . . . . . . . 35\n",
      "4.3 Sw amping the priors . . . . . . . . . . . . . . . . . . . . . . 37\n",
      "4.4 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n",
      "4.5 The b eta distribution . . . . . . . . . . . . . . . . . . . . . . 39\n",
      "4.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
      "4.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 11}\n",
      "------------------------\n",
      "page_content='Con ten ts xiii\n",
      "5 Odds and A ddends 43\n",
      "5.1 Odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n",
      "5.2 The o dds form of Ba y es's theorem . . . . . . . . . . . . . . . 44\n",
      "5.3 Oliv er's blo o d . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n",
      "5.4 A ddends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n",
      "5.5 Maxima . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n",
      "5.6 Mixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n",
      "5.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n",
      "6 Decision Analysis 55\n",
      "6.1 The Pric e is R ight problem . . . . . . . . . . . . . . . . . . . 55\n",
      "6.2 The prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n",
      "6.3 Probabilit y densit y functions . . . . . . . . . . . . . . . . . . 57\n",
      "6.4 Represen ting PDF s . . . . . . . . . . . . . . . . . . . . . . . 57\n",
      "6.5 Mo deling the con testan ts . . . . . . . . . . . . . . . . . . . . 60\n",
      "6.6 Lik eliho o d . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n",
      "6.7 Up date . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n",
      "6.8 Optimal bidding . . . . . . . . . . . . . . . . . . . . . . . . . 64\n",
      "6.9 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n",
      "7 Prediction 69\n",
      "7.1 The Boston Bruins problem . . . . . . . . . . . . . . . . . . 69\n",
      "7.2 P oisson pro cesses . . . . . . . . . . . . . . . . . . . . . . . . 70\n",
      "7.3 The p osteriors . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n",
      "7.4 The distribution of goals . . . . . . . . . . . . . . . . . . . . 72\n",
      "7.5 The probabilit y of winning . . . . . . . . . . . . . . . . . . . 74\n",
      "7.6 Sudden death . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n",
      "7.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n",
      "7.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 12}\n",
      "------------------------\n",
      "page_content='xiv Con ten ts\n",
      "8 Observ er Bias 79\n",
      "8.1 The Red Line problem . . . . . . . . . . . . . . . . . . . . . 79\n",
      "8.2 The mo del . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\n",
      "8.3 W ait times . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n",
      "8.4 Predicting w ait times . . . . . . . . . . . . . . . . . . . . . . 84\n",
      "8.5 Estimating the arriv al rate . . . . . . . . . . . . . . . . . . . 86\n",
      "8.6 Incorp orating uncertain t y . . . . . . . . . . . . . . . . . . . . 89\n",
      "8.7 Decision analysis . . . . . . . . . . . . . . . . . . . . . . . . 90\n",
      "8.8 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n",
      "8.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n",
      "9 T w o Dimensions 95\n",
      "9.1 P ain tball . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n",
      "9.2 The suite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n",
      "9.3 T rigonometry . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n",
      "9.4 Lik eliho o d . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n",
      "9.5 Join t distributions . . . . . . . . . . . . . . . . . . . . . . . . 100\n",
      "9.6 Conditional distributions . . . . . . . . . . . . . . . . . . . . 100\n",
      "9.7 Credible in terv als . . . . . . . . . . . . . . . . . . . . . . . . 102\n",
      "9.8 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n",
      "9.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n",
      "10 Appro ximate Ba y esian Computation 107\n",
      "10.1 The V ariabilit y Hyp othesis . . . . . . . . . . . . . . . . . . . 107\n",
      "10.2 Mean and standard deviation . . . . . . . . . . . . . . . . . 108\n",
      "10.3 Up date . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n",
      "10.4 The p osterior distribution of CV . . . . . . . . . . . . . . . . 111\n",
      "10.5 Under\u001do w . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 13}\n",
      "------------------------\n",
      "page_content='Con ten ts xv\n",
      "10.6 Log-lik eliho o d . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n",
      "10.7 A little optimization . . . . . . . . . . . . . . . . . . . . . . 114\n",
      "10.8 ABC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\n",
      "10.9 Robust estimation . . . . . . . . . . . . . . . . . . . . . . . . 117\n",
      "10.10 Who is more v ariable? . . . . . . . . . . . . . . . . . . . . . 120\n",
      "10.11 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n",
      "10.12 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n",
      "11 Hyp othesis T esting 123\n",
      "11.1 Bac k to the Euro problem . . . . . . . . . . . . . . . . . . . 123\n",
      "11.2 Making a fair comparison . . . . . . . . . . . . . . . . . . . . 124\n",
      "11.3 The triangle prior . . . . . . . . . . . . . . . . . . . . . . . . 126\n",
      "11.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n",
      "11.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n",
      "12 Evidence 129\n",
      "12.1 In terpreting SA T scores . . . . . . . . . . . . . . . . . . . . . 129\n",
      "12.2 The scale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n",
      "12.3 The prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n",
      "12.4 P osterior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n",
      "12.5 A b etter mo del . . . . . . . . . . . . . . . . . . . . . . . . . 134\n",
      "12.6 Calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n",
      "12.7 P osterior distribution of e\u001ecacy . . . . . . . . . . . . . . . . 137\n",
      "12.8 Predictiv e distribution . . . . . . . . . . . . . . . . . . . . . 139\n",
      "12.9 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 14}\n",
      "------------------------\n",
      "page_content='xvi Con ten ts\n",
      "13 Sim ulation 143\n",
      "13.1 The Kidney T umor problem . . . . . . . . . . . . . . . . . . 143\n",
      "13.2 A simple mo del . . . . . . . . . . . . . . . . . . . . . . . . . 144\n",
      "13.3 A more general mo del . . . . . . . . . . . . . . . . . . . . . . 146\n",
      "13.4 Implemen tation . . . . . . . . . . . . . . . . . . . . . . . . . 148\n",
      "13.5 Cac hing the join t distribution . . . . . . . . . . . . . . . . . 149\n",
      "13.6 Conditional distributions . . . . . . . . . . . . . . . . . . . . 150\n",
      "13.7 Serial Correlation . . . . . . . . . . . . . . . . . . . . . . . . 151\n",
      "13.8 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\n",
      "14 A Hierarc hical Mo del 157\n",
      "14.1 The Geiger coun ter problem . . . . . . . . . . . . . . . . . . 157\n",
      "14.2 Start simple . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n",
      "14.3 Mak e it hierarc hical . . . . . . . . . . . . . . . . . . . . . . . 159\n",
      "14.4 A little optimization . . . . . . . . . . . . . . . . . . . . . . 160\n",
      "14.5 Extracting the p osteriors . . . . . . . . . . . . . . . . . . . . 161\n",
      "14.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\n",
      "14.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\n",
      "15 Dealing with Dimensions 165\n",
      "15.1 Belly button bacteria . . . . . . . . . . . . . . . . . . . . . . 165\n",
      "15.2 Lions and tigers and b ears . . . . . . . . . . . . . . . . . . . 166\n",
      "15.3 The hierarc hical v ersion . . . . . . . . . . . . . . . . . . . . . 168\n",
      "15.4 Random sampling . . . . . . . . . . . . . . . . . . . . . . . . 170\n",
      "15.5 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . 172\n",
      "15.6 Collapsing the hierarc h y . . . . . . . . . . . . . . . . . . . . 173\n",
      "15.7 One more problem . . . . . . . . . . . . . . . . . . . . . . . 175\n",
      "15.8 W e're not done y et . . . . . . . . . . . . . . . . . . . . . . . 177' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 15}\n",
      "------------------------\n",
      "page_content='Con ten ts xvii\n",
      "15.9 The b elly button data . . . . . . . . . . . . . . . . . . . . . 178\n",
      "15.10 Predictiv e distributions . . . . . . . . . . . . . . . . . . . . . 181\n",
      "15.11 Join t p osterior . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n",
      "15.12 Co v erage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\n",
      "15.13 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 16}\n",
      "------------------------\n",
      "page_content='xviii Con ten ts' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 17}\n",
      "------------------------\n",
      "page_content='Chapter 1\n",
      "Bayes's Theorem\n",
      "1.1 Conditional probabilit y\n",
      "The fundamen tal idea b ehind all Ba y esian statistics is Ba y es's theorem, whic h\n",
      "is surprisingly easy to deriv e, pro vided that y ou understand conditional proba-\n",
      "bilit y . So w e'll start with probabilit y , then conditional probabilit y , then Ba y es's\n",
      "theorem, and on to Ba y esian statistics.\n",
      "A probabilit y is a n um b er b et w een 0 and 1 (including b oth) that represen ts a\n",
      "degree of b elief in a fact or prediction. The v alue 1 represen ts certain t y that\n",
      "a fact is true, or that a prediction will come true. The v alue 0 represen ts\n",
      "certain t y that the fact is false.\n",
      "In termediate v alues represen t degrees of certain t y . The v alue 0.5, often written\n",
      "as 50%, means that a predicted outcome is as lik ely to happ en as not. F or\n",
      "example, the probabilit y that a tossed coin lands face up is v ery close to 50%.\n",
      "A conditional probabilit y is a probabilit y based on some bac kground informa-\n",
      "tion. F or example, I w an t to kno w the probabilit y that I will ha v e a heart at-\n",
      "tac k in the next y ear. A ccording to the CDC, \u0010Ev ery y ear ab out 785,000 Amer-\n",
      "icans ha v e a \u001crst coronary attac k. ( http://www.cdc.gov/heartdisease/\n",
      "facts.htm )\u0011\n",
      "The U.S. p opulation is ab out 311 million, so the probabilit y that a randomly\n",
      "c hosen American will ha v e a heart attac k in the next y ear is roughly 0.3%.\n",
      "But I am not a randomly c hosen American. Epidemiologists ha v e iden ti\u001ced\n",
      "man y factors that a\u001bect the risk of heart attac ks; dep ending on those factors,\n",
      "m y risk migh t b e higher or lo w er than a v erage.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 18}\n",
      "------------------------\n",
      "page_content='2 Chapter 1. Ba y es's Theorem\n",
      "I am male, 45 y ears old, and I ha v e b orderline high c holesterol. Those factors\n",
      "increase m y c hances. Ho w ev er, I ha v e lo w blo o d pressure and I don't smok e,\n",
      "and those factors decrease m y c hances.\n",
      "Plugging ev erything in to the online calculator at http://cvdrisk.nhlbi.\n",
      "nih.gov/calculator.asp , I \u001cnd that m y risk of a heart attac k in the next\n",
      "y ear is ab out 0.2%, less than the national a v erage. That v alue is a condi-\n",
      "tional probabilit y , b ecause it is based on a n um b er of factors that mak e up m y\n",
      "\u0010condition.\u0011\n",
      "The usual notation for conditional probabilit y is p(A|B) , whic h is the proba-\n",
      "bilit y ofA giv en thatB is true. In this example, A represen ts the prediction\n",
      "that I will ha v e a heart attac k in the next y ear, and B is the set of conditions\n",
      "I listed.\n",
      "1.2 Conjoin t probabilit y\n",
      "Conjoin t probabilit y is a fancy w a y to sa y the probabilit y that t w o things\n",
      "are true. I write p(AandB) to mean the probabilit y that A andB are b oth\n",
      "true.\n",
      "If y ou learned ab out probabilit y in the con text of coin tosses and dice, y ou\n",
      "migh t ha v e learned the follo wing form ula:\n",
      "p(AandB) = p(A) p(B) W ARNING: not alw a ys true\n",
      "F or example, if I toss t w o coins, and A means the \u001crst coin lands face up, and\n",
      "B means the second coin lands face up, then p(A) = p(B) = 0.5 , and sure\n",
      "enough, p(AandB) = p(A) p(B) = 0.25 .\n",
      "But this form ula only w orks b ecause in this case A andB are indep enden t;\n",
      "that is, kno wing the outcome of the \u001crst ev en t do es not c hange the probabilit y\n",
      "of the second. Or, more formally , p(B|A) =p(B) .\n",
      "Here is a di\u001beren t example where the ev en ts are not indep enden t. Supp ose\n",
      "thatA means that it rains to da y and B means that it rains tomorro w. If\n",
      "I kno w that it rained to da y , it is more lik ely that it will rain tomorro w, so\n",
      "p(B|A)>p(B) .\n",
      "In general, the probabilit y of a conjunction is\n",
      "p(AandB) = p(A) p(B|A)\n",
      "for an yA andB . So if the c hance of rain on an y giv en da y is 0.5, the c hance\n",
      "of rain on t w o consecutiv e da ys is not 0.25, but probably a bit higher.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 19}\n",
      "------------------------\n",
      "page_content='1.3. The co okie problem 3\n",
      "1.3 The co okie problem\n",
      "W e'll get to Ba y es's theorem so on, but I w an t to motiv ate it with an example\n",
      "called the co okie problem.1Supp ose there are t w o b o wls of co okies. Bo wl 1\n",
      "con tains 30 v anilla co okies and 10 c ho colate co okies. Bo wl 2 con tains 20 of\n",
      "eac h.\n",
      "No w supp ose y ou c ho ose one of the b o wls at random and, without lo oking,\n",
      "select a co okie at random. The co okie is v anilla. What is the probabilit y that\n",
      "it came from Bo wl 1?\n",
      "This is a conditional probabilit y; w e w an t p( Bo wl 1| v anilla ) , but it is not\n",
      "ob vious ho w to compute it. If I ask ed a di\u001beren t question\u0016the probabilit y of\n",
      "a v anilla co okie giv en Bo wl 1\u0016it w ould b e easy:\n",
      "p( v anilla| Bo wl 1 ) = 3/4\n",
      "Sadly , p(A|B) is not the same as p(B|A) , but there is a w a y to get from one\n",
      "to the other: Ba y es's theorem.\n",
      "1.4 Ba y es's theorem\n",
      "A t this p oin t w e ha v e ev erything w e need to deriv e Ba y es's theorem. W e'll\n",
      "start with the observ ation that conjunction is comm utativ e; that is\n",
      "p(AandB) = p(BandA)\n",
      "for an y ev en ts A andB .\n",
      "Next, w e write the probabilit y of a conjunction:\n",
      "p(AandB) = p(A) p(B|A)\n",
      "Since w e ha v e not said an ything ab out what A andB mean, they are in ter-\n",
      "c hangeable. In terc hanging them yields\n",
      "p(BandA) = p(B) p(A|B)\n",
      "That's all w e need. Pulling those pieces together, w e get\n",
      "p(B) p(A|B) = p(A) p(B|A)\n",
      "1Based on an example from http://en.wikipedia.org/wiki/Bayes' _theorem that is\n",
      "no longer there.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 20}\n",
      "------------------------\n",
      "page_content='4 Chapter 1. Ba y es's Theorem\n",
      "Whic h means there are t w o w a ys to compute the conjunction. If y ou ha v e\n",
      "p(A) , y ou m ultiply b y the conditional probabilit y p(B|A) . Or y ou can do it\n",
      "the other w a y around; if y ou kno w p(B) , y ou m ultiply b y p(A|B) . Either w a y\n",
      "y ou should get the same thing.\n",
      "Finally w e can divide through b y p(B) :\n",
      "p(A|B) =p(A) p(B|A)\n",
      "p(B)\n",
      "And that's Ba y es's theorem! It migh t not lo ok lik e m uc h, but it turns out to\n",
      "b e surprisingly p o w erful.\n",
      "F or example, w e can use it to solv e the co okie problem. I'll write B1 for the\n",
      "h yp othesis that the co okie came from Bo wl 1 and V for the v anilla co okie.\n",
      "Plugging in Ba y es's theorem w e get\n",
      "p(B1|V) =p(B1) p(V|B1)\n",
      "p(V)\n",
      "The term on the left is what w e w an t: the probabilit y of Bo wl 1, giv en that\n",
      "w e c hose a v anilla co okie. The terms on the righ t are:\n",
      "p(B1) : This is the probabilit y that w e c hose Bo wl 1, unconditioned b y\n",
      "what kind of co okie w e got. Since the problem sa ys w e c hose a b o wl at\n",
      "random, w e can assume p(B1) = 1/2 .\n",
      "p(V|B1) : This is the probabilit y of getting a v anilla co okie from Bo wl 1,\n",
      "whic h is 3/4.\n",
      "p(V) : This is the probabilit y of dra wing a v anilla co okie from either\n",
      "b o wl. Since w e had an equal c hance of c ho osing either b o wl and the\n",
      "b o wls con tain the same n um b er of co okies, w e had the same c hance of\n",
      "c ho osing an y co okie. Bet w een the t w o b o wls there are 50 v anilla and 30\n",
      "c ho colate co okies, so p(V) = 5/8.\n",
      "Putting it together, w e ha v e\n",
      "p(B1|V) =(1/2) (3/4)\n",
      "5/8\n",
      "whic h reduces to 3/5. So the v anilla co okie is evidence in fa v or of the h yp othe-\n",
      "sis that w e c hose Bo wl 1, b ecause v anilla co okies are more lik ely to come from\n",
      "Bo wl 1.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 21}\n",
      "------------------------\n",
      "page_content='1.5. The diac hronic in terpretation 5\n",
      "This example demonstrates one use of Ba y es's theorem: it pro vides a strategy\n",
      "to get from p(B|A) top(A|B) . This strategy is useful in cases, lik e the co okie\n",
      "problem, where it is easier to compute the terms on the righ t side of Ba y es's\n",
      "theorem than the term on the left.\n",
      "1.5 The diac hronic in terpretation\n",
      "There is another w a y to think of Ba y es's theorem: it giv es us a w a y to up date\n",
      "the probabilit y of a h yp othesis, H , in ligh t of some b o dy of data, D .\n",
      "This w a y of thinking ab out Ba y es's theorem is called the diac hronic in ter-\n",
      "pretation . \u0010Diac hronic\u0011 means that something is happ ening o v er time; in this\n",
      "case the probabilit y of the h yp otheses c hanges, o v er time, as w e see new data.\n",
      "Rewriting Ba y es's theorem with H andD yields:\n",
      "p(H|D) =p(H) p(D|H)\n",
      "p(D)\n",
      "In this in terpretation, eac h term has a name:\n",
      "p(H) is the probabilit y of the h yp othesis b efore w e see the data, called\n",
      "the prior probabilit y , or just prior .\n",
      "p(H|D) is what w e w an t to compute, the probabilit y of the h yp othesis\n",
      "after w e see the data, called the p osterior .\n",
      "p(D|H) is the probabilit y of the data under the h yp othesis, called the\n",
      "lik eliho o d .\n",
      "p(D) is the probabilit y of the data under an y h yp othesis, called the\n",
      "normalizing constan t .\n",
      "Sometimes w e can compute the prior based on bac kground information. F or\n",
      "example, the co okie problem sp eci\u001ces that w e c ho ose a b o wl at random with\n",
      "equal probabilit y .\n",
      "In other cases the prior is sub jectiv e; that is, reasonable p eople migh t dis-\n",
      "agree, either b ecause they use di\u001beren t bac kground information or b ecause\n",
      "they in terpret the same information di\u001beren tly .\n",
      "The lik eliho o d is usually the easiest part to compute. In the co okie problem, if\n",
      "w e kno w whic h b o wl the co okie came from, w e \u001cnd the probabilit y of a v anilla\n",
      "co okie b y coun ting.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 22}\n",
      "------------------------\n",
      "page_content='6 Chapter 1. Ba y es's Theorem\n",
      "The normalizing constan t can b e tric ky . It is supp osed to b e the probabilit y\n",
      "of seeing the data under an y h yp othesis at all, but in the most general case it\n",
      "is hard to nail do wn what that means.\n",
      "Most often w e simplify things b y sp ecifying a set of h yp otheses that are\n",
      "Mutually exclusiv e: A t most one h yp othesis in the set can b e true, and\n",
      "Collectiv ely exhaustiv e: There are no other p ossibilities; at least one of the\n",
      "h yp otheses has to b e true.\n",
      "I use the w ord suite for a set of h yp otheses that has these prop erties.\n",
      "In the co okie problem, there are only t w o h yp otheses\u0016the co okie came from\n",
      "Bo wl 1 or Bo wl 2\u0016and they are m utually exclusiv e and collectiv ely exhaustiv e.\n",
      "In that case w e can compute p(D) using the la w of total probabilit y , whic h\n",
      "sa ys that if there are t w o exclusiv e w a ys that something migh t happ en, y ou\n",
      "can add up the probabilities lik e this:\n",
      "p(D) = p(B1) p(D|B1) + p(B2) p(D|B2)\n",
      "Plugging in the v alues from the co okie problem, w e ha v e\n",
      "p(D) = (1/2) (3/4) + (1/2) (1/2) = 5/8\n",
      "whic h is what w e computed earlier b y men tally com bining the t w o b o wls.\n",
      "1.6 The M&M problem\n",
      "M&M's are small candy-coated c ho colates that come in a v ariet y of colors.\n",
      "Mars, Inc., whic h mak es M&M's, c hanges the mixture of colors from time to\n",
      "time.\n",
      "In 1995, they in tro duced blue M&M's. Before then, the color mix in a bag\n",
      "of plain M&M's w as 30% Bro wn, 20% Y ello w, 20% Red, 10% Green, 10%\n",
      "Orange, 10% T an. Afterw ard it w as 24% Blue , 20% Green, 16% Orange, 14%\n",
      "Y ello w, 13% Red, 13% Bro wn.\n",
      "Supp ose a friend of mine has t w o bags of M&M's, and he tells me that one is\n",
      "from 1994 and one from 1996. He w on't tell me whic h is whic h, but he giv es\n",
      "me one M&M from eac h bag. One is y ello w and one is green. What is the\n",
      "probabilit y that the y ello w one came from the 1994 bag?' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 23}\n",
      "------------------------\n",
      "page_content='1.6. The M&M problem 7\n",
      "This problem is similar to the co okie problem, with the t wist that I dra w\n",
      "one sample from eac h b o wl/bag. This problem also giv es me a c hance to\n",
      "demonstrate the table metho d, whic h is useful for solving problems lik e this\n",
      "on pap er. In the next c hapter w e will solv e them computationally .\n",
      "The \u001crst step is to en umerate the h yp otheses. The bag the y ello w M&M came\n",
      "from I'll call Bag 1; I'll call the other Bag 2. So the h yp otheses are:\n",
      " A: Bag 1 is from 1994, whic h implies that Bag 2 is from 1996.\n",
      " B: Bag 1 is from 1996 and Bag 2 from 1994.\n",
      "No w w e construct a table with a ro w for eac h h yp othesis and a column for\n",
      "eac h term in Ba y es's theorem:\n",
      "Prior Lik eliho o d P osterior\n",
      "p(H)p(D|H)p(H) p(D|H)p(H|D)\n",
      "A 1/2 (20)(20) 200 20/27\n",
      "B 1/2 (14)(10) 70 7/27\n",
      "The \u001crst column has the priors. Based on the statemen t of the problem, it is\n",
      "reasonable to c ho ose p(A) = p(B) = 1/2 .\n",
      "The second column has the lik eliho o ds, whic h follo w from the information\n",
      "in the problem. F or example, if A is true, the y ello w M&M came from the\n",
      "1994 bag with probabilit y 20%, and the green came from the 1996 bag with\n",
      "probabilit y 20%. If B is true, the y ello w M&M came from the 1996 bag with\n",
      "probabilit y 14%, and the green came from the 1994 bag with probabilit y 10%.\n",
      "Because the selections are indep enden t, w e get the conjoin t probabilit y b y\n",
      "m ultiplying.\n",
      "The third column is just the pro duct of the previous t w o. The sum of this col-\n",
      "umn, 270, is the normalizing constan t. T o get the last column, whic h con tains\n",
      "the p osteriors, w e divide the third column b y the normalizing constan t.\n",
      "That's it. Simple, righ t?\n",
      "W ell, y ou migh t b e b othered b y one detail. I write p(D|H) in terms of p er-\n",
      "cen tages, not probabilities, whic h means it is o\u001b b y a factor of 10,000. But\n",
      "that cancels out when w e divide through b y the normalizing constan t, so it\n",
      "do esn't a\u001bect the result.\n",
      "When the set of h yp otheses is m utually exclusiv e and collectiv ely exhaustiv e,\n",
      "y ou can m ultiply the lik eliho o ds b y an y factor, if it is con v enien t, as long as\n",
      "y ou apply the same factor to the en tire column.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 24}\n",
      "------------------------\n",
      "page_content='8 Chapter 1. Ba y es's Theorem\n",
      "1.7 The Mon t y Hall problem\n",
      "The Mon t y Hall problem migh t b e the most con ten tious question in the history\n",
      "of probabilit y . The scenario is simple, but the correct answ er is so coun ter-\n",
      "in tuitiv e that man y p eople just can't accept it, and man y smart p eople ha v e\n",
      "em barrassed themselv es not just b y getting it wrong but b y arguing the wrong\n",
      "side, aggressiv ely , in public.\n",
      "Mon t y Hall w as the original host of the game sho w L et's Make a De al . The\n",
      "Mon t y Hall problem is based on one of the regular games on the sho w. If y ou\n",
      "are on the sho w, here's what happ ens:\n",
      " Mon t y sho ws y ou three closed do ors and tells y ou that there is a prize\n",
      "b ehind eac h do or: one prize is a car, the other t w o are less v aluable\n",
      "prizes lik e p ean ut butter and fak e \u001cnger nails. The prizes are arranged\n",
      "at random.\n",
      " The ob ject of the game is to guess whic h do or has the car. If y ou guess\n",
      "righ t, y ou get to k eep the car.\n",
      " Y ou pic k a do or, whic h w e will call Do or A. W e'll call the other do ors B\n",
      "and C.\n",
      " Before op ening the do or y ou c hose, Mon t y increases the susp ense b y\n",
      "op ening either Do or B or C, whic hev er do es not ha v e the car. (If the car\n",
      "is actually b ehind Do or A, Mon t y can safely op en B or C, so he c ho oses\n",
      "one at random.)\n",
      " Then Mon t y o\u001bers y ou the option to stic k with y our original c hoice or\n",
      "switc h to the one remaining unop ened do or.\n",
      "The question is, should y ou \u0010stic k\u0011 or \u0010switc h\u0011 or do es it mak e no di\u001berence?\n",
      "Most p eople ha v e the strong in tuition that it mak es no di\u001berence. There are\n",
      "t w o do ors left, they reason, so the c hance that the car is b ehind Do or A is\n",
      "50%.\n",
      "But that is wrong. In fact, the c hance of winning if y ou stic k with Do or A is\n",
      "only 1/3; if y ou switc h, y our c hances are 2/3.\n",
      "By applying Ba y es's theorem, w e can break this problem in to simple pieces,\n",
      "and ma yb e con vince ourselv es that the correct answ er is, in fact, correct.\n",
      "T o start, w e should mak e a careful statemen t of the data. In this case D\n",
      "consists of t w o parts: Mon t y c ho oses Do or B and there is no car there.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 25}\n",
      "------------------------\n",
      "page_content='1.7. The Mon t y Hall problem 9\n",
      "Next w e de\u001cne three h yp otheses: A ,B , andC represen t the h yp othesis that\n",
      "the car is b ehind Do or A, Do or B, or Do or C. Again, let's apply the table\n",
      "metho d:\n",
      "Prior Lik eliho o d P osterior\n",
      "p(H)p(D|H)p(H) p(D|H)p(H|D)\n",
      "A 1/3 1/2 1/6 1/3\n",
      "B 1/3 0 0 0\n",
      "C 1/3 1 1/3 2/3\n",
      "Filling in the priors is easy b ecause w e are told that the prizes are arranged at\n",
      "random, whic h suggests that the car is equally lik ely to b e b ehind an y do or.\n",
      "Figuring out the lik eliho o ds tak es some though t, but with reasonable care w e\n",
      "can b e con\u001cden t that w e ha v e it righ t:\n",
      " If the car is actually b ehind A, Mon t y could safely op en Do ors B or C.\n",
      "So the probabilit y that he c ho oses B is 1/2. And since the car is actually\n",
      "b ehind A, the probabilit y that the car is not b ehind B is 1.\n",
      " If the car is actually b ehind B, Mon t y has to op en do or C, so the prob-\n",
      "abilit y that he op ens do or B is 0.\n",
      " Finally , if the car is b ehind Do or C, Mon t y op ens B with probabilit y 1\n",
      "and \u001cnds no car there with probabilit y 1.\n",
      "No w the hard part is o v er; the rest is just arithmetic. The sum of the third\n",
      "column is 1/2. Dividing through yields p(A|D) = 1/3 andp(C|D) = 2/3 . So\n",
      "y ou are b etter o\u001b switc hing.\n",
      "There are man y v ariations of the Mon t y Hall problem. One of the strengths\n",
      "of the Ba y esian approac h is that it generalizes to handle these v ariations.\n",
      "F or example, supp ose that Mon t y alw a ys c ho oses B if he can, and only c ho oses\n",
      "C if he has to (b ecause the car is b ehind B). In that case the revised table is:\n",
      "Prior Lik eliho o d P osterior\n",
      "p(H)p(D|H)p(H) p(D|H)p(H|D)\n",
      "A 1/3 1 1/3 1/2\n",
      "B 1/3 0 0 0\n",
      "C 1/3 1 1/3 1/2\n",
      "The only c hange is p(D|A) . If the car is b ehind A , Mon t y can c ho ose to op en\n",
      "B or C. But in this v ariation he alw a ys c ho oses B, so p(D|A) = 1 .\n",
      "As a result, the lik eliho o ds are the same for A andC , and the p osteriors are\n",
      "the same: p(A|D) = p(C|D) = 1/2 . In this case, the fact that Mon t y c hose' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 26}\n",
      "------------------------\n",
      "page_content='10 Chapter 1. Ba y es's Theorem\n",
      "B rev eals no information ab out the lo cation of the car, so it do esn't matter\n",
      "whether the con testan t stic ks or switc hes.\n",
      "On the other hand, if he had op ened C , w e w ould kno w p(B|D) = 1 .\n",
      "I included the Mon t y Hall problem in this c hapter b ecause I think it is fun, and\n",
      "b ecause Ba y es's theorem mak es the complexit y of the problem a little more\n",
      "manageable. But it is not a t ypical use of Ba y es's theorem, so if y ou found it\n",
      "confusing, don't w orry!\n",
      "1.8 Discussion\n",
      "F or man y problems in v olving conditional probabilit y , Ba y es's theorem pro-\n",
      "vides a divide-and-conquer strategy . If p(A|B) is hard to compute, or hard\n",
      "to measure exp erimen tally , c hec k whether it migh t b e easier to compute the\n",
      "other terms in Ba y es's theorem, p(B|A) ,p(A) andp(B) .\n",
      "If the Mon t y Hall problem is y our idea of fun, I ha v e collected a n um-\n",
      "b er of similar problems in an article called \u0010All y our Ba y es are b elong to\n",
      "us,\u0011 whic h y ou can read at http://allendowney.blogspot.com/2011/10/\n",
      "all- your- bayes- are- belong- to- us.html .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 27}\n",
      "------------------------\n",
      "page_content='Chapter 2\n",
      "Computational Statistics\n",
      "2.1 Distributions\n",
      "In statistics a distribution is a set of v alues and their corresp onding proba-\n",
      "bilities.\n",
      "F or example, if y ou roll a six-sided die, the set of p ossible v alues is the n um b ers\n",
      "1 to 6, and the probabilit y asso ciated with eac h v alue is 1/6.\n",
      "As another example, y ou migh t b e in terested in ho w man y times eac h w ord\n",
      "app ears in common English usage. Y ou could build a distribution that includes\n",
      "eac h w ord and ho w man y times it app ears.\n",
      "T o represen t a distribution in Python, y ou could use a dictionary that maps\n",
      "from eac h v alue to its probabilit y . I ha v e written a class called Pmf that\n",
      "uses a Python dictionary in exactly that w a y , and pro vides a n um b er of useful\n",
      "metho ds. I called the class Pmf in reference to a probabilit y mass function ,\n",
      "whic h is a w a y to represen t a distribution mathematically .\n",
      "Pmf is de\u001cned in a Python mo dule I wrote to accompan y this b o ok,\n",
      "thinkbayes.py . Y ou can do wnload it from http://thinkbayes.com/\n",
      "thinkbayes.py . F or more information see Section 0.3.\n",
      "T o use Pmf y ou can imp ort it lik e this:\n",
      "from thinkbayes import Pmf\n",
      "The follo wing co de builds a Pmf to represen t the distribution of outcomes for\n",
      "a six-sided die:\n",
      "pmf = Pmf()\n",
      "for x in [1,2,3,4,5,6]:\n",
      "pmf.Set(x, 1/6.0)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 28}\n",
      "------------------------\n",
      "page_content='12 Chapter 2. Computational Statistics\n",
      "Pmf creates an empt y Pmf with no v alues. The Set metho d sets the probabilit y\n",
      "asso ciated with eac h v alue to 1/6 .\n",
      "Here's another example that coun ts the n um b er of times eac h w ord app ears\n",
      "in a sequence:\n",
      "pmf = Pmf()\n",
      "for word in word_list:\n",
      "pmf.Incr(word, 1)\n",
      "Incr increases the \u0010probabilit y\u0011 asso ciated with eac h w ord b y 1. If a w ord is\n",
      "not already in the Pmf, it is added.\n",
      "I put \u0010probabilit y\u0011 in quotes b ecause in this example, the probabilities are not\n",
      "normalized; that is, they do not add up to 1. So they are not true probabilities.\n",
      "But in this example the w ord coun ts are prop ortional to the probabilities. So\n",
      "after w e coun t all the w ords, w e can compute probabilities b y dividing through\n",
      "b y the total n um b er of w ords. Pmf pro vides a metho d, Normalize , that do es\n",
      "exactly that:\n",
      "pmf.Normalize()\n",
      "Once y ou ha v e a Pmf ob ject, y ou can ask for the probabilit y asso ciated with\n",
      "an y v alue:\n",
      "print pmf.Prob( ' the ' )\n",
      "And that w ould prin t the frequency of the w ord \u0010the\u0011 as a fraction of the w ords\n",
      "in the list.\n",
      "Pmf uses a Python dictionary to store the v alues and their probabilities, so\n",
      "the v alues in the Pmf can b e an y hashable t yp e. The probabilities can b e an y\n",
      "n umerical t yp e, but they are usually \u001doating-p oin t n um b ers (t yp e float ).\n",
      "2.2 The co okie problem\n",
      "In the con text of Ba y es's theorem, it is natural to use a Pmf to map from eac h\n",
      "h yp othesis to its probabilit y . In the co okie problem, the h yp otheses are B1\n",
      "andB2 . In Python, I represen t them with strings:\n",
      "pmf = Pmf()\n",
      "pmf.Set( ' Bowl 1 ' , 0.5)\n",
      "pmf.Set( ' Bowl 2 ' , 0.5)\n",
      "This distribution, whic h con tains the priors for eac h h yp othesis, is called (w ait\n",
      "for it) the prior distribution .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 29}\n",
      "------------------------\n",
      "page_content='2.3. The Ba y esian framew ork 13\n",
      "T o up date the distribution based on new data (the v anilla co okie), w e m ultiply\n",
      "eac h prior b y the corresp onding lik eliho o d. The lik eliho o d of dra wing a v anilla\n",
      "co okie from Bo wl 1 is 3/4. The lik eliho o d for Bo wl 2 is 1/2.\n",
      "pmf.Mult( ' Bowl 1 ' , 0.75)\n",
      "pmf.Mult( ' Bowl 2 ' , 0.5)\n",
      "Mult do es what y ou w ould exp ect. It gets the probabilit y for the giv en h y-\n",
      "p othesis and m ultiplies b y the giv en lik eliho o d.\n",
      "After this up date, the distribution is no longer normalized, but b ecause these\n",
      "h yp otheses are m utually exclusiv e and collectiv ely exhaustiv e, w e can renor-\n",
      "malize :\n",
      "pmf.Normalize()\n",
      "The result is a distribution that con tains the p osterior probabilit y for eac h\n",
      "h yp othesis, whic h is called (w ait no w) the p osterior distribution .\n",
      "Finally , w e can get the p osterior probabilit y for Bo wl 1:\n",
      "print pmf.Prob( ' Bowl 1 ' )\n",
      "And the answ er is 0.6. Y ou can do wnload this example from http://\n",
      "thinkbayes.com/cookie.py . F or more information see Section 0.3.\n",
      "2.3 The Ba y esian framew ork\n",
      "Before w e go on to other problems, I w an t to rewrite the co de from the previous\n",
      "section to mak e it more general. First I'll de\u001cne a class to encapsulate the co de\n",
      "related to this problem:\n",
      "class Cookie(Pmf):\n",
      "def __init__(self, hypos):\n",
      "Pmf.__init__(self)\n",
      "for hypo in hypos:\n",
      "self.Set(hypo, 1)\n",
      "self.Normalize()\n",
      "A Co okie ob ject is a Pmf that maps from h yp otheses to their probabilities.\n",
      "The __init__ metho d giv es eac h h yp othesis the same prior probabilit y . As in\n",
      "the previous section, there are t w o h yp otheses:\n",
      "hypos = [ ' Bowl 1 ' , ' Bowl 2 ' ]\n",
      "pmf = Cookie(hypos)\n",
      "Cookie pro vides an Update metho d that tak es data as a parameter and up dates\n",
      "the probabilities:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 30}\n",
      "------------------------\n",
      "page_content='14 Chapter 2. Computational Statistics\n",
      "def Update(self, data):\n",
      "for hypo in self.Values():\n",
      "like = self.Likelihood(data, hypo)\n",
      "self.Mult(hypo, like)\n",
      "self.Normalize()\n",
      "Update lo ops through eac h h yp othesis in the suite and m ultiplies its probabilit y\n",
      "b y the lik eliho o d of the data under the h yp othesis, whic h is computed b y\n",
      "Likelihood :\n",
      "mixes = {\n",
      "' Bowl 1 ' :dict(vanilla=0.75, chocolate=0.25),\n",
      "' Bowl 2 ' :dict(vanilla=0.5, chocolate=0.5),\n",
      "}\n",
      "def Likelihood(self, data, hypo):\n",
      "mix = self.mixes[hypo]\n",
      "like = mix[data]\n",
      "return like\n",
      "Likelihood uses mixes , whic h is a dictionary that maps from the name of a\n",
      "b o wl to the mix of co okies in the b o wl.\n",
      "Here's what the up date lo oks lik e:\n",
      "pmf.Update( ' vanilla ' )\n",
      "And then w e can prin t the p osterior probabilit y of eac h h yp othesis:\n",
      "for hypo, prob in pmf.Items():\n",
      "print hypo, prob\n",
      "The result is\n",
      "Bowl 1 0.6\n",
      "Bowl 2 0.4\n",
      "whic h is the same as what w e got b efore. This co de is more complicated than\n",
      "what w e sa w in the previous section. One adv an tage is that it generalizes\n",
      "to the case where w e dra w more than one co okie from the same b o wl (with\n",
      "replacemen t):\n",
      "dataset = [ ' vanilla ' , ' chocolate ' , ' vanilla ' ]\n",
      "for data in dataset:\n",
      "pmf.Update(data)\n",
      "The other adv an tage is that it pro vides a framew ork for solving man y similar\n",
      "problems. In the next section w e'll solv e the Mon t y Hall problem computa-\n",
      "tionally and then see what parts of the framew ork are the same.\n",
      "The co de in this section is a v ailable from http://thinkbayes.com/cookie2.\n",
      "py . F or more information see Section 0.3.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 31}\n",
      "------------------------\n",
      "page_content='2.4. The Mon t y Hall problem 15\n",
      "2.4 The Mon t y Hall problem\n",
      "T o solv e the Mon t y Hall problem, I'll de\u001cne a new class:\n",
      "class Monty(Pmf):\n",
      "def __init__(self, hypos):\n",
      "Pmf.__init__(self)\n",
      "for hypo in hypos:\n",
      "self.Set(hypo, 1)\n",
      "self.Normalize()\n",
      "So far Monty and Cookie are exactly the same. And the co de that creates the\n",
      "Pmf is the same, to o, except for the names of the h yp otheses:\n",
      "hypos = ' ABC '\n",
      "pmf = Monty(hypos)\n",
      "Calling Update is prett y m uc h the same:\n",
      "data = ' B '\n",
      "pmf.Update(data)\n",
      "And the implemen tation of Update is exactly the same:\n",
      "def Update(self, data):\n",
      "for hypo in self.Values():\n",
      "like = self.Likelihood(data, hypo)\n",
      "self.Mult(hypo, like)\n",
      "self.Normalize()\n",
      "The only part that requires some w ork is Likelihood :\n",
      "def Likelihood(self, data, hypo):\n",
      "if hypo == data:\n",
      "return 0\n",
      "elif hypo == ' A ' :\n",
      "return 0.5\n",
      "else:\n",
      "return 1\n",
      "Finally , prin ting the results is the same:\n",
      "for hypo, prob in pmf.Items():\n",
      "print hypo, prob\n",
      "And the answ er is\n",
      "A 0.333333333333\n",
      "B 0.0\n",
      "C 0.666666666667' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 32}\n",
      "------------------------\n",
      "page_content='16 Chapter 2. Computational Statistics\n",
      "In this example, writing Likelihood is a little complicated, but the framew ork\n",
      "of the Ba y esian up date is simple. The co de in this section is a v ailable from\n",
      "http://thinkbayes.com/monty.py . F or more information see Section 0.3.\n",
      "2.5 Encapsulating the framew ork\n",
      "No w that w e see what elemen ts of the framew ork are the same, w e can encap-\n",
      "sulate them in an ob ject\u0016a Suite is a Pmf that pro vides __init__ , Update ,\n",
      "and Print :\n",
      "class Suite(Pmf):\n",
      "\"\"\"Represents a suite of hypotheses and their probabilities.\"\"\"\n",
      "def __init__(self, hypo=tuple()):\n",
      "\"\"\"Initializes the distribution.\"\"\"\n",
      "def Update(self, data):\n",
      "\"\"\"Updates each hypothesis based on the data.\"\"\"\n",
      "def Print(self):\n",
      "\"\"\"Prints the hypotheses and their probabilities.\"\"\"\n",
      "The implemen tation of Suite is in thinkbayes.py . T o use Suite , y ou should\n",
      "write a class that inherits from it and pro vides Likelihood . F or example, here\n",
      "is the solution to the Mon t y Hall problem rewritten to use Suite :\n",
      "from thinkbayes import Suite\n",
      "class Monty(Suite):\n",
      "def Likelihood(self, data, hypo):\n",
      "if hypo == data:\n",
      "return 0\n",
      "elif hypo == ' A ' :\n",
      "return 0.5\n",
      "else:\n",
      "return 1\n",
      "And here's the co de that uses this class:\n",
      "suite = Monty( ' ABC ' )\n",
      "suite.Update( ' B ' )\n",
      "suite.Print()\n",
      "Y ou can do wnload this example from http://thinkbayes.com/monty2.py .\n",
      "F or more information see Section 0.3.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 33}\n",
      "------------------------\n",
      "page_content='2.6. The M&M problem 17\n",
      "2.6 The M&M problem\n",
      "W e can use the Suite framew ork to solv e the M&M problem. W riting the\n",
      "Likelihood function is tric ky , but ev erything else is straigh tforw ard.\n",
      "First I need to enco de the color mixes from b efore and after 1995:\n",
      "mix94 = dict(brown=30,\n",
      "yellow=20,\n",
      "red=20,\n",
      "green=10,\n",
      "orange=10,\n",
      "tan=10)\n",
      "mix96 = dict(blue=24,\n",
      "green=20,\n",
      "orange=16,\n",
      "yellow=14,\n",
      "red=13,\n",
      "brown=13)\n",
      "Then I ha v e to enco de the h yp otheses:\n",
      "hypoA = dict(bag1=mix94, bag2=mix96)\n",
      "hypoB = dict(bag1=mix96, bag2=mix94)\n",
      "hypoA represen ts the h yp othesis that Bag 1 is from 1994 and Bag 2 from 1996.\n",
      "hypoB is the other w a y around.\n",
      "Next I map from the name of the h yp othesis to the represen tation:\n",
      "hypotheses = dict(A=hypoA, B=hypoB)\n",
      "And \u001cnally I can write Likelihood . In this case the h yp othesis, hypo , is a\n",
      "string, either A or B . The data is a tuple that sp eci\u001ces a bag and a color.\n",
      "def Likelihood(self, data, hypo):\n",
      "bag, color = data\n",
      "mix = self.hypotheses[hypo][bag]\n",
      "like = mix[color]\n",
      "return like\n",
      "Here's the co de that creates the suite and up dates it:\n",
      "suite = M_and_M( ' AB ' )\n",
      "suite.Update(( ' bag1 ' , ' yellow ' ))\n",
      "suite.Update(( ' bag2 ' , ' green ' ))\n",
      "suite.Print()' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 34}\n",
      "------------------------\n",
      "page_content='18 Chapter 2. Computational Statistics\n",
      "And here's the result:\n",
      "A 0.740740740741\n",
      "B 0.259259259259\n",
      "The p osterior probabilit y of A is appro ximately 20/27 , whic h is what w e got\n",
      "b efore.\n",
      "The co de in this section is a v ailable from http://thinkbayes.com/m_and_m.\n",
      "py . F or more information see Section 0.3.\n",
      "2.7 Discussion\n",
      "This c hapter presen ts the Suite class, whic h encapsulates the Ba y esian up date\n",
      "framew ork.\n",
      "Suite is an abstract t yp e , whic h means that it de\u001cnes the in terface a Suite\n",
      "is supp osed to ha v e, but do es not pro vide a complete implemen tation. The\n",
      "Suite in terface includes Update and Likelihood , but the Suite class only\n",
      "pro vides an implemen tation of Update , not Likelihood .\n",
      "A concrete t yp e is a class that extends an abstract paren t class and pro-\n",
      "vides an implemen tation of the missing metho ds. F or example, Monty extends\n",
      "Suite , so it inherits Update and pro vides Likelihood .\n",
      "If y ou are familiar with design patterns, y ou migh t recognize this as an example\n",
      "of the template metho d pattern. Y ou can read ab out this pattern at http:\n",
      "//en.wikipedia.org/wiki/Template_method_pattern .\n",
      "Most of the examples in the follo wing c hapters follo w the same pattern; for\n",
      "eac h problem w e de\u001cne a new class that extends Suite , inherits Update , and\n",
      "pro vides Likelihood . In a few cases w e o v erride Update , usually to impro v e\n",
      "p erformance.\n",
      "2.8 Exercises\n",
      "Exercise 2.1 In Section 2.3 I said that the solution to the co okie problem\n",
      "generalizes to the case where w e dra w m ultiple co okies with replacemen t.\n",
      "But in the more lik ely scenario where w e eat the co okies w e dra w, the lik eliho o d\n",
      "of eac h dra w dep ends on the previous dra ws.\n",
      "Mo dify the solution in this c hapter to handle selection without replacemen t.\n",
      "Hin t: add instance v ariables to Cookie to represen t the h yp othetical state of' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 35}\n",
      "------------------------\n",
      "page_content='2.8. Exercises 19\n",
      "the b o wls, and mo dify Likelihood accordingly . Y ou migh t w an t to de\u001cne a\n",
      "Bowl ob ject.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 36}\n",
      "------------------------\n",
      "page_content='20 Chapter 2. Computational Statistics' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 37}\n",
      "------------------------\n",
      "page_content='Chapter 3\n",
      "Estimation\n",
      "3.1 The dice problem\n",
      "Supp ose I ha v e a b o x of dice that con tains a 4-sided die, a 6-sided die, an\n",
      "8-sided die, a 12-sided die, and a 20-sided die. If y ou ha v e ev er pla y ed Dun-\n",
      "ge ons & Dr agons , y ou kno w what I am talking ab out.\n",
      "Supp ose I select a die from the b o x at random, roll it, and get a 6. What is\n",
      "the probabilit y that I rolled eac h die?\n",
      "Let me suggest a three-step strategy for approac hing a problem lik e this.\n",
      "1. Cho ose a represen tation for the h yp otheses.\n",
      "2. Cho ose a represen tation for the data.\n",
      "3. W rite the lik eliho o d function.\n",
      "In previous examples I used strings to represen t h yp otheses and data, but for\n",
      "the die problem I'll use n um b ers. Sp eci\u001ccally , I'll use the in tegers 4, 6, 8, 12,\n",
      "and 20 to represen t h yp otheses:\n",
      "suite = Dice([4, 6, 8, 12, 20])\n",
      "And in tegers from 1 to 20 for the data. These represen tations mak e it easy to\n",
      "write the lik eliho o d function:\n",
      "class Dice(Suite):\n",
      "def Likelihood(self, data, hypo):\n",
      "if hypo < data:\n",
      "return 0\n",
      "else:\n",
      "return 1.0/hypo' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 38}\n",
      "------------------------\n",
      "page_content='22 Chapter 3. Estimation\n",
      "Here's ho w Likelihood w orks. If hypo<data , that means the roll is greater\n",
      "than the n um b er of sides on the die. That can't happ en, so the lik eliho o d is\n",
      "0.\n",
      "Otherwise the question is, \u0010Giv en that there are hypo sides, what is the c hance\n",
      "of rolling data ?\u0011 The answ er is 1/hypo , regardless of data .\n",
      "Here is the statemen t that do es the up date (if I roll a 6):\n",
      "suite.Update(6)\n",
      "And here is the p osterior distribution:\n",
      "4 0.0\n",
      "6 0.392156862745\n",
      "8 0.294117647059\n",
      "12 0.196078431373\n",
      "20 0.117647058824\n",
      "After w e roll a 6, the probabilit y for the 4-sided die is 0. The most lik ely\n",
      "alternativ e is the 6-sided die, but there is still almost a 12% c hance for the\n",
      "20-sided die.\n",
      "What if w e roll a few more times and get 6, 8, 7, 7, 5, and 4?\n",
      "for roll in [6, 8, 7, 7, 5, 4]:\n",
      "suite.Update(roll)\n",
      "With this data the 6-sided die is eliminated, and the 8-sided die seems quite\n",
      "lik ely . Here are the results:\n",
      "4 0.0\n",
      "6 0.0\n",
      "8 0.943248453672\n",
      "12 0.0552061280613\n",
      "20 0.0015454182665\n",
      "No w the probabilit y is 94% that w e are rolling the 8-sided die, and less than\n",
      "1% for the 20-sided die.\n",
      "The dice problem is based on an example I sa w in Sanjo y Maha jan's class on\n",
      "Ba y esian inference. Y ou can do wnload the co de in this section from http:\n",
      "//thinkbayes.com/dice.py . F or more information see Section 0.3.\n",
      "3.2 The lo comotiv e problem\n",
      "I found the lo comotiv e problem in F rederic k Mosteller's, Fifty Chal lenging\n",
      "Pr oblems in Pr ob ability with Solutions (Do v er, 1987):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 39}\n",
      "------------------------\n",
      "page_content='3.2. The lo comotiv e problem 23\n",
      "0 200 400 600 800 1000\n",
      "Number of trains0.0000.0010.0020.0030.0040.0050.006Probability\n",
      "Figure 3.1: P osterior distribution for the lo comotiv e problem, based on a\n",
      "uniform prior.\n",
      "\u0010A railroad n um b ers its lo comotiv es in order 1..N. One da y y ou see\n",
      "a lo comotiv e with the n um b er 60. Estimate ho w man y lo comotiv es\n",
      "the railroad has.\u0011\n",
      "Based on this observ ation, w e kno w the railroad has 60 or more lo comotiv es.\n",
      "But ho w man y more? T o apply Ba y esian reasoning, w e can break this problem\n",
      "in to t w o steps:\n",
      "1. What did w e kno w ab out N b efore w e sa w the data?\n",
      "2. F or an y giv en v alue of N , what is the lik eliho o d of seeing the data (a\n",
      "lo comotiv e with n um b er 60)?\n",
      "The answ er to the \u001crst question is the prior. The answ er to the second is the\n",
      "lik eliho o d.\n",
      "W e don't ha v e m uc h basis to c ho ose a prior, but w e can start with something\n",
      "simple and then consider alternativ es. Let's assume that N is equally lik ely\n",
      "to b e an y v alue from 1 to 1000.\n",
      "hypos = xrange(1, 1001)\n",
      "No w all w e need is a lik eliho o d function. In a h yp othetical \u001deet of N lo co-\n",
      "motiv es, what is the probabilit y that w e w ould see n um b er 60? If w e assume\n",
      "that there is only one train-op erating compan y (or only one w e care ab out)\n",
      "and that w e are equally lik ely to see an y of its lo comotiv es, then the c hance\n",
      "of seeing an y particular lo comotiv e is 1/N .\n",
      "Here's the lik eliho o d function:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 40}\n",
      "------------------------\n",
      "page_content='24 Chapter 3. Estimation\n",
      "class Train(Suite):\n",
      "def Likelihood(self, data, hypo):\n",
      "if hypo < data:\n",
      "return 0\n",
      "else:\n",
      "return 1.0/hypo\n",
      "This migh t lo ok familiar; the lik eliho o d functions for the lo comotiv e problem\n",
      "and the dice problem are iden tical.\n",
      "Here's the up date:\n",
      "suite = Train(hypos)\n",
      "suite.Update(60)\n",
      "There are to o man y h yp otheses to prin t, so I plotted the results in Figure 3.1.\n",
      "Not surprisingly , all v alues of N b elo w 60 ha v e b een eliminated.\n",
      "The most lik ely v alue, if y ou had to guess, is 60. That migh t not seem lik e a\n",
      "v ery go o d guess; after all, what are the c hances that y ou just happ ened to see\n",
      "the train with the highest n um b er? Nev ertheless, if y ou w an t to maximize the\n",
      "c hance of getting the answ er exactly righ t, y ou should guess 60.\n",
      "But ma yb e that's not the righ t goal. An alternativ e is to compute the mean\n",
      "of the p osterior distribution:\n",
      "def Mean(suite):\n",
      "total = 0\n",
      "for hypo, prob in suite.Items():\n",
      "total += hypo * prob\n",
      "return total\n",
      "print Mean(suite)\n",
      "Or y ou could use the v ery similar metho d pro vided b y Pmf :\n",
      "print suite.Mean()\n",
      "The mean of the p osterior is 333, so that migh t b e a go o d guess if y ou w an ted to\n",
      "minimize error. If y ou pla y ed this guessing game o v er and o v er, using the mean\n",
      "of the p osterior as y our estimate w ould minimize the mean squared error o v er\n",
      "the long run (see http://en.wikipedia.org/wiki/Minimum_mean_square_\n",
      "error ).\n",
      "Y ou can do wnload this example from http://thinkbayes.com/train.py . F or\n",
      "more information see Section 0.3.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 41}\n",
      "------------------------\n",
      "page_content='3.3. What ab out that prior? 25\n",
      "3.3 What ab out that prior?\n",
      "T o mak e an y progress on the lo comotiv e problem w e had to mak e assumptions,\n",
      "and some of them w ere prett y arbitrary . In particular, w e c hose a uniform prior\n",
      "from 1 to 1000, without m uc h justi\u001ccation for c ho osing 1000, or for c ho osing\n",
      "a uniform distribution.\n",
      "It is not crazy to b eliev e that a railroad compan y migh t op erate 1000 lo como-\n",
      "tiv es, but a reasonable p erson migh t guess more or few er. So w e migh t w onder\n",
      "whether the p osterior distribution is sensitiv e to these assumptions. With so\n",
      "little data\u0016only one observ ation\u0016it probably is.\n",
      "Recall that with a uniform prior from 1 to 1000, the mean of the p osterior is\n",
      "333. With an upp er b ound of 500, w e get a p osterior mean of 207, and with\n",
      "an upp er b ound of 2000, the p osterior mean is 552.\n",
      "So that's bad. There are t w o w a ys to pro ceed:\n",
      " Get more data.\n",
      " Get more bac kground information.\n",
      "With more data, p osterior distributions based on di\u001beren t priors tend to con-\n",
      "v erge. F or example, supp ose that in addition to train 60 w e also see trains 30\n",
      "and 90. W e can up date the distribution lik e this:\n",
      "for data in [60, 30, 90]:\n",
      "suite.Update(data)\n",
      "With these data, the means of the p osteriors are\n",
      "Upp er P osterior\n",
      "Bound Mean\n",
      "500 152\n",
      "1000 164\n",
      "2000 171\n",
      "So the di\u001berences are smaller.\n",
      "3.4 An alternativ e prior\n",
      "If more data are not a v ailable, another option is to impro v e the priors b y gath-\n",
      "ering more bac kground information. It is probably not reasonable to assume\n",
      "that a train-op erating compan y with 1000 lo comotiv es is just as lik ely as a\n",
      "compan y with only 1.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 42}\n",
      "------------------------\n",
      "page_content='26 Chapter 3. Estimation\n",
      "0 200 400 600 800 1000\n",
      "Number of trains0.0000.0020.0040.0060.0080.0100.0120.0140.0160.018Probabilityuniform\n",
      "power law\n",
      "Figure 3.2: P osterior distribution based on a p o w er la w prior, compared to a\n",
      "uniform prior.\n",
      "With some e\u001bort, w e could probably \u001cnd a list of companies that op erate\n",
      "lo comotiv es in the area of observ ation. Or w e could in terview an exp ert in rail\n",
      "shipping to gather information ab out the t ypical size of companies.\n",
      "But ev en without getting in to the sp eci\u001ccs of railroad economics, w e can mak e\n",
      "some educated guesses. In most \u001celds, there are man y small companies, few er\n",
      "medium-sized companies, and only one or t w o v ery large companies. In fact,\n",
      "the distribution of compan y sizes tends to follo w a p o w er la w, as Rob ert\n",
      "Axtell rep orts in Scienc e (see http://www.sciencemag.org/content/293/\n",
      "5536/1818.full.pdf ).\n",
      "This la w suggests that if there are 1000 companies with few er than 10 lo como-\n",
      "tiv es, there migh t b e 100 companies with 100 lo comotiv es, 10 companies with\n",
      "1000, and p ossibly one compan y with 10,000 lo comotiv es.\n",
      "Mathematically , a p o w er la w means that the n um b er of companies with a giv en\n",
      "size is in v ersely prop ortional to size, or\n",
      "PMF(x)∝(1\n",
      "x)α\n",
      "where PMF(x) is the probabilit y mass function of x andα is a parameter that\n",
      "is often near 1.\n",
      "W e can construct a p o w er la w prior lik e this:\n",
      "class Train(Dice):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 43}\n",
      "------------------------\n",
      "page_content='3.5. Credible in terv als 27\n",
      "def __init__(self, hypos, alpha=1.0):\n",
      "Pmf.__init__(self)\n",
      "for hypo in hypos:\n",
      "self.Set(hypo, hypo**(-alpha))\n",
      "self.Normalize()\n",
      "And here's the co de that constructs the prior:\n",
      "hypos = range(1, 1001)\n",
      "suite = Train(hypos)\n",
      "Again, the upp er b ound is arbitrary , but with a p o w er la w prior, the p osterior\n",
      "is less sensitiv e to this c hoice.\n",
      "Figure 3.2 sho ws the new p osterior based on the p o w er la w, compared to\n",
      "the p osterior based on the uniform prior. Using the bac kground information\n",
      "represen ted in the p o w er la w prior, w e can all but eliminate v alues of N greater\n",
      "than 700.\n",
      "If w e start with this prior and observ e trains 30, 60, and 90, the means of the\n",
      "p osteriors are\n",
      "Upp er P osterior\n",
      "Bound Mean\n",
      "500 131\n",
      "1000 133\n",
      "2000 134\n",
      "No w the di\u001berences are m uc h smaller. In fact, with an arbitrarily large upp er\n",
      "b ound, the mean con v erges on 134.\n",
      "So the p o w er la w prior is more realistic, b ecause it is based on general infor-\n",
      "mation ab out the size of companies, and it b eha v es b etter in practice.\n",
      "Y ou can do wnload the examples in this section from http://thinkbayes.\n",
      "com/train3.py . F or more information see Section 0.3.\n",
      "3.5 Credible in terv als\n",
      "Once y ou ha v e computed a p osterior distribution, it is often useful to summa-\n",
      "rize the results with a single p oin t estimate or an in terv al. F or p oin t estimates\n",
      "it is common to use the mean, median, or the v alue with maxim um lik eliho o d.\n",
      "F or in terv als w e usually rep ort t w o v alues computed so that there is a 90%\n",
      "c hance that the unkno wn v alue falls b et w een them (or an y other probabilit y).\n",
      "These v alues de\u001cne a credible in terv al .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 44}\n",
      "------------------------\n",
      "page_content='28 Chapter 3. Estimation\n",
      "A simple w a y to compute a credible in terv al is to add up the probabilities in the\n",
      "p osterior distribution and record the v alues that corresp ond to probabilities\n",
      "5% and 95%. In other w ords, the 5th and 95th p ercen tiles.\n",
      "thinkbayes pro vides a function that computes p ercen tiles:\n",
      "def Percentile(pmf, percentage):\n",
      "p = percentage / 100.0\n",
      "total = 0\n",
      "for val, prob in pmf.Items():\n",
      "total += prob\n",
      "if total >= p:\n",
      "return val\n",
      "And here's the co de that uses it:\n",
      "interval = Percentile(suite, 5), Percentile(suite, 95)\n",
      "print interval\n",
      "F or the previous example\u0016the lo comotiv e problem with a p o w er la w prior\n",
      "and three trains\u0016the 90% credible in terv al is (91,243) . The width of this\n",
      "range suggests, correctly , that w e are still quite uncertain ab out ho w man y\n",
      "lo comotiv es there are.\n",
      "3.6 Cum ulativ e distribution functions\n",
      "In the previous section w e computed p ercen tiles b y iterating through the v alues\n",
      "and probabilities in a Pmf. If w e need to compute more than a few p ercen tiles,\n",
      "it is more e\u001ecien t to use a cum ulativ e distribution function, or Cdf.\n",
      "Cdfs and Pmfs are equiv alen t in the sense that they con tain the same informa-\n",
      "tion ab out the distribution, and y ou can alw a ys con v ert from one to the other.\n",
      "The adv an tage of the Cdf is that y ou can compute p ercen tiles more e\u001ecien tly .\n",
      "thinkbayes pro vides a Cdf class that represen ts a cum ulativ e distribution\n",
      "function. Pmf pro vides a metho d that mak es the corresp onding Cdf:\n",
      "cdf = suite.MakeCdf()\n",
      "And Cdf pro vides a function named Percentile\n",
      "interval = cdf.Percentile(5), cdf.Percentile(95)\n",
      "Con v erting from a Pmf to a Cdf tak es time prop ortional to the n um b er of\n",
      "v alues, len(pmf) . The Cdf stores the v alues and probabilities in sorted lists,\n",
      "so lo oking up a probabilit y to get the corresp onding v alue tak es \u0010log time\u0011:\n",
      "that is, time prop ortional to the logarithm of the n um b er of v alues. Lo oking' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 45}\n",
      "------------------------\n",
      "page_content='3.7. The German tank problem 29\n",
      "up a v alue to get the corresp onding probabilit y is also logarithmic, so Cdfs are\n",
      "e\u001ecien t for man y calculations.\n",
      "The examples in this section are in http://thinkbayes.com/train3.py . F or\n",
      "more information see Section 0.3.\n",
      "3.7 The German tank problem\n",
      "During W orld W ar I I, the Economic W arfare Division of the American Em-\n",
      "bassy in London used statistical analysis to estimate German pro duction of\n",
      "tanks and other equipmen t.1\n",
      "The W estern Allies had captured log b o oks, in v en tories, and repair records\n",
      "that included c hassis and engine serial n um b ers for individual tanks.\n",
      "Analysis of these records indicated that serial n um b ers w ere allo cated b y man-\n",
      "ufacturer and tank t yp e in blo c ks of 100 n um b ers, that n um b ers in eac h blo c k\n",
      "w ere used sequen tially , and that not all n um b ers in eac h blo c k w ere used. So\n",
      "the problem of estimating German tank pro duction could b e reduced, within\n",
      "eac h blo c k of 100 n um b ers, to a form of the lo comotiv e problem.\n",
      "Based on this insigh t, American and British analysts pro duced estimates sub-\n",
      "stan tially lo w er than estimates from other forms of in telligence. And after the\n",
      "w ar, records indicated that they w ere substan tially more accurate.\n",
      "They p erformed similar analyses for tires, truc ks, ro c k ets, and other equip-\n",
      "men t, yielding accurate and actionable economic in telligence.\n",
      "The German tank problem is historically in teresting; it is also a nice example\n",
      "of real-w orld application of statistical estimation. So far man y of the examples\n",
      "in this b o ok ha v e b een to y problems, but it will not b e long b efore w e start\n",
      "solving real problems. I think it is an adv an tage of Ba y esian analysis, esp ecially\n",
      "with the computational approac h w e are taking, that it pro vides suc h a short\n",
      "path from a basic in tro duction to the researc h fron tier.\n",
      "3.8 Discussion\n",
      "Among Ba y esians, there are t w o approac hes to c ho osing prior distributions.\n",
      "Some recommend c ho osing the prior that b est represen ts bac kground infor-\n",
      "mation ab out the problem; in that case the prior is said to b e informativ e .\n",
      "1Ruggles and Bro die, \u0010An Empirical Approac h to Economic In telligence in W orld W ar\n",
      "I I,\u0011 Journal of the A meric an Statistic al Asso ciation , V ol. 42, No. 237 (Marc h 1947).' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 46}\n",
      "------------------------\n",
      "page_content='30 Chapter 3. Estimation\n",
      "The problem with using an informativ e prior is that p eople migh t use di\u001ber-\n",
      "en t bac kground information (or in terpret it di\u001beren tly). So informativ e priors\n",
      "often seem sub jectiv e.\n",
      "The alternativ e is a so-called uninformativ e prior , whic h is in tended to b e\n",
      "as unrestricted as p ossible, in order to let the data sp eak for themselv es. In\n",
      "some cases y ou can iden tify a unique prior that has some desirable prop ert y ,\n",
      "lik e represen ting minimal prior information ab out the estimated quan tit y .\n",
      "Uninformativ e priors are app ealing b ecause they seem more ob jectiv e. But\n",
      "I am generally in fa v or of using informativ e priors. Wh y? First, Ba y esian\n",
      "analysis is alw a ys based on mo deling decisions. Cho osing the prior is one of\n",
      "those decisions, but it is not the only one, and it migh t not ev en b e the most\n",
      "sub jectiv e. So ev en if an uninformativ e prior is more ob jectiv e, the en tire\n",
      "analysis is still sub jectiv e.\n",
      "Also, for most practical problems, y ou are lik ely to b e in one of t w o regimes:\n",
      "either y ou ha v e a lot of data or not v ery m uc h. If y ou ha v e a lot of data, the\n",
      "c hoice of the prior do esn't matter v ery m uc h; informativ e and uninformativ e\n",
      "priors yield almost the same results. W e'll see an example lik e this in the next\n",
      "c hapter.\n",
      "But if, as in the lo comotiv e problem, y ou don't ha v e m uc h data, using rel-\n",
      "ev an t bac kground information (lik e the p o w er la w distribution) mak es a big\n",
      "di\u001berence.\n",
      "And if, as in the German tank problem, y ou ha v e to mak e life-and-death deci-\n",
      "sions based on y our results, y ou should probably use all of the information at\n",
      "y our disp osal, rather than main taining the illusion of ob jectivit y b y pretending\n",
      "to kno w less than y ou do.\n",
      "3.9 Exercises\n",
      "Exercise 3.1 T o write a lik eliho o d function for the lo comotiv e problem, w e\n",
      "had to answ er this question: \u0010If the railroad has N lo comotiv es, what is the\n",
      "probabilit y that w e see n um b er 60?\u0011\n",
      "The answ er dep ends on what sampling pro cess w e use when w e observ e the\n",
      "lo comotiv e. In this c hapter, I resolv ed the am biguit y b y sp ecifying that there\n",
      "is only one train-op erating compan y (or only one that w e care ab out).\n",
      "But supp ose instead that there are man y companies with di\u001beren t n um b ers of\n",
      "trains. And supp ose that y ou are equally lik ely to see an y train op erated b y' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 47}\n",
      "------------------------\n",
      "page_content='3.9. Exercises 31\n",
      "an y compan y . In that case, the lik eliho o d function is di\u001beren t b ecause y ou are\n",
      "more lik ely to see a train op erated b y a large compan y .\n",
      "As an exercise, implemen t the lik eliho o d function for this v ariation of the\n",
      "lo comotiv e problem, and compare the results.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 48}\n",
      "------------------------\n",
      "page_content='32 Chapter 3. Estimation' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 49}\n",
      "------------------------\n",
      "page_content='Chapter 4\n",
      "More Estimation\n",
      "4.1 The Euro problem\n",
      "In Information The ory, Infer enc e, and L e arning A lgorithms , Da vid MacKa y\n",
      "p oses this problem:\n",
      "A statistical statemen t app eared in \u0010The Guardian\" on F rida y Jan-\n",
      "uary 4, 2002:\n",
      "When spun on edge 250 times, a Belgian one-euro coin\n",
      "came up heads 140 times and tails 110. `It lo oks v ery\n",
      "suspicious to me,' said Barry Bligh t, a statistics lecturer\n",
      "at the London Sc ho ol of Economics. `If the coin w ere\n",
      "un biased, the c hance of getting a result as extreme as\n",
      "that w ould b e less than 7%.'\n",
      "But do these data giv e evidence that the coin is biased rather than\n",
      "fair?\n",
      "T o answ er that question, w e'll pro ceed in t w o steps. The \u001crst is to estimate\n",
      "the probabilit y that the coin lands face up. The second is to ev aluate whether\n",
      "the data supp ort the h yp othesis that the coin is biased.\n",
      "Y ou can do wnload the co de in this section from http://thinkbayes.com/\n",
      "euro.py . F or more information see Section 0.3.\n",
      "An y giv en coin has some probabilit y , x , of landing heads up when spun on\n",
      "edge. It seems reasonable to b eliev e that the v alue of x dep ends on some\n",
      "ph ysical c haracteristics of the coin, primarily the distribution of w eigh t.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 50}\n",
      "------------------------\n",
      "page_content='34 Chapter 4. More Estimation\n",
      "0 20 40 60 80 100\n",
      "x0.000.020.040.060.080.100.120.14Probabilityuniform\n",
      "Figure 4.1: P osterior distribution for the Euro problem on a uniform prior.\n",
      "If a coin is p erfectly balanced, w e exp ect x to b e close to 50%, but for a\n",
      "lopsided coin, x migh t b e substan tially di\u001beren t. W e can use Ba y es's theorem\n",
      "and the observ ed data to estimate x .\n",
      "Let's de\u001cne 101 h yp otheses, where Hx is the h yp othesis that the probabilit y\n",
      "of heads is x %, for v alues from 0 to 100. I'll start with a uniform prior where\n",
      "the probabilit y of Hx is the same for all x . W e'll come bac k later to consider\n",
      "other priors.\n",
      "The lik eliho o d function is relativ ely easy: If Hx is true, the probabilit y of\n",
      "heads isx/100 and the probabilit y of tails is 1−x/100 .\n",
      "class Euro(Suite):\n",
      "def Likelihood(self, data, hypo):\n",
      "x = hypo\n",
      "if data == ' H ' :\n",
      "return x/100.0\n",
      "else:\n",
      "return 1 - x/100.0\n",
      "Here's the co de that mak es the suite and up dates it:\n",
      "suite = Euro(xrange(0, 101))\n",
      "dataset = ' H ' * 140 + ' T ' * 110\n",
      "for data in dataset:\n",
      "suite.Update(data)\n",
      "The result is in Figure 4.1.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 51}\n",
      "------------------------\n",
      "page_content='4.2. Summarizing the p osterior 35\n",
      "4.2 Summarizing the p osterior\n",
      "Again, there are sev eral w a ys to summarize the p osterior distribution. One\n",
      "option is to \u001cnd the most lik ely v alue in the p osterior distribution. thinkbayes\n",
      "pro vides a function that do es that:\n",
      "def MaximumLikelihood(pmf):\n",
      "\"\"\"Returns the value with the highest probability.\"\"\"\n",
      "prob, val = max((prob, val) for val, prob in pmf.Items())\n",
      "return val\n",
      "In this case the result is 56, whic h is also the observ ed p ercen tage of heads,\n",
      "140/250 = 56% . So that suggests (correctly) that the observ ed p ercen tage is\n",
      "the maxim um lik eliho o d estimator for the p opulation.\n",
      "W e migh t also summarize the p osterior b y computing the mean and median:\n",
      "print ' Mean ' , suite.Mean()\n",
      "print ' Median ' , thinkbayes.Percentile(suite, 50)\n",
      "The mean is 55.95; the median is 56. Finally , w e can compute a credible\n",
      "in terv al:\n",
      "print ' CI ' , thinkbayes.CredibleInterval(suite, 90)\n",
      "The result is (51,61) .\n",
      "No w, getting bac k to the original question, w e w ould lik e to kno w whether the\n",
      "coin is fair. W e observ e that the p osterior credible in terv al do es not include\n",
      "50%, whic h suggests that the coin is not fair.\n",
      "But that is not exactly the question w e started with. MacKa y ask ed, \u0010 Do\n",
      "these data giv e evidence that the coin is biased rather than fair?\u0011 T o answ er\n",
      "that question, w e will ha v e to b e more precise ab out what it means to sa y that\n",
      "data constitute evidence for a h yp othesis. And that is the sub ject of the next\n",
      "c hapter.\n",
      "But b efore w e go on, I w an t to address one p ossible source of confusion. Since\n",
      "w e w an t to kno w whether the coin is fair, it migh t b e tempting to ask for the\n",
      "probabilit y that x is 50%:\n",
      "print suite.Prob(50)\n",
      "The result is 0.021, but that v alue is almost meaningless. The decision to\n",
      "ev aluate 101 h yp otheses w as arbitrary; w e could ha v e divided the range in to\n",
      "more or few er pieces, and if w e had, the probabilit y for an y giv en h yp othesis\n",
      "w ould b e greater or less.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 52}\n",
      "------------------------\n",
      "page_content='36 Chapter 4. More Estimation\n",
      "0 20 40 60 80 100\n",
      "x0.0000.0050.0100.0150.0200.025Probabilityuniform\n",
      "triangle\n",
      "Figure 4.2: Uniform and triangular priors for the Euro problem.\n",
      "0 20 40 60 80 100\n",
      "x0.000.020.040.060.080.100.120.14Probabilityuniform\n",
      "triangle\n",
      "Figure 4.3: P osterior distributions for the Euro problem.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 53}\n",
      "------------------------\n",
      "page_content='4.3. Sw amping the priors 37\n",
      "4.3 Sw amping the priors\n",
      "W e started with a uniform prior, but that migh t not b e a go o d c hoice. I can\n",
      "b eliev e that if a coin is lopsided, x migh t deviate substan tially from 50%, but\n",
      "it seems unlik ely that the Belgian Euro coin is so im balanced that x is 10% or\n",
      "90%.\n",
      "It migh t b e more reasonable to c ho ose a prior that giv es higher probabilit y to\n",
      "v alues ofx near 50% and lo w er probabilit y to extreme v alues.\n",
      "As an example, I constructed a triangular prior, sho wn in Figure 4.2. Here's\n",
      "the co de that constructs the prior:\n",
      "def TrianglePrior():\n",
      "suite = Euro()\n",
      "for x in range(0, 51):\n",
      "suite.Set(x, x)\n",
      "for x in range(51, 101):\n",
      "suite.Set(x, 100-x)\n",
      "suite.Normalize()\n",
      "Figure 4.2 sho ws the result (and the uniform prior for comparison). Up dating\n",
      "this prior with the same dataset yields the p osterior distribution sho wn in\n",
      "Figure 4.3. Ev en with substan tially di\u001beren t priors, the p osterior distributions\n",
      "are v ery similar. The medians and the credible in terv als are iden tical; the\n",
      "means di\u001ber b y less than 0.5%.\n",
      "This is an example of sw amping the priors : with enough data, p eople who\n",
      "start with di\u001beren t priors will tend to con v erge on the same p osterior.\n",
      "4.4 Optimization\n",
      "The co de I ha v e sho wn so far is mean t to b e easy to read, but it is not v ery\n",
      "e\u001ecien t. In general, I lik e to dev elop co de that is demonstrably correct, then\n",
      "c hec k whether it is fast enough for m y purp oses. If so, there is no need to\n",
      "optimize. F or this example, if w e care ab out run time, there are sev eral w a ys\n",
      "w e can sp eed it up.\n",
      "The \u001crst opp ortunit y is to reduce the n um b er of times w e normalize the suite.\n",
      "In the original co de, w e call Update once for eac h spin.\n",
      "dataset = ' H ' * heads + ' T ' * tails\n",
      "for data in dataset:\n",
      "suite.Update(data)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 54}\n",
      "------------------------\n",
      "page_content='38 Chapter 4. More Estimation\n",
      "And here's what Update lo oks lik e:\n",
      "def Update(self, data):\n",
      "for hypo in self.Values():\n",
      "like = self.Likelihood(data, hypo)\n",
      "self.Mult(hypo, like)\n",
      "return self.Normalize()\n",
      "Eac h up date iterates through the h yp otheses, then calls Normalize , whic h\n",
      "iterates through the h yp otheses again. W e can sa v e some time b y doing all of\n",
      "the up dates b efore normalizing.\n",
      "Suite pro vides a metho d called UpdateSet that do es exactly that. Here it is:\n",
      "def UpdateSet(self, dataset):\n",
      "for data in dataset:\n",
      "for hypo in self.Values():\n",
      "like = self.Likelihood(data, hypo)\n",
      "self.Mult(hypo, like)\n",
      "return self.Normalize()\n",
      "And here's ho w w e can in v ok e it:\n",
      "dataset = ' H ' * heads + ' T ' * tails\n",
      "suite.UpdateSet(dataset)\n",
      "This optimization sp eeds things up, but the run time is still prop ortional to the\n",
      "amoun t of data. W e can sp eed things up ev en more b y rewriting Likelihood\n",
      "to pro cess the en tire dataset, rather than one spin at a time.\n",
      "In the original v ersion, data is a string that enco des either heads or tails:\n",
      "def Likelihood(self, data, hypo):\n",
      "x = hypo / 100.0\n",
      "if data == ' H ' :\n",
      "return x\n",
      "else:\n",
      "return 1-x\n",
      "As an alternativ e, w e could enco de the dataset as a tuple of t w o in tegers: the\n",
      "n um b er of heads and tails. In that case Likelihood lo oks lik e this:\n",
      "def Likelihood(self, data, hypo):\n",
      "x = hypo / 100.0\n",
      "heads, tails = data\n",
      "like = x**heads * (1-x)**tails\n",
      "return like\n",
      "And then w e can call Update lik e this:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 55}\n",
      "------------------------\n",
      "page_content='4.5. The b eta distribution 39\n",
      "heads, tails = 140, 110\n",
      "suite.Update((heads, tails))\n",
      "Since w e ha v e replaced rep eated m ultiplication with exp onen tiation, this v er-\n",
      "sion tak es the same time for an y n um b er of spins.\n",
      "4.5 The b eta distribution\n",
      "There is one more optimization that solv es this problem ev en faster.\n",
      "So far w e ha v e used a Pmf ob ject to represen t a discrete set of v alues for x .\n",
      "No w w e will use a con tin uous distribution, sp eci\u001ccally the b eta distribution\n",
      "(see http://en.wikipedia.org/wiki/Beta_distribution ).\n",
      "The b eta distribution is de\u001cned on the in terv al from 0 to 1 (including b oth),\n",
      "so it is a natural c hoice for describing prop ortions and probabilities. But w ait,\n",
      "it gets b etter.\n",
      "It turns out that if y ou do a Ba y esian up date with a binomial lik eliho o d\n",
      "function, whic h is what w e did in the previous section, the b eta distribution is\n",
      "a conjugate prior . That means that if the prior distribution for x is a b eta\n",
      "distribution, the p osterior is also a b eta distribution. But w ait, it gets ev en\n",
      "b etter.\n",
      "The shap e of the b eta distribution dep ends on t w o parameters, written α and\n",
      "β , or alpha and beta . If the prior is a b eta distribution with parameters\n",
      "alpha and beta , and w e see data with h heads and t tails, the p osterior is a\n",
      "b eta distribution with parameters alpha+h and beta+t . In other w ords, w e\n",
      "can do an up date with t w o additions.\n",
      "So that's great, but it only w orks if w e can \u001cnd a b eta distribution that is a\n",
      "go o d c hoice for a prior. F ortunately , for man y realistic priors there is a b eta\n",
      "distribution that is at least a go o d appro ximation, and for a uniform prior\n",
      "there is a p erfect matc h. The b eta distribution with alpha=1 and beta=1 is\n",
      "uniform from 0 to 1.\n",
      "Let's see ho w w e can tak e adv an tage of all this. thinkbayes.py pro vides a\n",
      "class that represen ts a b eta distribution:\n",
      "class Beta(object):\n",
      "def __init__(self, alpha=1, beta=1):\n",
      "self.alpha = alpha\n",
      "self.beta = beta' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 56}\n",
      "------------------------\n",
      "page_content='40 Chapter 4. More Estimation\n",
      "By default __init__ mak es a uniform distribution. Update p erforms a\n",
      "Ba y esian up date:\n",
      "def Update(self, data):\n",
      "heads, tails = data\n",
      "self.alpha += heads\n",
      "self.beta += tails\n",
      "data is a pair of in tegers represen ting the n um b er of heads and tails.\n",
      "So w e ha v e y et another w a y to solv e the Euro problem:\n",
      "beta = thinkbayes.Beta()\n",
      "beta.Update((140, 110))\n",
      "print beta.Mean()\n",
      "Beta pro vides Mean , whic h computes a simple function of alpha and beta :\n",
      "def Mean(self):\n",
      "return float(self.alpha) / (self.alpha + self.beta)\n",
      "F or the Euro problem the p osterior mean is 56%, whic h is the same result w e\n",
      "got using Pmfs.\n",
      "Beta also pro vides EvalPdf , whic h ev aluates the probabilit y densit y function\n",
      "(PDF) of the b eta distribution:\n",
      "def EvalPdf(self, x):\n",
      "return x**(self.alpha-1) * (1-x)**(self.beta-1)\n",
      "Finally , Beta pro vides MakePmf , whic h uses EvalPdf to generate a discrete\n",
      "appro ximation of the b eta distribution.\n",
      "4.6 Discussion\n",
      "In this c hapter w e solv ed the same problem with t w o di\u001beren t priors and found\n",
      "that with a large dataset, the priors get sw amp ed. If t w o p eople start with\n",
      "di\u001beren t prior b eliefs, they generally \u001cnd, as they see more data, that their\n",
      "p osterior distributions con v erge. A t some p oin t the di\u001berence b et w een their\n",
      "distributions is small enough that it has no practical e\u001bect.\n",
      "When this happ ens, it reliev es some of the w orry ab out ob jectivit y that I\n",
      "discussed in the previous c hapter. And for man y real-w orld problems ev en\n",
      "stark prior b eliefs can ev en tually b e reconciled b y data.\n",
      "But that is not alw a ys the case. First, remem b er that all Ba y esian analysis\n",
      "is based on mo deling decisions. If y ou and I do not c ho ose the same mo del,' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 57}\n",
      "------------------------\n",
      "page_content='4.7. Exercises 41\n",
      "w e migh t in terpret data di\u001beren tly . So ev en with the same data, w e w ould\n",
      "compute di\u001beren t lik eliho o ds, and our p osterior b eliefs migh t not con v erge.\n",
      "Also, notice that in a Ba y esian up date, w e m ultiply eac h prior probabilit y\n",
      "b y a lik eliho o d, so if p(H) is 0, p(H|D) is also 0, regardless of D . In the\n",
      "Euro problem, if y ou are con vinced that x is less than 50%, and y ou assign\n",
      "probabilit y 0 to all other h yp otheses, no amoun t of data will con vince y ou\n",
      "otherwise.\n",
      "This observ ation is the basis of Crom w ell's rule , whic h is the recommenda-\n",
      "tion that y ou should a v oid giving a prior probabilit y of 0 to an y h yp othesis that\n",
      "is ev en remotely p ossible (see http://en.wikipedia.org/wiki/Cromwell' s_\n",
      "rule ).\n",
      "Crom w ell's rule is named after Oliv er Crom w ell, who wrote, \u0010I b eseec h y ou,\n",
      "in the b o w els of Christ, think it p ossible that y ou ma y b e mistak en.\u0011 F or\n",
      "Ba y esians, this turns out to b e go o d advice (ev en if it's a little o v erwrough t).\n",
      "4.7 Exercises\n",
      "Exercise 4.1 Supp ose that instead of observing coin tosses directly , y ou mea-\n",
      "sure the outcome using an instrumen t that is not alw a ys correct. Sp eci\u001ccally ,\n",
      "supp ose there is a probabilit y y that an actual heads is rep orted as tails, or\n",
      "actual tails rep orted as heads.\n",
      "W rite a class that estimates the bias of a coin giv en a series of outcomes and\n",
      "the v alue of y .\n",
      "Ho w do es the spread of the p osterior distribution dep end on y ?\n",
      "Exercise 4.2 This exercise is inspired b y a question p osted b y a \u0010redditor\u0011\n",
      "named dominosci on Reddit's statistics \u0010subreddit\u0011 at http://reddit.com/\n",
      "r/statistics .\n",
      "Reddit is an online forum with man y in terest groups called subreddits. Users,\n",
      "called redditors, p ost links to online con ten t and other w eb pages. Other\n",
      "redditors v ote on the links, giving an \u0010up v ote\u0011 to high-qualit y links and a\n",
      "\u0010do wn v ote\u0011 to links that are bad or irrelev an t.\n",
      "A problem, iden ti\u001ced b y dominosci, is that some redditors are more reliable\n",
      "than others, and Reddit do es not tak e this in to accoun t.\n",
      "The c hallenge is to devise a system so that when a redditor casts a v ote, the\n",
      "estimated qualit y of the link is up dated in accordance with the reliabilit y of the' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 58}\n",
      "------------------------\n",
      "page_content='42 Chapter 4. More Estimation\n",
      "redditor, and the estimated reliabilit y of the redditor is up dated in accordance\n",
      "with the qualit y of the link.\n",
      "One approac h is to mo del the qualit y of the link as the probabilit y of garnering\n",
      "an up v ote, and to mo del the reliabilit y of the redditor as the probabilit y of\n",
      "correctly giving an up v ote to a high-qualit y item.\n",
      "W rite class de\u001cnitions for redditors and links and an up date function that\n",
      "up dates b oth ob jects whenev er a redditor casts a v ote.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 59}\n",
      "------------------------\n",
      "page_content='Chapter 5\n",
      "Odds and Addends\n",
      "5.1 Odds\n",
      "One w a y to represen t a probabilit y is with a n um b er b et w een 0 and 1, but\n",
      "that's not the only w a y . If y ou ha v e ev er b et on a fo otball game or a horse\n",
      "race, y ou ha v e probably encoun tered another represen tation of probabilit y ,\n",
      "called o dds .\n",
      "Y ou migh t ha v e heard expressions lik e \u0010the o dds are three to one,\u0011 but y ou\n",
      "migh t not kno w what that means. The o dds in fa v or of an ev en t are the\n",
      "ratio of the probabilit y it will o ccur to the probabilit y that it will not.\n",
      "So if I think m y team has a 75% c hance of winning, I w ould sa y that the o dds\n",
      "in their fa v or are three to one, b ecause the c hance of winning is three times\n",
      "the c hance of losing.\n",
      "Y ou can write o dds in decimal form, but it is most common to write them as\n",
      "a ratio of in tegers. So \u0010three to one\u0011 is written 3 : 1 .\n",
      "When probabilities are lo w, it is more common to rep ort the o dds against\n",
      "rather than the o dds in fa v or. F or example, if I think m y horse has a 10%\n",
      "c hance of winning, I w ould sa y that the o dds against are 9 : 1 .\n",
      "Probabilities and o dds are di\u001beren t represen tations of the same information.\n",
      "Giv en a probabilit y , y ou can compute the o dds lik e this:\n",
      "def Odds(p):\n",
      "return p / (1-p)\n",
      "Giv en the o dds in fa v or, in decimal form, y ou can con v ert to probabilit y lik e\n",
      "this:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 60}\n",
      "------------------------\n",
      "page_content='44 Chapter 5. Odds and A ddends\n",
      "def Probability(o):\n",
      "return o / (o+1)\n",
      "If y ou represen t o dds with a n umerator and denominator, y ou can con v ert to\n",
      "probabilit y lik e this:\n",
      "def Probability2(yes, no):\n",
      "return yes / (yes + no)\n",
      "When I w ork with o dds in m y head, I \u001cnd it helpful to picture p eople at the\n",
      "trac k. If 20% of them think m y horse will win, then 80% of them don't, so the\n",
      "o dds in fa v or are 20 : 80 or1 : 4 .\n",
      "If the o dds are 5 : 1 against m y horse, then \u001cv e out of six p eople think she\n",
      "will lose, so the probabilit y of winning is 1/6 .\n",
      "5.2 The o dds form of Ba y es's theorem\n",
      "In Chapter 1 I wrote Ba y es's theorem in the probabilit y form :\n",
      "p(H|D) =p(H) p(D|H)\n",
      "p(D)\n",
      "If w e ha v e t w o h yp otheses, A andB , w e can write the ratio of p osterior\n",
      "probabilities lik e this:\n",
      "p(A|D)\n",
      "p(B|D)=p(A) p(D|A)\n",
      "p(B) p(D|B)\n",
      "Notice that the normalizing constan t, p(D) , drops out of this equation.\n",
      "IfA andB are m utually exclusiv e and collectiv ely exhaustiv e, that means\n",
      "p(B) = 1−p(A) , so w e can rewrite the ratio of the priors, and the ratio of the\n",
      "p osteriors, as o dds.\n",
      "W riting o(A) for o dds in fa v or of A , w e get:\n",
      "o(A|D) = o(A)p(D|A)\n",
      "p(D|B)\n",
      "In w ords, this sa ys that the p osterior o dds are the prior o dds times the lik eli-\n",
      "ho o d ratio. This is the o dds form of Ba y es's theorem.\n",
      "This form is most con v enien t for computing a Ba y esian up date on pap er or in\n",
      "y our head. F or example, let's go bac k to the co okie problem:\n",
      "Supp ose there are t w o b o wls of co okies. Bo wl 1 con tains 30 v anilla\n",
      "co okies and 10 c ho colate co okies. Bo wl 2 con tains 20 of eac h.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 61}\n",
      "------------------------\n",
      "page_content='5.3. Oliv er's blo o d 45\n",
      "No w supp ose y ou c ho ose one of the b o wls at random and, without\n",
      "lo oking, select a co okie at random. The co okie is v anilla. What is\n",
      "the probabilit y that it came from Bo wl 1?\n",
      "The prior probabilit y is 50%, so the prior o dds are 1 : 1 , or just 1. The lik eli-\n",
      "ho o d ratio is3\n",
      "4/1\n",
      "2, or3/2 . So the p osterior o dds are 3 : 2 , whic h corresp onds\n",
      "to probabilit y 3/5 .\n",
      "5.3 Oliv er's blo o d\n",
      "Here is another problem from MacKa y's Information The ory, Infer enc e, and\n",
      "L e arning A lgorithms :\n",
      "T w o p eople ha v e left traces of their o wn blo o d at the scene of a\n",
      "crime. A susp ect, Oliv er, is tested and found to ha v e t yp e `O'\n",
      "blo o d. The blo o d groups of the t w o traces are found to b e of\n",
      "t yp e `O' (a common t yp e in the lo cal p opulation, ha ving frequency\n",
      "60%) and of t yp e `AB' (a rare t yp e, with frequency 1%). Do these\n",
      "data [the traces found at the scene] giv e evidence in fa v or of the\n",
      "prop osition that Oliv er w as one of the p eople [who left blo o d at\n",
      "the scene]?\n",
      "T o answ er this question, w e need to think ab out what it means for data to\n",
      "giv e evidence in fa v or of (or against) a h yp othesis. In tuitiv ely , w e migh t sa y\n",
      "that data fa v or a h yp othesis if the h yp othesis is more lik ely in ligh t of the data\n",
      "than it w as b efore.\n",
      "In the co okie problem, the prior o dds are 1 : 1 , or probabilit y 50%. The\n",
      "p osterior o dds are 3 : 2 , or probabilit y 60%. So w e could sa y that the v anilla\n",
      "co okie is evidence in fa v or of Bo wl 1.\n",
      "The o dds form of Ba y es's theorem pro vides a w a y to mak e this in tuition more\n",
      "precise. Again\n",
      "o(A|D) = o(A)p(D|A)\n",
      "p(D|B)\n",
      "Or dividing through b y o(A) :\n",
      "o(A|D)\n",
      "o(A)=p(D|A)\n",
      "p(D|B)\n",
      "The term on the left is the ratio of the p osterior and prior o dds. The term on\n",
      "the righ t is the lik eliho o d ratio, also called the Ba y es factor .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 62}\n",
      "------------------------\n",
      "page_content='46 Chapter 5. Odds and A ddends\n",
      "If the Ba y es factor v alue is greater than 1, that means that the data w ere more\n",
      "lik ely under A than under B . And since the o dds ratio is also greater than\n",
      "1, that means that the o dds are greater, in ligh t of the data, than they w ere\n",
      "b efore.\n",
      "If the Ba y es factor is less than 1, that means the data w ere less lik ely under\n",
      "A than under B , so the o dds in fa v or of A go do wn.\n",
      "Finally , if the Ba y es factor is exactly 1, the data are equally lik ely under either\n",
      "h yp othesis, so the o dds do not c hange.\n",
      "No w w e can get bac k to the Oliv er's blo o d problem. If Oliv er is one of the\n",
      "p eople who left blo o d at the crime scene, then he accoun ts for the `O' sample,\n",
      "so the probabilit y of the data is just the probabilit y that a random mem b er of\n",
      "the p opulation has t yp e `AB' blo o d, whic h is 1%.\n",
      "If Oliv er did not lea v e blo o d at the scene, then w e ha v e t w o samples to accoun t\n",
      "for. If w e c ho ose t w o random p eople from the p opulation, what is the c hance of\n",
      "\u001cnding one with t yp e `O' and one with t yp e `AB' ? W ell, there are t w o w a ys it\n",
      "migh t happ en: the \u001crst p erson w e c ho ose migh t ha v e t yp e `O' and the second\n",
      "`AB', or the other w a y around. So the total probabilit y is 2(0.6)(0.01) = 1.2% .\n",
      "The lik eliho o d of the data is sligh tly higher if Oliv er is not one of the p eople\n",
      "who left blo o d at the scene, so the blo o d data is actually evidence against\n",
      "Oliv er's guilt.\n",
      "This example is a little con triv ed, but it is an example of the coun terin tuitiv e\n",
      "result that data c onsistent with a h yp othesis are not necessarily in favor of\n",
      "the h yp othesis.\n",
      "If this result is so coun terin tuitiv e that it b others y ou, this w a y of thinking\n",
      "migh t help: the data consist of a common ev en t, t yp e `O' blo o d, and a rare\n",
      "ev en t, t yp e `AB' blo o d. If Oliv er accoun ts for the common ev en t, that lea v es\n",
      "the rare ev en t still unexplained. If Oliv er do esn't accoun t for the `O' blo o d,\n",
      "then w e ha v e t w o c hances to \u001cnd someone in the p opulation with `AB' blo o d.\n",
      "And that factor of t w o mak es the di\u001berence.\n",
      "5.4 A ddends\n",
      "The fundamen tal op eration of Ba y esian statistics is Update , whic h tak es a\n",
      "prior distribution and a set of data, and pro duces a p osterior distribution. But\n",
      "solving real problems usually in v olv es a n um b er of other op erations, including\n",
      "scaling, addition and other arithmetic op erations, max and min, and mixtures.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 63}\n",
      "------------------------\n",
      "page_content='5.4. A ddends 47\n",
      "This c hapter presen ts addition and max; I will presen t other op erations as w e\n",
      "need them.\n",
      "The \u001crst example is based on Dunge ons & Dr agons , a role-pla ying game\n",
      "where the results of pla y ers' decisions are usually determined b y rolling\n",
      "dice. In fact, b efore game pla y starts, pla y ers generate eac h attribute of\n",
      "their c haracters\u0016strength, in telligence, wisdom, dexterit y , constitution, and\n",
      "c harisma\u0016b y rolling three 6-sided dice and adding them up.\n",
      "So y ou migh t b e curious to kno w the distribution of this sum. There are t w o\n",
      "w a ys y ou migh t compute it:\n",
      "Sim ulation: Giv en a Pmf that represen ts the distribution for a single die, y ou\n",
      "can dra w random samples, add them up, and accum ulate the distribution\n",
      "of sim ulated sums.\n",
      "En umeration: Giv en t w o Pmfs, y ou can en umerate all p ossible pairs of v alues\n",
      "and compute the distribution of the sums.\n",
      "thinkbayes pro vides functions for b oth. Here's an example of the \u001crst ap-\n",
      "proac h. First, I'll de\u001cne a class to represen t a single die as a Pmf:\n",
      "class Die(thinkbayes.Pmf):\n",
      "def __init__(self, sides):\n",
      "thinkbayes.Pmf.__init__(self)\n",
      "for x in xrange(1, sides+1):\n",
      "self.Set(x, 1)\n",
      "self.Normalize()\n",
      "No w I can create a 6-sided die:\n",
      "d6 = Die(6)\n",
      "And use thinkbayes.SampleSum to generate a sample of 1000 rolls.\n",
      "dice = [d6] * 3\n",
      "three = thinkbayes.SampleSum(dice, 1000)\n",
      "SampleSum tak es list of distributions (either Pmf or Cdf ob jects) and the sam-\n",
      "ple size, n . It generates n random sums and returns their distribution as a\n",
      "Pmf ob ject.\n",
      "def SampleSum(dists, n):\n",
      "pmf = MakePmfFromList(RandomSum(dists) for i in xrange(n))\n",
      "return pmf\n",
      "SampleSum uses RandomSum , also in thinkbayes.py :' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 64}\n",
      "------------------------\n",
      "page_content='48 Chapter 5. Odds and A ddends\n",
      "def RandomSum(dists):\n",
      "total = sum(dist.Random() for dist in dists)\n",
      "return total\n",
      "RandomSum in v ok es Random on eac h distribution and adds up the results.\n",
      "The dra wbac k of sim ulation is that the result is only appro ximately correct.\n",
      "As n gets larger, it gets more accurate, but of course the run time increases as\n",
      "w ell.\n",
      "The other approac h is to en umerate all pairs of v alues and compute the sum\n",
      "and probabilit y of eac h pair. This is implemen ted in Pmf.__add__ :\n",
      "# class Pmf\n",
      "def __add__(self, other):\n",
      "pmf = Pmf()\n",
      "for v1, p1 in self.Items():\n",
      "for v2, p2 in other.Items():\n",
      "pmf.Incr(v1+v2, p1*p2)\n",
      "return pmf\n",
      "self is a Pmf, of course; other can b e a Pmf or an ything else that pro-\n",
      "vides Items . The result is a new Pmf. The time to run __add__ dep ends on\n",
      "the n um b er of items in self and other ; it is prop ortional to len(self) *\n",
      "len(other) .\n",
      "And here's ho w it's used:\n",
      "three_exact = d6 + d6 + d6\n",
      "When y ou apply the + op erator to a Pmf, Python in v ok es __add__ . In this\n",
      "example, __add__ is in v ok ed t wice.\n",
      "Figure 5.1 sho ws an appro ximate result generated b y sim ulation and the exact\n",
      "result computed b y en umeration.\n",
      "Pmf.__add__ is based on the assumption that the random selections from eac h\n",
      "Pmf are indep enden t. In the example of rolling sev eral dice, this assumption\n",
      "is prett y go o d. In other cases, w e w ould ha v e to extend this metho d to use\n",
      "conditional probabilities.\n",
      "The co de from this section is a v ailable from http://thinkbayes.com/\n",
      "dungeons.py . F or more information see Section 0.3.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 65}\n",
      "------------------------\n",
      "page_content='5.5. Maxima 49\n",
      "2 4 6 8 10 12 14 16 18\n",
      "Sum of three d60.000.020.040.060.080.100.120.14Probabilitysample\n",
      "exact\n",
      "Figure 5.1: Appro ximate and exact distributions for the sum of three 6-sided\n",
      "dice.\n",
      "2 4 6 8 10 12 14 16 18\n",
      "Sum of three d60.000.050.100.150.20Probability\n",
      "Figure 5.2: Distribution of the maxim um of six rolls of three dice.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 66}\n",
      "------------------------\n",
      "page_content='50 Chapter 5. Odds and A ddends\n",
      "5.5 Maxima\n",
      "When y ou generate a Dunge ons & Dr agons c haracter, y ou are particularly\n",
      "in terested in the c haracter's b est attributes, so y ou migh t lik e to kno w the\n",
      "distribution of the maxim um attribute.\n",
      "There are three w a ys to compute the distribution of a maxim um:\n",
      "Sim ulation: Giv en a Pmf that represen ts the distribution for a single selec-\n",
      "tion, y ou can generate random samples, \u001cnd the maxim um, and accu-\n",
      "m ulate the distribution of sim ulated maxima.\n",
      "En umeration: Giv en t w o Pmfs, y ou can en umerate all p ossible pairs of v alues\n",
      "and compute the distribution of the maxim um.\n",
      "Exp onen tiation: If w e con v ert a Pmf to a Cdf, there is a simple and e\u001ecien t\n",
      "algorithm for \u001cnding the Cdf of the maxim um.\n",
      "The co de to sim ulate maxima is almost iden tical to the co de for sim ulating\n",
      "sums:\n",
      "def RandomMax(dists):\n",
      "total = max(dist.Random() for dist in dists)\n",
      "return total\n",
      "def SampleMax(dists, n):\n",
      "pmf = MakePmfFromList(RandomMax(dists) for i in xrange(n))\n",
      "return pmf\n",
      "All I did w as replace \u0010sum\u0011 with \u0010max\u0011. And the co de for en umeration is\n",
      "almost iden tical, to o:\n",
      "def PmfMax(pmf1, pmf2):\n",
      "res = thinkbayes.Pmf()\n",
      "for v1, p1 in pmf1.Items():\n",
      "for v2, p2 in pmf2.Items():\n",
      "res.Incr(max(v1, v2), p1*p2)\n",
      "return res\n",
      "In fact, y ou could generalize this function b y taking the appropriate op erator\n",
      "as a parameter.\n",
      "The only problem with this algorithm is that if eac h Pmf has m v alues, the\n",
      "run time is prop ortional to m2. And if w e w an t the maxim um of k selections,\n",
      "it tak es time prop ortional to km2.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 67}\n",
      "------------------------\n",
      "page_content='5.5. Maxima 51\n",
      "If w e con v ert the Pmfs to Cdfs, w e can do the same calculation m uc h faster!\n",
      "The k ey is to remem b er the de\u001cnition of the cum ulativ e distribution function:\n",
      "CDF (x) = p(X≤x)\n",
      "whereX is a random v ariable that means \u0010a v alue c hosen randomly from this\n",
      "distribution.\u0011 So, for example, CDF (5) is the probabilit y that a v alue from\n",
      "this distribution is less than or equal to 5.\n",
      "If I dra wX fromCDF 1 andY fromCDF 2 , and compute the maxim um Z=\n",
      "max(X,Y ) , what is the c hance that Z is less than or equal to 5? W ell, in that\n",
      "case b othX andY m ust b e less than or equal to 5.\n",
      "If the selections of X andY are indep enden t,\n",
      "CDF 3(5) =CDF 1(5)CDF 2(5)\n",
      "whereCDF 3 is the distribution of Z . I c hose the v alue 5 b ecause I think it\n",
      "mak es the form ulas easy to read, but w e can generalize for an y v alue of z :\n",
      "CDF 3(z) =CDF 1(z)CDF 2(z)\n",
      "In the sp ecial case where w e dra w k v alues from the same distribution,\n",
      "CDFk(z) =CDF 1(z)k\n",
      "So to \u001cnd the distribution of the maxim um of k v alues, w e can en umerate the\n",
      "probabilities in the giv en Cdf and raise them to the k th p o w er. Cdf pro vides\n",
      "a metho d that do es just that:\n",
      "# class Cdf\n",
      "def Max(self, k):\n",
      "cdf = self.Copy()\n",
      "cdf.ps = [p**k for p in cdf.ps]\n",
      "return cdf\n",
      "Max tak es the n um b er of selections, k , and returns a new Cdf that represen ts\n",
      "the distribution of the maxim um of k selections. The run time for this metho d\n",
      "is prop ortional to m , the n um b er of items in the Cdf.\n",
      "Pmf.Max do es the same thing for Pmfs. It has to do a little more w ork to\n",
      "con v ert the Pmf to a Cdf, so the run time is prop ortional to mlogm , but\n",
      "that's still b etter than quadratic.\n",
      "Finally , here's an example that computes the distribution of a c haracter's b est\n",
      "attribute:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 68}\n",
      "------------------------\n",
      "page_content='52 Chapter 5. Odds and A ddends\n",
      "0 5 10 15 20 25\n",
      "Outcome0.000.020.040.060.080.100.120.140.160.18Probabilitymix\n",
      "Figure 5.3: Distribution outcome for random die from a b o x.\n",
      "best_attr_cdf = three_exact.Max(6)\n",
      "best_attr_pmf = best_attr_cdf.MakePmf()\n",
      "Where three_exact is de\u001cned in the previous section. If w e prin t the results,\n",
      "w e see that the c hance of generating a c haracter with at least one attribute of\n",
      "18 is ab out 3%. Figure 5.2 sho ws the distribution.\n",
      "5.6 Mixtures\n",
      "Let's do one more example from Dunge ons & Dr agons . Supp ose I ha v e a b o x\n",
      "of dice with the follo wing in v en tory:\n",
      "5 4-sided dice\n",
      "4 6-sided dice\n",
      "3 8-sided dice\n",
      "2 12-sided dice\n",
      "1 20-sided die\n",
      "I c ho ose a die from the b o x and roll it. What is the distribution of the outcome?\n",
      "If y ou kno w whic h die it is, the answ er is easy . A die with n sides yields a\n",
      "uniform distribution from 1 to n , including b oth.\n",
      "But if w e don't kno w whic h die it is, the resulting distribution is a mixture\n",
      "of uniform distributions with di\u001beren t b ounds. In general, this kind of mix-\n",
      "ture do es not \u001ct an y simple mathematical mo del, but it is straigh tforw ard to\n",
      "compute the distribution in the form of a PMF.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 69}\n",
      "------------------------\n",
      "page_content='5.6. Mixtures 53\n",
      "As alw a ys, one option is to sim ulate the scenario, generate a random sample,\n",
      "and compute the PMF of the sample. This approac h is simple and it generates\n",
      "an appro ximate solution quic kly . But if w e w an t an exact solution, w e need a\n",
      "di\u001beren t approac h.\n",
      "Let's start with a simple v ersion of the problem where there are only t w o dice,\n",
      "one with 6 sides and one with 8. W e can mak e a Pmf to represen t eac h die:\n",
      "d6 = Die(6)\n",
      "d8 = Die(8)\n",
      "Then w e create a Pmf to represen t the mixture:\n",
      "mix = thinkbayes.Pmf()\n",
      "for die in [d6, d8]:\n",
      "for outcome, prob in die.Items():\n",
      "mix.Incr(outcome, prob)\n",
      "mix.Normalize()\n",
      "The \u001crst lo op en umerates the dice; the second en umerates the outcomes and\n",
      "their probabilities. Inside the lo op, Pmf.Incr adds up the con tributions from\n",
      "the t w o distributions.\n",
      "This co de assumes that the t w o dice are equally lik ely . More generally , w e need\n",
      "to kno w the probabilit y of eac h die so w e can w eigh t the outcomes accordingly .\n",
      "First w e create a Pmf that maps from eac h die to the probabilit y it is selected:\n",
      "pmf_dice = thinkbayes.Pmf()\n",
      "pmf_dice.Set(Die(4), 5)\n",
      "pmf_dice.Set(Die(6), 4)\n",
      "pmf_dice.Set(Die(8), 3)\n",
      "pmf_dice.Set(Die(12), 2)\n",
      "pmf_dice.Set(Die(20), 1)\n",
      "pmf_dice.Normalize()\n",
      "Next w e need a more general v ersion of the mixture algorithm:\n",
      "mix = thinkbayes.Pmf()\n",
      "for die, weight in pmf_dice.Items():\n",
      "for outcome, prob in die.Items():\n",
      "mix.Incr(outcome, weight*prob)\n",
      "No w eac h die has a w eigh t asso ciated with it (whic h mak es it a w eigh ted die,\n",
      "I supp ose). When w e add eac h outcome to the mixture, its probabilit y is\n",
      "m ultiplied b y weight .\n",
      "Figure 5.3 sho ws the result. As exp ected, v alues 1 through 4 are the most lik ely\n",
      "b ecause an y die can pro duce them. V alues ab o v e 12 are unlik ely b ecause there' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 70}\n",
      "------------------------\n",
      "page_content='54 Chapter 5. Odds and A ddends\n",
      "is only one die in the b o x that can pro duce them (and it do es so less than half\n",
      "the time).\n",
      "thinkbayes pro vides a function named MakeMixture that encapsulates this\n",
      "algorithm, so w e could ha v e written:\n",
      "mix = thinkbayes.MakeMixture(pmf_dice)\n",
      "W e'll use MakeMixture again in Chapters 7 and 8.\n",
      "5.7 Discussion\n",
      "Other than the o dds form of Ba y es's theorem, this c hapter is not sp eci\u001ccally\n",
      "Ba y esian. But Ba y esian analysis is all ab out distributions, so it is imp ortan t\n",
      "to understand the concept of a distribution w ell. F rom a computational p oin t\n",
      "of view, a distribution is an y data structure that represen ts a set of v alues\n",
      "(p ossible outcomes of a random pro cess) and their probabilities.\n",
      "W e ha v e seen t w o represen tations of distributions: Pmfs and Cdfs. These\n",
      "represen tations are equiv alen t in the sense that they con tain the same infor-\n",
      "mation, so y ou can con v ert from one to the other. The primary di\u001berence\n",
      "b et w een them is p erformance: some op erations are faster and easier with a\n",
      "Pmf; others are faster with a Cdf.\n",
      "The other goal of this c hapter is to in tro duce op erations that act on distri-\n",
      "butions, lik e Pmf.__add__ , Cdf.Max , and thinkbayes.MakeMixture . W e will\n",
      "use these op erations later, but I in tro duce them no w to encourage y ou to think\n",
      "of a distribution as a fundamen tal unit of computation, not just a con tainer\n",
      "for v alues and probabilities.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 71}\n",
      "------------------------\n",
      "page_content='Chapter 6\n",
      "Decision Analysis\n",
      "6.1 The Pric e is R ight problem\n",
      "On No v em b er 1, 2007, con testan ts named Letia and Nathaniel app eared on\n",
      "The Pric e is R ight , an American game sho w. They comp eted in a game called\n",
      "The Showc ase , where the ob jectiv e is to guess the price of a sho w case of prizes.\n",
      "The con testan t who comes closest to the actual price of the sho w case, without\n",
      "going o v er, wins the prizes.\n",
      "Nathaniel w en t \u001crst. His sho w case included a dish w asher, a wine cabinet, a\n",
      "laptop computer, and a car. He bid $26,000.\n",
      "Letia's sho w case included a pin ball mac hine, a video arcade game, a p o ol table,\n",
      "and a cruise of the Bahamas. She bid $21,500.\n",
      "The actual price of Nathaniel's sho w case w as $25,347. His bid w as to o high,\n",
      "so he lost.\n",
      "The actual price of Letia's sho w case w as $21,578. She w as only o\u001b b y $78, so\n",
      "she w on her sho w case and, b ecause her bid w as o\u001b b y less than $250, she also\n",
      "w on Nathaniel's sho w case.\n",
      "F or a Ba y esian think er, this scenario suggests sev eral questions:\n",
      "1. Before seeing the prizes, what prior b eliefs should the con testan t ha v e\n",
      "ab out the price of the sho w case?\n",
      "2. After seeing the prizes, ho w should the con testan t up date those b eliefs?\n",
      "3. Based on the p osterior distribution, what should the con testan t bid?' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 72}\n",
      "------------------------\n",
      "page_content='56 Chapter 6. Decision Analysis\n",
      "0 10000 20000 30000 40000 50000 60000 70000 80000\n",
      "price ($)0.000.010.020.030.040.05PDFshowcase 1\n",
      "showcase 2\n",
      "Figure 6.1: Distribution of prices for sho w cases on The Pric e is R ight , 2011-12.\n",
      "The third question demonstrates a common use of Ba y esian analysis: decision\n",
      "analysis. Giv en a p osterior distribution, w e can c ho ose the bid that maximizes\n",
      "the con testan t's exp ected return.\n",
      "This problem is inspired b y an example in Cameron Da vidson-Pilon's b o ok,\n",
      "Bayesian Metho ds for Hackers . The co de I wrote for this c hapter is a v ail-\n",
      "able from http://thinkbayes.com/price.py ; it reads data \u001cles y ou can\n",
      "do wnload from http://thinkbayes.com/showcases.2011.csv and http:\n",
      "//thinkbayes.com/showcases.2012.csv . F or more information see Sec-\n",
      "tion 0.3.\n",
      "6.2 The prior\n",
      "T o c ho ose a prior distribution of prices, w e can tak e adv an tage of data from\n",
      "previous episo des. F ortunately , fans of the sho w k eep detailed records. When\n",
      "I corresp onded with Mr. Da vidson-Pilon ab out his b o ok, he sen t me data\n",
      "collected b y Stev e Gee at http://tpirsummaries.8m.com . It includes the\n",
      "price of eac h sho w case from the 2011 and 2012 seasons and the bids o\u001bered b y\n",
      "the con testan ts.\n",
      "Figure 6.1 sho ws the distribution of prices for these sho w cases. The most\n",
      "common v alue for b oth sho w cases is around $28,000, but the \u001crst sho w case\n",
      "has a second mo de near $50,000, and the second sho w case is o ccasionally w orth\n",
      "more than $70,000.\n",
      "These distributions are based on actual data, but they ha v e b een smo othed' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 73}\n",
      "------------------------\n",
      "page_content='6.3. Probabilit y densit y functions 57\n",
      "b y Gaussian k ernel densit y estimation (KDE). Before w e go on, I w an t to tak e\n",
      "a detour to talk ab out probabilit y densit y functions and KDE.\n",
      "6.3 Probabilit y densit y functions\n",
      "So far w e ha v e b een w orking with probabilit y mass functions, or PMF s. A PMF\n",
      "is a map from eac h p ossible v alue to its probabilit y . In m y implemen tation, a\n",
      "Pmf ob ject pro vides a metho d named Prob that tak es a v alue and returns a\n",
      "probabilit y , also kno wn as a probabilit y mass .\n",
      "A probabilit y densit y function , or PDF, is the con tin uous v ersion of a\n",
      "PMF, where the p ossible v alues mak e up a con tin uous range rather than a\n",
      "discrete set.\n",
      "In mathematical notation, PDF s are usually written as functions; for example,\n",
      "here is the PDF of a Gaussian distribution with mean 0 and standard deviation\n",
      "1:\n",
      "f(x) =1√\n",
      "2πexp(−x2/2)\n",
      "F or a giv en v alue of x , this function computes a probabilit y densit y . A densit y\n",
      "is similar to a probabilit y mass in the sense that a higher densit y indicates\n",
      "that a v alue is more lik ely .\n",
      "But a densit y is not a probabilit y . A densit y can b e 0 or an y p ositiv e v alue; it\n",
      "is not b ounded, lik e a probabilit y , b et w een 0 and 1.\n",
      "If y ou in tegrate a densit y o v er a con tin uous range, the result is a probabilit y .\n",
      "But for the applications in this b o ok w e seldom ha v e to do that.\n",
      "Instead w e primarily use probabilit y densities as part of a lik eliho o d function.\n",
      "W e will see an example so on.\n",
      "6.4 Represen ting PDF s\n",
      "T o represen t PDF s in Python, thinkbayes.py pro vides a class named Pdf .\n",
      "Pdf is an abstract t yp e , whic h means that it de\u001cnes the in terface a Pdf is\n",
      "supp osed to ha v e, but do es not pro vide a complete implemen tation. The Pdf\n",
      "in terface includes t w o metho ds, Density and MakePmf :\n",
      "class Pdf(object):\n",
      "def Density(self, x):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 74}\n",
      "------------------------\n",
      "page_content='58 Chapter 6. Decision Analysis\n",
      "raise UnimplementedMethodException()\n",
      "def MakePmf(self, xs):\n",
      "pmf = Pmf()\n",
      "for x in xs:\n",
      "pmf.Set(x, self.Density(x))\n",
      "pmf.Normalize()\n",
      "return pmf\n",
      "Density tak es a v alue, x , and returns the corresp onding densit y . MakePmf\n",
      "mak es a discrete appro ximation to the PDF.\n",
      "Pdf pro vides an implemen tation of MakePmf , but not Density , whic h has to\n",
      "b e pro vided b y a c hild class.\n",
      "A concrete t yp e is a c hild class that extends an abstract t yp e and pro vides an\n",
      "implemen tation of the missing metho ds. F or example, GaussianPdf extends\n",
      "Pdf and pro vides Density :\n",
      "class GaussianPdf(Pdf):\n",
      "def __init__(self, mu, sigma):\n",
      "self.mu = mu\n",
      "self.sigma = sigma\n",
      "def Density(self, x):\n",
      "return scipy.stats.norm.pdf(x, self.mu, self.sigma)\n",
      "__init__ tak es mu and sigma , whic h are the mean and standard deviation of\n",
      "the distribution, and stores them as attributes.\n",
      "Density uses a function from scipy.stats to ev aluate the Gaussian PDF. The\n",
      "function is called norm.pdf b ecause the Gaussian distribution is also called the\n",
      "\u0010normal\u0011 distribution.\n",
      "The Gaussian PDF is de\u001cned b y a simple mathematical function, so it is easy\n",
      "to ev aluate. And it is useful b ecause man y quan tities in the real w orld ha v e\n",
      "distributions that are appro ximately Gaussian.\n",
      "But with real data, there is no guaran tee that the distribution is Gaussian or\n",
      "an y other simple mathematical function. In that case w e can use a sample to\n",
      "estimate the PDF of the whole p opulation.\n",
      "F or example, in The Pric e Is R ight data, w e ha v e 313 prices for the \u001crst\n",
      "sho w case. W e can think of these v alues as a sample from the p opulation of all\n",
      "p ossible sho w case prices.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 75}\n",
      "------------------------\n",
      "page_content='6.4. Represen ting PDF s 59\n",
      "This sample includes the follo wing v alues (in order):\n",
      "28800,28868,28941,28957,28958\n",
      "In the sample, no v alues app ear b et w een 28801 and 28867, but there is no\n",
      "reason to think that these v alues are imp ossible. Based on our bac kground\n",
      "information, w e exp ect all v alues in this range to b e equally lik ely . In other\n",
      "w ords, w e exp ect the PDF to b e fairly smo oth.\n",
      "Kernel densit y estimation (KDE) is an algorithm that tak es a sample and\n",
      "\u001cnds an appropriately smo oth PDF that \u001cts the data. Y ou can read details\n",
      "at http://en.wikipedia.org/wiki/Kernel_density_estimation .\n",
      "scipy pro vides an implemen tation of KDE and thinkbayes pro vides a class\n",
      "called EstimatedPdf that uses it:\n",
      "class EstimatedPdf(Pdf):\n",
      "def __init__(self, sample):\n",
      "self.kde = scipy.stats.gaussian_kde(sample)\n",
      "def Density(self, x):\n",
      "return self.kde.evaluate(x)\n",
      "__init__ tak es a sample and computes a k ernel densit y estimate. The result\n",
      "is a gaussian_kde ob ject that pro vides an evaluate metho d.\n",
      "Density tak es a v alue, calls gaussian_kde.evaluate , and returns the result-\n",
      "ing densit y .\n",
      "Finally , here's an outline of the co de I used to generate Figure 6.1:\n",
      "prices = ReadData()\n",
      "pdf = thinkbayes.EstimatedPdf(prices)\n",
      "low, high = 0, 75000\n",
      "n = 101\n",
      "xs = numpy.linspace(low, high, n)\n",
      "pmf = pdf.MakePmf(xs)\n",
      "pdf is a Pdf ob ject, estimated b y KDE. pmf is a Pmf ob ject that appro ximates\n",
      "the Pdf b y ev aluating the densit y at a sequence of equally spaced v alues.\n",
      "linspace stands for \u0010linear space.\u0011 It tak es a range, low and high , and the\n",
      "n um b er of p oin ts, n , and returns a new numpy arra y with n elemen ts equally\n",
      "spaced b et w een low and high , including b oth.\n",
      "And no w bac k to The Pric e is R ight .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 76}\n",
      "------------------------\n",
      "page_content='60 Chapter 6. Decision Analysis\n",
      "30000\n",
      " 20000\n",
      " 10000\n",
      " 0 10000 20000 30000 40000 50000\n",
      "diff ($)0.00.20.40.60.81.0CDFplayer 1\n",
      "player 2\n",
      "Figure 6.2: Cum ulativ e distribution (CDF) of the di\u001berence b et w een the con-\n",
      "testan t's bid and the actual price.\n",
      "6.5 Mo deling the con testan ts\n",
      "The PDF s in Figure 6.1 estimate the distribution of p ossible prices. If y ou\n",
      "w ere a con testan t on the sho w, y ou could use this distribution to quan tify\n",
      "y our prior b elief ab out the price of eac h sho w case (b efore y ou see the prizes).\n",
      "T o up date these priors, w e ha v e to answ er these questions:\n",
      "1. What data should w e consider and ho w should w e quan tify it?\n",
      "2. Can w e compute a lik eliho o d function; that is, for eac h h yp othetical\n",
      "v alue of price , can w e compute the conditional lik eliho o d of the data?\n",
      "T o answ er these questions, I am going to mo del the con testan t as a price-\n",
      "guessing instrumen t with kno wn error c haracteristics. In other w ords, when\n",
      "the con testan t sees the prizes, he or she guesses the price of eac h prize\u0016\n",
      "ideally without taking in to consideration the fact that the prize is part of a\n",
      "sho w case\u0016and adds up the prices. Let's call this total guess .\n",
      "Under this mo del, the question w e ha v e to answ er is, \u0010If the actual price is\n",
      "price , what is the lik eliho o d that the con testan t's estimate w ould b e guess ?\u0011\n",
      "Or if w e de\u001cne\n",
      "error = price - guess' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 77}\n",
      "------------------------\n",
      "page_content='6.5. Mo deling the con testan ts 61\n",
      "then w e could ask, \u0010What is the lik eliho o d that the con testan t's estimate is o\u001b\n",
      "b y error ?\u0011\n",
      "T o answ er this question, w e can use the historical data again. Figure 6.2 sho ws\n",
      "the cum ulativ e distribution of diff , the di\u001berence b et w een the con testan t's bid\n",
      "and the actual price of the sho w case.\n",
      "The de\u001cnition of di\u001b is\n",
      "diff = price - bid\n",
      "When diff is negativ e, the bid is to o high. As an aside, w e can use this\n",
      "distribution to compute the probabilit y that the con testan ts o v erbid: the \u001crst\n",
      "con testan t o v erbids 25% of the time; the second con testan t o v erbids 29% of\n",
      "the time.\n",
      "W e can also see that the bids are biased; that is, they are more lik ely to b e\n",
      "to o lo w than to o high. And that mak es sense, giv en the rules of the game.\n",
      "Finally , w e can use this distribution to estimate the reliabilit y of the con tes-\n",
      "tan ts' guesses. This step is a little tric ky b ecause w e don't actually kno w the\n",
      "con testan t's guesses; w e only kno w what they bid.\n",
      "So w e'll ha v e to mak e some assumptions. Sp eci\u001ccally , I assume that the dis-\n",
      "tribution of error is Gaussian with mean 0 and the same v ariance as diff .\n",
      "The Player class implemen ts this mo del:\n",
      "class Player(object):\n",
      "def __init__(self, prices, bids, diffs):\n",
      "self.pdf_price = thinkbayes.EstimatedPdf(prices)\n",
      "self.cdf_diff = thinkbayes.MakeCdfFromList(diffs)\n",
      "mu = 0\n",
      "sigma = numpy.std(diffs)\n",
      "self.pdf_error = thinkbayes.GaussianPdf(mu, sigma)\n",
      "prices is a sequence of sho w case prices, bids is a sequence of bids, and diffs\n",
      "is a sequence of di\u001bs, where again diff = price - bid .\n",
      "pdf_price is the smo othed PDF of prices, estimated b y KDE. cdf_diff is the\n",
      "cum ulativ e distribution of diff , whic h w e sa w in Figure 6.2. And pdf_error\n",
      "is the PDF that c haracterizes the distribution of errors; where error = price\n",
      "- guess .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 78}\n",
      "------------------------\n",
      "page_content='62 Chapter 6. Decision Analysis\n",
      "Again, w e use the v ariance of diff to estimate the v ariance of error . This\n",
      "estimate is not p erfect b ecause con testan ts' bids are sometimes strategic; for\n",
      "example, if Pla y er 2 thinks that Pla y er 1 has o v erbid, Pla y er 2 migh t mak e\n",
      "a v ery lo w bid. In that case diff do es not re\u001dect error . If this happ ens a\n",
      "lot, the observ ed v ariance in diff migh t o v erestimate the v ariance in error .\n",
      "Nev ertheless, I think it is a reasonable mo deling decision.\n",
      "As an alternativ e, someone preparing to app ear on the sho w could estimate\n",
      "their o wn distribution of error b y w atc hing previous sho ws and recording\n",
      "their guesses and the actual prices.\n",
      "6.6 Lik eliho o d\n",
      "No w w e are ready to write the lik eliho o d function. As usual, I de\u001cne a new\n",
      "class that extends thinkbayes.Suite :\n",
      "class Price(thinkbayes.Suite):\n",
      "def __init__(self, pmf, player):\n",
      "thinkbayes.Suite.__init__(self, pmf)\n",
      "self.player = player\n",
      "pmf represen ts the prior distribution and player is a Pla y er ob ject as describ ed\n",
      "in the previous section. Here's Likelihood :\n",
      "def Likelihood(self, data, hypo):\n",
      "price = hypo\n",
      "guess = data\n",
      "error = price - guess\n",
      "like = self.player.ErrorDensity(error)\n",
      "return like\n",
      "hypo is the h yp othetical price of the sho w case. data is the con testan t's b est\n",
      "guess at the price. error is the di\u001berence, and like is the lik eliho o d of the\n",
      "data, giv en the h yp othesis.\n",
      "ErrorDensity is de\u001cned in Player :\n",
      "# class Player:\n",
      "def ErrorDensity(self, error):\n",
      "return self.pdf_error.Density(error)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 79}\n",
      "------------------------\n",
      "page_content='6.7. Up date 63\n",
      "0 10000 20000 30000 40000 50000 60000 70000 80000\n",
      "price ($)0.000.010.020.030.040.050.060.070.08PMFprior\n",
      "posterior\n",
      "Figure 6.3: Prior and p osterior distributions for Pla y er 1, based on a b est\n",
      "guess of $20,000.\n",
      "ErrorDensity w orks b y ev aluating pdf_error at the giv en v alue of error .\n",
      "The result is a probabilit y densit y , so it is not really a probabilit y . But re-\n",
      "mem b er that Likelihood do esn't need to compute a probabilit y; it only has\n",
      "to compute something pr op ortional to a probabilit y . As long as the constan t\n",
      "of prop ortionalit y is the same for all lik eliho o ds, it gets canceled out when w e\n",
      "normalize the p osterior distribution.\n",
      "And therefore, a probabilit y densit y is a p erfectly go o d lik eliho o d.\n",
      "6.7 Up date\n",
      "Player pro vides a metho d that tak es the con testan t's guess and computes the\n",
      "p osterior distribution:\n",
      "# class Player\n",
      "def MakeBeliefs(self, guess):\n",
      "pmf = self.PmfPrice()\n",
      "self.prior = Price(pmf, self)\n",
      "self.posterior = self.prior.Copy()\n",
      "self.posterior.Update(guess)\n",
      "PmfPrice generates a discrete appro ximation to the PDF of price, whic h w e\n",
      "use to construct the prior.\n",
      "PmfPrice uses MakePmf , whic h ev aluates pdf_price at a sequence of v alues:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 80}\n",
      "------------------------\n",
      "page_content='64 Chapter 6. Decision Analysis\n",
      "# class Player\n",
      "n = 101\n",
      "price_xs = numpy.linspace(0, 75000, n)\n",
      "def PmfPrice(self):\n",
      "return self.pdf_price.MakePmf(self.price_xs)\n",
      "T o construct the p osterior, w e mak e a cop y of the prior and then in v ok e Update ,\n",
      "whic h in v ok es Likelihood for eac h h yp othesis, m ultiplies the priors b y the\n",
      "lik eliho o ds, and renormalizes.\n",
      "So let's get bac k to the original scenario. Supp ose y ou are Pla y er 1 and when\n",
      "y ou see y our sho w case, y our b est guess is that the total price of the prizes is\n",
      "$20,000.\n",
      "Figure 6.3 sho ws prior and p osterior b eliefs ab out the actual price. The p os-\n",
      "terior is shifted to the left b ecause y our guess is on the lo w end of the prior\n",
      "range.\n",
      "On one lev el, this result mak es sense. The most lik ely v alue in the prior is\n",
      "$27,750, y our b est guess is $20,000, and the mean of the p osterior is somewhere\n",
      "in b et w een: $25,096.\n",
      "On another lev el, y ou migh t \u001cnd this result bizarre, b ecause it suggests that\n",
      "if y ou think the price is $20,000, then y ou should b elieve the price is $24,000.\n",
      "T o resolv e this apparen t parado x, remem b er that y ou are com bining t w o\n",
      "sources of information, historical data ab out past sho w cases and guesses ab out\n",
      "the prizes y ou see.\n",
      "W e are treating the historical data as the prior and up dating it based on y our\n",
      "guesses, but w e could equiv alen tly use y our guess as a prior and up date it\n",
      "based on historical data.\n",
      "If y ou think of it that w a y , ma yb e it is less surprising that the most lik ely\n",
      "v alue in the p osterior is not y our original guess.\n",
      "6.8 Optimal bidding\n",
      "No w that w e ha v e a p osterior distribution, w e can use it to compute the\n",
      "optimal bid, whic h I de\u001cne as the bid that maximizes exp ected return (see\n",
      "http://en.wikipedia.org/wiki/Expected_return ).' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 81}\n",
      "------------------------\n",
      "page_content='6.8. Optimal bidding 65\n",
      "I'm going to presen t the metho ds in this section top-do wn, whic h means I will\n",
      "sho w y ou ho w they are used b efore I sho w y ou ho w they w ork. If y ou see an\n",
      "unfamiliar metho d, don't w orry; the de\u001cnition will b e along shortly .\n",
      "T o compute optimal bids, I wrote a class called GainCalculator :\n",
      "class GainCalculator(object):\n",
      "def __init__(self, player, opponent):\n",
      "self.player = player\n",
      "self.opponent = opponent\n",
      "player and opponent are Player ob jects.\n",
      "GainCalculator pro vides ExpectedGains , whic h computes a sequence of bids\n",
      "and the exp ected gain for eac h bid:\n",
      "def ExpectedGains(self, low=0, high=75000, n=101):\n",
      "bids = numpy.linspace(low, high, n)\n",
      "gains = [self.ExpectedGain(bid) for bid in bids]\n",
      "return bids, gains\n",
      "low and high sp ecify the range of p ossible bids; n is the n um b er of bids to try .\n",
      "ExpectedGains calls ExpectedGain , whic h computes exp ected gain for a giv en\n",
      "bid:\n",
      "def ExpectedGain(self, bid):\n",
      "suite = self.player.posterior\n",
      "total = 0\n",
      "for price, prob in sorted(suite.Items()):\n",
      "gain = self.Gain(bid, price)\n",
      "total += prob * gain\n",
      "return total\n",
      "ExpectedGain lo ops through the v alues in the p osterior and computes the gain\n",
      "for eac h bid, giv en the actual prices of the sho w case. It w eigh ts eac h gain with\n",
      "the corresp onding probabilit y and returns the total.\n",
      "ExpectedGain in v ok es Gain , whic h tak es a bid and an actual price and returns\n",
      "the exp ected gain:\n",
      "def Gain(self, bid, price):\n",
      "if bid > price:\n",
      "return 0' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 82}\n",
      "------------------------\n",
      "page_content='66 Chapter 6. Decision Analysis\n",
      "0 10000 20000 30000 40000 50000 60000 70000 80000\n",
      "bid ($)05000100001500020000expected gain ($)Player 1\n",
      "Player 2\n",
      "Figure 6.4: Exp ected gain v ersus bid in a scenario where Pla y er 1's b est guess\n",
      "is $20,000 and Pla y er 2's b est guess is $40,000.\n",
      "diff = price - bid\n",
      "prob = self.ProbWin(diff)\n",
      "if diff <= 250:\n",
      "return 2 * price * prob\n",
      "else:\n",
      "return price * prob\n",
      "If y ou o v erbid, y ou get nothing. Otherwise w e compute the di\u001berence b et w een\n",
      "y our bid and the price, whic h determines y our probabilit y of winning.\n",
      "If diff is less than $250, y ou win b oth sho w cases. F or simplicit y , I assume\n",
      "that b oth sho w cases ha v e the same price. Since this outcome is rare, it do esn't\n",
      "mak e m uc h di\u001berence.\n",
      "Finally , w e ha v e to compute the probabilit y of winning based on diff :\n",
      "def ProbWin(self, diff):\n",
      "prob = (self.opponent.ProbOverbid() +\n",
      "self.opponent.ProbWorseThan(diff))\n",
      "return prob\n",
      "If y our opp onen t o v erbids, y ou win. Otherwise, y ou ha v e to hop e that y our\n",
      "opp onen t is o\u001b b y more than diff . Player pro vides metho ds to compute b oth\n",
      "probabilities:\n",
      "# class Player:\n",
      "def ProbOverbid(self):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 83}\n",
      "------------------------\n",
      "page_content='6.9. Discussion 67\n",
      "return self.cdf_diff.Prob(-1)\n",
      "def ProbWorseThan(self, diff):\n",
      "return 1 - self.cdf_diff.Prob(diff)\n",
      "This co de migh t b e confusing b ecause the computation is no w from the p oin t\n",
      "of view of the opp onen t, who is computing, \u0010What is the probabilit y that I\n",
      "o v erbid?\u0011 and \u0010What is the probabilit y that m y bid is o\u001b b y more than diff ?\u0011\n",
      "Both answ ers are based on the CDF of diff . If the opp onen t's diff is less\n",
      "than or equal to -1, y ou win. If the opp onen t's diff is w orse than y ours, y ou\n",
      "win. Otherwise y ou lose.\n",
      "Finally , here's the co de that computes optimal bids:\n",
      "# class Player:\n",
      "def OptimalBid(self, guess, opponent):\n",
      "self.MakeBeliefs(guess)\n",
      "calc = GainCalculator(self, opponent)\n",
      "bids, gains = calc.ExpectedGains()\n",
      "gain, bid = max(zip(gains, bids))\n",
      "return bid, gain\n",
      "Giv en a guess and an opp onen t, OptimalBid computes the p osterior distribu-\n",
      "tion, instan tiates a GainCalculator , computes exp ected gains for a range of\n",
      "bids and returns the optimal bid and exp ected gain. Whew!\n",
      "Figure 6.4 sho ws the results for b oth pla y ers, based on a scenario where Pla y er\n",
      "1's b est guess is $20,000 and Pla y er 2's b est guess is $40,000.\n",
      "F or Pla y er 1 the optimal bid is $21,000, yielding an exp ected return of almost\n",
      "$16,700. This is a case (whic h turns out to b e un usual) where the optimal bid\n",
      "is actually higher than the con testan t's b est guess.\n",
      "F or Pla y er 2 the optimal bid is $31,500, yielding an exp ected return of almost\n",
      "$19,400. This is the more t ypical case where the optimal bid is less than the\n",
      "b est guess.\n",
      "6.9 Discussion\n",
      "One of the features of Ba y esian estimation is that the result comes in the form\n",
      "of a p osterior distribution. Classical estimation usually generates a single\n",
      "p oin t estimate or a con\u001cdence in terv al, whic h is su\u001ecien t if estimation is the' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 84}\n",
      "------------------------\n",
      "page_content='68 Chapter 6. Decision Analysis\n",
      "last step in the pro cess, but if y ou w an t to use an estimate as an input to a\n",
      "subsequen t analysis, p oin t estimates and in terv als are often not m uc h help.\n",
      "In this example, w e use the p osterior distribution to compute an optimal bid.\n",
      "The return on a giv en bid is asymmetric and discon tin uous (if y ou o v erbid,\n",
      "y ou lose), so it w ould b e hard to solv e this problem analytically . But it is\n",
      "relativ ely simple to do computationally .\n",
      "New comers to Ba y esian thinking are often tempted to summarize the p oste-\n",
      "rior distribution b y computing the mean or the maxim um lik eliho o d estimate.\n",
      "These summaries can b e useful, but if that's all y ou need, then y ou probably\n",
      "don't need Ba y esian metho ds in the \u001crst place.\n",
      "Ba y esian metho ds are most useful when y ou can carry the p osterior distri-\n",
      "bution in to the next step of the analysis to p erform some kind of decision\n",
      "analysis, as w e did in this c hapter, or some kind of prediction, as w e see in the\n",
      "next c hapter.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 85}\n",
      "------------------------\n",
      "page_content='Chapter 7\n",
      "Prediction\n",
      "7.1 The Boston Bruins problem\n",
      "In the 2010-11 National Ho c k ey League (NHL) Finals, m y b elo v ed Boston Bru-\n",
      "ins pla y ed a b est-of-sev en c hampionship series against the despised V ancouv er\n",
      "Can uc ks. Boston lost the \u001crst t w o games 0-1 and 2-3, then w on the next t w o\n",
      "games 8-1 and 4-0. A t this p oin t in the series, what is the probabilit y that\n",
      "Boston will win the next game, and what is their probabilit y of winning the\n",
      "c hampionship?\n",
      "As alw a ys, to answ er a question lik e this, w e need to mak e some assumptions.\n",
      "First, it is reasonable to b eliev e that goal scoring in ho c k ey is at least appro x-\n",
      "imately a P oisson pro cess, whic h means that it is equally lik ely for a goal to\n",
      "b e scored at an y time during a game. Second, w e can assume that against a\n",
      "particular opp onen t, eac h team has some long-term a v erage goals p er game,\n",
      "denotedλ .\n",
      "Giv en these assumptions, m y strategy for answ ering this question is\n",
      "1. Use statistics from previous games to c ho ose a prior distribution for λ .\n",
      "2. Use the score from the \u001crst four games to estimate λ for eac h team.\n",
      "3. Use the p osterior distributions of λ to compute distribution of goals for\n",
      "eac h team, the distribution of the goal di\u001beren tial, and the probabilit y\n",
      "that eac h team wins the next game.\n",
      "4. Compute the probabilit y that eac h team wins the series.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 86}\n",
      "------------------------\n",
      "page_content='70 Chapter 7. Prediction\n",
      "T o c ho ose a prior distribution, I got some statistics from http://www.nhl.com ,\n",
      "sp eci\u001ccally the a v erage goals p er game for eac h team in the 2010-11 season.\n",
      "The distribution is roughly Gaussian with mean 2.8 and standard deviation\n",
      "0.3.\n",
      "The Gaussian distribution is con tin uous, but w e'll appro ximate it with a dis-\n",
      "crete Pmf. thinkbayes pro vides MakeGaussianPmf to do exactly that:\n",
      "def MakeGaussianPmf(mu, sigma, num_sigmas, n=101):\n",
      "pmf = Pmf()\n",
      "low = mu - num_sigmas*sigma\n",
      "high = mu + num_sigmas*sigma\n",
      "for x in numpy.linspace(low, high, n):\n",
      "p = scipy.stats.norm.pdf(x, mu, sigma)\n",
      "pmf.Set(x, p)\n",
      "pmf.Normalize()\n",
      "return pmf\n",
      "mu and sigma are the mean and standard deviation of the Gaussian distribu-\n",
      "tion. num_sigmas is the n um b er of standard deviations ab o v e and b elo w the\n",
      "mean that the Pmf will span, and n is the n um b er of v alues in the Pmf.\n",
      "Again w e use numpy.linspace to mak e an arra y of n equally spaced v alues\n",
      "b et w een low and high , including b oth.\n",
      "norm.pdf ev aluates the Gaussian probabilit y densit y function (PDF).\n",
      "Getting bac k to the ho c k ey problem, here's the de\u001cnition for a suite of h y-\n",
      "p otheses ab out the v alue of λ .\n",
      "class Hockey(thinkbayes.Suite):\n",
      "def __init__(self):\n",
      "pmf = thinkbayes.MakeGaussianPmf(2.7, 0.3, 4)\n",
      "thinkbayes.Suite.__init__(self, pmf)\n",
      "So the prior distribution is Gaussian with mean 2.7, standard deviation 0.3,\n",
      "and it spans 4 sigmas ab o v e and b elo w the mean.\n",
      "As alw a ys, w e ha v e to decide ho w to represen t eac h h yp othesis; in this case I\n",
      "represen t the h yp othesis that λ=x with the \u001doating-p oin t v alue x .\n",
      "7.2 P oisson pro cesses\n",
      "In mathematical statistics, a pro cess is a sto c hastic mo del of a ph ysical system\n",
      "(\u0010sto c hastic\u0011 means that the mo del has some kind of randomness in it). F or' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 87}\n",
      "------------------------\n",
      "page_content='7.3. The p osteriors 71\n",
      "example, a Bernoulli pro cess is a mo del of a sequence of ev en ts, called trials,\n",
      "in whic h eac h trial has t w o p ossible outcomes, lik e success and failure. So a\n",
      "Bernoulli pro cess is a natural mo del for a series of coin \u001dips, or a series of\n",
      "shots on goal.\n",
      "A P oisson pro cess is the con tin uous v ersion of a Bernoulli pro cess, where an\n",
      "ev en t can o ccur at an y p oin t in time with equal probabilit y . P oisson pro cesses\n",
      "can b e used to mo del customers arriving in a store, buses arriving at a bus\n",
      "stop, or goals scored in a ho c k ey game.\n",
      "In man y real systems the probabilit y of an ev en t c hanges o v er time. Customers\n",
      "are more lik ely to go to a store at certain times of da y , buses are supp osed\n",
      "to arriv e at \u001cxed in terv als, and goals are more or less lik ely at di\u001beren t times\n",
      "during a game.\n",
      "But all mo dels are based on simpli\u001ccations, and in this case mo deling a ho c k ey\n",
      "game with a P oisson pro cess is a reasonable c hoice. Heuer, Müller and Rub-\n",
      "ner (2010) analyze scoring in a German so ccer league and come to the same\n",
      "conclusion; see http://www.cimat.mx/Eventos/vpec10/img/poisson.pdf .\n",
      "The b ene\u001ct of using this mo del is that w e can compute the distribution of\n",
      "goals p er game e\u001ecien tly , as w ell as the distribution of time b et w een goals.\n",
      "Sp eci\u001ccally , if the a v erage n um b er of goals in a game is lam , the distribution\n",
      "of goals p er game is giv en b y the P oisson PMF:\n",
      "def EvalPoissonPmf(k, lam):\n",
      "return (lam)**k * math.exp(-lam) / math.factorial(k)\n",
      "And the distribution of time b et w een goals is giv en b y the exp onen tial PDF:\n",
      "def EvalExponentialPdf(x, lam):\n",
      "return lam * math.exp(-lam * x)\n",
      "I use the v ariable lam b ecause lambda is a reserv ed k eyw ord in Python. Both\n",
      "of these functions are in thinkbayes.py .\n",
      "7.3 The p osteriors\n",
      "No w w e can compute the lik eliho o d that a team with a h yp othetical v alue of\n",
      "lam scores k goals in a game:\n",
      "# class Hockey\n",
      "def Likelihood(self, data, hypo):\n",
      "lam = hypo\n",
      "k = data' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 88}\n",
      "------------------------\n",
      "page_content='72 Chapter 7. Prediction\n",
      "1.5 2.0 2.5 3.0 3.5 4.0\n",
      "Goals per game0.0000.0020.0040.0060.0080.0100.0120.0140.0160.018Probabilitybruins\n",
      "canucks\n",
      "Figure 7.1: P osterior distribution of the n um b er of goals p er game.\n",
      "like = thinkbayes.EvalPoissonPmf(k, lam)\n",
      "return like\n",
      "Eac h h yp othesis is a p ossible v alue of λ ; data is the observ ed n um b er of goals,\n",
      "k .\n",
      "With the lik eliho o d function in place, w e can mak e a suite for eac h team and\n",
      "up date them with the scores from the \u001crst four games.\n",
      "suite1 = Hockey( ' bruins ' )\n",
      "suite1.UpdateSet([0, 2, 8, 4])\n",
      "suite2 = Hockey( ' canucks ' )\n",
      "suite2.UpdateSet([1, 3, 1, 0])\n",
      "Figure 7.1 sho ws the resulting p osterior distributions for lam . Based on the\n",
      "\u001crst four games, the most lik ely v alues for lam are 2.6 for the Can uc ks and 2.9\n",
      "for the Bruins.\n",
      "7.4 The distribution of goals\n",
      "T o compute the probabilit y that eac h team wins the next game, w e need to\n",
      "compute the distribution of goals for eac h team.\n",
      "If w e knew the v alue of lam exactly , w e could use the P oisson distribution again.\n",
      "thinkbayes pro vides a metho d that computes a truncated appro ximation of\n",
      "a P oisson distribution:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 89}\n",
      "------------------------\n",
      "page_content='7.4. The distribution of goals 73\n",
      "0 2 4 6 8 10\n",
      "Goals0.000.050.100.150.200.25Probabilitybruins\n",
      "canucks\n",
      "Figure 7.2: Distribution of goals in a single game.\n",
      "def MakePoissonPmf(lam, high):\n",
      "pmf = Pmf()\n",
      "for k in xrange(0, high+1):\n",
      "p = EvalPoissonPmf(k, lam)\n",
      "pmf.Set(k, p)\n",
      "pmf.Normalize()\n",
      "return pmf\n",
      "The range of v alues in the computed Pmf is from 0 to high . So if the v alue of\n",
      "lam w ere exactly 3.4, w e w ould compute:\n",
      "lam = 3.4\n",
      "goal_dist = thinkbayes.MakePoissonPmf(lam, 10)\n",
      "I c hose the upp er b ound, 10, b ecause the probabilit y of scoring more than 10\n",
      "goals in a game is quite lo w.\n",
      "That's simple enough so far; the problem is that w e don't kno w the v alue of\n",
      "lam exactly . Instead, w e ha v e a distribution of p ossible v alues for lam .\n",
      "F or eac h v alue of lam , the distribution of goals is P oisson. So the o v erall distri-\n",
      "bution of goals is a mixture of these P oisson distributions, w eigh ted according\n",
      "to the probabilities in the distribution of lam .\n",
      "Giv en the p osterior distribution of lam , here's the co de that mak es the distri-\n",
      "bution of goals:\n",
      "def MakeGoalPmf(suite):\n",
      "metapmf = thinkbayes.Pmf()\n",
      "for lam, prob in suite.Items():' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 90}\n",
      "------------------------\n",
      "page_content='74 Chapter 7. Prediction\n",
      "0.0 0.5 1.0 1.5 2.0\n",
      "Games until goal0.00000.00050.00100.00150.00200.00250.0030Probabilitybruins\n",
      "canucks\n",
      "Figure 7.3: Distribution of time b et w een goals.\n",
      "pmf = thinkbayes.MakePoissonPmf(lam, 10)\n",
      "metapmf.Set(pmf, prob)\n",
      "mix = thinkbayes.MakeMixture(metapmf)\n",
      "return mix\n",
      "F or eac h v alue of lam w e mak e a P oisson Pmf and add it to the meta-Pmf. I\n",
      "call it a meta-Pmf b ecause it is a Pmf that con tains Pmfs as its v alues.\n",
      "Then w e use MakeMixture to compute the mixture (w e sa w MakeMixture in\n",
      "Section 5.6).\n",
      "Figure 7.2 sho ws the resulting distribution of goals for the Bruins and Can uc ks.\n",
      "The Bruins are less lik ely to score 3 goals or few er in the next game, and more\n",
      "lik ely to score 4 or more.\n",
      "7.5 The probabilit y of winning\n",
      "T o get the probabilit y of winning, \u001crst w e compute the distribution of the goal\n",
      "di\u001beren tial:\n",
      "goal_dist1 = MakeGoalPmf(suite1)\n",
      "goal_dist2 = MakeGoalPmf(suite2)\n",
      "diff = goal_dist1 - goal_dist2\n",
      "The subtraction op erator in v ok es Pmf.__sub__ , whic h en umerates pairs of\n",
      "v alues and computes the di\u001berence. Subtracting t w o distributions is almost\n",
      "the same as adding, whic h w e sa w in Section 5.4.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 91}\n",
      "------------------------\n",
      "page_content='7.6. Sudden death 75\n",
      "If the goal di\u001beren tial is p ositiv e, the Bruins win; if negativ e, the Can uc ks win;\n",
      "if 0, it's a tie:\n",
      "p_win = diff.ProbGreater(0)\n",
      "p_loss = diff.ProbLess(0)\n",
      "p_tie = diff.Prob(0)\n",
      "With the distributions from the previous section, p_win is 46%, p_loss is\n",
      "37%, and p_tie is 17%.\n",
      "In the ev en t of a tie at the end of \u0010regulation pla y ,\u0011 the teams pla y o v ertime\n",
      "p erio ds un til one team scores. Since the game ends immediately when the \u001crst\n",
      "goal is scored, this o v ertime format is kno wn as \u0010sudden death.\u0011\n",
      "7.6 Sudden death\n",
      "T o compute the probabilit y of winning in a sudden death o v ertime, the im-\n",
      "p ortan t statistic is not goals p er game, but time un til the \u001crst goal. The\n",
      "assumption that goal-scoring is a P oisson pro cess implies that the time b e-\n",
      "t w een goals is exp onen tially distributed.\n",
      "Giv en lam , w e can compute the time b et w een goals lik e this:\n",
      "lam = 3.4\n",
      "time_dist = thinkbayes.MakeExponentialPmf(lam, high=2, n=101)\n",
      "high is the upp er b ound of the distribution. In this case I c hose 2, b ecause\n",
      "the probabilit y of going more than t w o games without scoring is small. n is\n",
      "the n um b er of v alues in the Pmf.\n",
      "If w e kno w lam exactly , that's all there is to it. But w e don't; instead w e ha v e\n",
      "a p osterior distribution of p ossible v alues. So as w e did with the distribution\n",
      "of goals, w e mak e a meta-Pmf and compute a mixture of Pmfs.\n",
      "def MakeGoalTimePmf(suite):\n",
      "metapmf = thinkbayes.Pmf()\n",
      "for lam, prob in suite.Items():\n",
      "pmf = thinkbayes.MakeExponentialPmf(lam, high=2, n=2001)\n",
      "metapmf.Set(pmf, prob)\n",
      "mix = thinkbayes.MakeMixture(metapmf)\n",
      "return mix\n",
      "Figure 7.3 sho ws the resulting distributions. F or time v alues less than one\n",
      "p erio d (one third of a game), the Bruins are more lik ely to score. The time\n",
      "un til the Can uc ks score is more lik ely to b e longer.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 92}\n",
      "------------------------\n",
      "page_content='76 Chapter 7. Prediction\n",
      "I set the n um b er of v alues, n , fairly high in order to minimize the n um b er of\n",
      "ties, since it is not p ossible for b oth teams to score sim ultaneously .\n",
      "No w w e compute the probabilit y that the Bruins score \u001crst:\n",
      "time_dist1 = MakeGoalTimePmf(suite1)\n",
      "time_dist2 = MakeGoalTimePmf(suite2)\n",
      "p_overtime = thinkbayes.PmfProbLess(time_dist1, time_dist2)\n",
      "F or the Bruins, the probabilit y of winning in o v ertime is 52%.\n",
      "Finally , the total probabilit y of winning is the c hance of winning at the end of\n",
      "regulation pla y plus the probabilit y of winning in o v ertime.\n",
      "p_tie = diff.Prob(0)\n",
      "p_overtime = thinkbayes.PmfProbLess(time_dist1, time_dist2)\n",
      "p_win = diff.ProbGreater(0) + p_tie * p_overtime\n",
      "F or the Bruins, the o v erall c hance of winning the next game is 55%.\n",
      "T o win the series, the Bruins can either win the next t w o games or split the\n",
      "next t w o and win the third. Again, w e can compute the total probabilit y:\n",
      "# win the next two\n",
      "p_series = p_win**2\n",
      "# split the next two, win the third\n",
      "p_series += 2 * p_win * (1-p_win) * p_win\n",
      "The Bruins c hance of winning the series is 57%. And in 2011, they did.\n",
      "7.7 Discussion\n",
      "As alw a ys, the analysis in this c hapter is based on mo deling decisions, and\n",
      "mo deling is almost alw a ys an iterativ e pro cess. In general, y ou w an t to\n",
      "start with something simple that yields an appro ximate answ er, iden tify lik ely\n",
      "sources of error, and lo ok for opp ortunities for impro v emen t.\n",
      "In this example, I w ould consider these options:\n",
      " I c hose a prior based on the a v erage goals p er game for eac h team.\n",
      "But this statistic is a v eraged across all opp onen ts. Against a particular\n",
      "opp onen t, w e migh t exp ect more v ariabilit y . F or example, if the team\n",
      "with the b est o\u001bense pla ys the team with the w orst defense, the exp ected\n",
      "goals p er game migh t b e sev eral standard deviations ab o v e the mean.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 93}\n",
      "------------------------\n",
      "page_content='7.8. Exercises 77\n",
      " F or data I used only the \u001crst four games of the c hampionship series. If\n",
      "the same teams pla y ed eac h other during the regular season, I could use\n",
      "the results from those games as w ell. One complication is that the com-\n",
      "p osition of teams c hanges during the season due to trades and injuries.\n",
      "So it migh t b e b est to giv e more w eigh t to recen t games.\n",
      " T o tak e adv an tage of all a v ailable information, w e could use results from\n",
      "all regular season games to estimate eac h team's goal scoring rate, p ossi-\n",
      "bly adjusted b y estimating an additional factor for eac h pairwise matc h-\n",
      "up. This approac h w ould b e more complicated, but it is still feasible.\n",
      "F or the \u001crst option, w e could use the results from the regular season to estimate\n",
      "the v ariabilit y across all pairwise matc h-ups. Thanks to Dirk Hoag at http:\n",
      "//forechecker.blogspot.com/ , I w as able to get the n um b er of goals scored\n",
      "during regulation pla y (not o v ertime) for eac h game in the regular season.\n",
      "T eams in di\u001beren t conferences only pla y eac h other one or t w o times in the\n",
      "regular season, so I fo cused on pairs that pla y ed eac h other 4\u00156 times. F or\n",
      "eac h pair, I computed the a v erage goals p er game, whic h is an estimate of λ ,\n",
      "then plotted the distribution of these estimates.\n",
      "The mean of these estimates is 2.8, again, but the standard deviation is 0.85,\n",
      "substan tially higher than what w e got computing one estimate for eac h team.\n",
      "If w e run the analysis again with the higher-v ariance prior, the probabilit y that\n",
      "the Bruins win the series is 80%, substan tially higher than the result with the\n",
      "lo w-v ariance prior, 57%.\n",
      "So it turns out that the results are sensitiv e to the prior, whic h mak es sense\n",
      "considering ho w little data w e ha v e to w ork with. Based on the di\u001berence b e-\n",
      "t w een the lo w-v ariance mo del and the high-v ariable mo del, it seems w orth while\n",
      "to put some e\u001bort in to getting the prior righ t.\n",
      "The co de and data for this c hapter are a v ailable from http://thinkbayes.\n",
      "com/hockey.py and http://thinkbayes.com/hockey_data.csv . F or more\n",
      "information see Section 0.3.\n",
      "7.8 Exercises\n",
      "Exercise 7.1 If buses arriv e at a bus stop ev ery 20 min utes, and y ou arriv e\n",
      "at the bus stop at a random time, y our w ait time un til the bus arriv es is\n",
      "uniformly distributed from 0 to 20 min utes.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 94}\n",
      "------------------------\n",
      "page_content='78 Chapter 7. Prediction\n",
      "But in realit y , there is v ariabilit y in the time b et w een buses. Supp ose y ou are\n",
      "w aiting for a bus, and y ou kno w the historical distribution of time b et w een\n",
      "buses. Compute y our distribution of w ait times.\n",
      "Hin t: Supp ose that the time b et w een buses is either 5 or 10 min utes with\n",
      "equal probabilit y . What is the probabilit y that y ou arriv e during one of the\n",
      "10 min ute in terv als?\n",
      "I solv e a v ersion of this problem in the next c hapter.\n",
      "Exercise 7.2 Supp ose that passengers arriving at the bus stop are w ell-\n",
      "mo deled b y a P oisson pro cess with parameter λ . If y ou arriv e at the stop\n",
      "and \u001cnd 3 p eople w aiting, what is y our p osterior distribution for the time\n",
      "since the last bus arriv ed.\n",
      "I solv e a v ersion of this problem in the next c hapter.\n",
      "Exercise 7.3 Supp ose that y ou are an ecologist sampling the insect p opulation\n",
      "in a new en vironmen t. Y ou deplo y 100 traps in a test area and come bac k\n",
      "the next da y to c hec k on them. Y ou \u001cnd that 37 traps ha v e b een triggered,\n",
      "trapping an insect inside. Once a trap triggers, it cannot trap another insect\n",
      "un til it has b een reset.\n",
      "If y ou reset the traps and come bac k in t w o da ys, ho w man y traps do y ou\n",
      "exp ect to \u001cnd triggered? Compute a p osterior predictiv e distribution for the\n",
      "n um b er of traps.\n",
      "Exercise 7.4 Supp ose y ou are the manager of an apartmen t building with 100\n",
      "ligh t bulbs in common areas. It is y our resp onsibilit y to replace ligh t bulbs\n",
      "when they break.\n",
      "On Jan uary 1, all 100 bulbs are w orking. When y ou insp ect them on F ebruary\n",
      "1, y ou \u001cnd 3 ligh t bulbs out. If y ou come bac k on April 1, ho w man y ligh t\n",
      "bulbs do y ou exp ect to \u001cnd brok en?\n",
      "In the previous exercise, y ou could reasonably assume that an ev en t is equally\n",
      "lik ely at an y time. F or ligh t bulbs, the lik eliho o d of failure dep ends on the\n",
      "age of the bulb. Sp eci\u001ccally , old bulbs ha v e an increasing failure rate due to\n",
      "ev ap oration of the \u001clamen t.\n",
      "This problem is more op en-ended than some; y ou will ha v e to mak e mo deling\n",
      "decisions. Y ou migh t w an t to read ab out the W eibull distribution ( http:\n",
      "//en.wikipedia.org/wiki/Weibull_distribution ). Or y ou migh t w an t to\n",
      "lo ok around for information ab out ligh t bulb surviv al curv es.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 95}\n",
      "------------------------\n",
      "page_content='Chapter 8\n",
      "Observer Bias\n",
      "8.1 The Red Line problem\n",
      "In Massac h usetts, the Red Line is a sub w a y that connects Cam bridge and\n",
      "Boston. When I w as w orking in Cam bridge I to ok the Red Line from Kendall\n",
      "Square to South Station and caugh t the comm uter rail to Needham. During\n",
      "rush hour Red Line trains run ev ery 7\u00158 min utes, on a v erage.\n",
      "When I arriv ed at the station, I could estimate the time un til the next train\n",
      "based on the n um b er of passengers on the platform. If there w ere only a few\n",
      "p eople, I inferred that I just missed a train and exp ected to w ait ab out 7\n",
      "min utes. If there w ere more passengers, I exp ected the train to arriv e so oner.\n",
      "But if there w ere a large n um b er of passengers, I susp ected that trains w ere\n",
      "not running on sc hedule, so I w ould go bac k to the street lev el and get a taxi.\n",
      "While I w as w aiting for trains, I though t ab out ho w Ba y esian estimation could\n",
      "help predict m y w ait time and decide when I should giv e up and tak e a taxi.\n",
      "This c hapter presen ts the analysis I came up with.\n",
      "This c hapter is based on a pro ject b y Brendan Ritter and Kai Austin, who\n",
      "to ok a class with me at Olin College. The co de in this c hapter is a v ailable\n",
      "from http://thinkbayes.com/redline.py . The co de I used to collect data\n",
      "is in http://thinkbayes.com/redline_data.py . F or more information see\n",
      "Section 0.3.\n",
      "8.2 The mo del\n",
      "Before w e get to the analysis, w e ha v e to mak e some mo deling decisions. First,\n",
      "I will treat passenger arriv als as a P oisson pro cess, whic h means I assume that' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 96}\n",
      "------------------------\n",
      "page_content='80 Chapter 8. Observ er Bias\n",
      "0 5 10 15 20\n",
      "Time (min)0.0000.0050.0100.0150.0200.025CDFz\n",
      "zb\n",
      "Figure 8.1: PMF of gaps b et w een trains, based on collected data, smo othed\n",
      "b y KDE. z is the actual distribution; zb is the biased distribution seen b y\n",
      "passengers.\n",
      "passengers are equally lik ely to arriv e at an y time, and that they arriv e at\n",
      "an unkno wn rate, λ , measured in passengers p er min ute. Since I observ e\n",
      "passengers during a short p erio d of time, and at the same time ev ery da y , I\n",
      "assume that λ is constan t.\n",
      "On the other hand, the arriv al pro cess for trains is not P oisson. T rains to\n",
      "Boston are supp osed to lea v e from the end of the line (Alewife station) ev ery\n",
      "7\u00158 min utes during p eak times, but b y the time they get to Kendall Square,\n",
      "the time b et w een trains v aries b et w een 3 and 12 min utes.\n",
      "T o gather data on the time b et w een trains, I wrote a script that do wnloads\n",
      "real-time data from http://www.mbta.com/rider_tools/developers/ , se-\n",
      "lects south-b ound trains arriving at Kendall square, and records their arriv al\n",
      "times in a database. I ran the script from 4pm to 6pm ev ery w eekda y for 5\n",
      "da ys, and recorded ab out 15 arriv als p er da y . Then I computed the time b e-\n",
      "t w een consecutiv e arriv als; the distribution of these gaps is sho wn in Figure 8.1,\n",
      "lab eled z .\n",
      "If y ou sto o d on the platform from 4pm to 6pm and recorded the time b et w een\n",
      "trains, this is the distribution y ou w ould see. But if y ou arriv e at some random\n",
      "time (without regard to the train sc hedule) y ou w ould see a di\u001beren t distri-\n",
      "bution. The a v erage time b et w een trains, as seen b y a random passenger, is\n",
      "substan tially higher than the true a v erage.\n",
      "Wh y? Because a passenger is more lik e to arriv e during a large in terv al than a\n",
      "small one. Consider a simple example: supp ose that the time b et w een trains is' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 97}\n",
      "------------------------\n",
      "page_content='8.3. W ait times 81\n",
      "either 5 min utes or 10 min utes with equal probabilit y . In that case the a v erage\n",
      "time b et w een trains is 7.5 min utes.\n",
      "But a passenger is more lik ely to arriv e during a 10 min ute gap than a 5\n",
      "min ute gap; in fact, t wice as lik ely . If w e surv ey ed arriving passengers, w e\n",
      "w ould \u001cnd that 2/3 of them arriv ed during a 10 min ute gap, and only 1/3\n",
      "during a 5 min ute gap. So the a v erage time b et w een trains, as seen b y an\n",
      "arriving passenger, is 8.33 min utes.\n",
      "This kind of observ er bias app ears in man y con texts. Studen ts think that\n",
      "classes are bigger than they are b ecause more of them are in the big classes.\n",
      "Airline passengers think that planes are fuller than they are b ecause more of\n",
      "them are on full \u001digh ts.\n",
      "In eac h case, v alues from the actual distribution are o v ersampled in prop ortion\n",
      "to their v alue. In the Red Line example, a gap that is t wice as big is t wice as\n",
      "lik ely to b e observ ed.\n",
      "So giv en the actual distribution of gaps, w e can compute the distribution of\n",
      "gaps as seen b y passengers. BiasPmf do es this computation:\n",
      "def BiasPmf(pmf):\n",
      "new_pmf = pmf.Copy()\n",
      "for x, p in pmf.Items():\n",
      "new_pmf.Mult(x, x)\n",
      "new_pmf.Normalize()\n",
      "return new_pmf\n",
      "pmf is the actual distribution; new_pmf is the biased distribution. Inside the\n",
      "lo op, w e m ultiply the probabilit y of eac h v alue, x , b y the lik eliho o d it will b e\n",
      "observ ed, whic h is prop ortional to x . Then w e normalize the result.\n",
      "Figure 8.1 sho ws the actual distribution of gaps, lab eled z , and the distribution\n",
      "of gaps seen b y passengers, lab eled zb for \u0010z biased\u0011.\n",
      "8.3 W ait times\n",
      "W ait time, whic h I call y , is the time b et w een the arriv al of a passenger and\n",
      "the next arriv al of a train. Elapsed time, whic h I call x , is the time b et w een\n",
      "the arriv al of the previous train and the arriv al of a passenger. I c hose these\n",
      "de\u001cnitions so that zb = x + y .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 98}\n",
      "------------------------\n",
      "page_content='82 Chapter 8. Observ er Bias\n",
      "0 5 10 15 20\n",
      "Time (min)0.00.20.40.60.81.0CDFz\n",
      "zb\n",
      "y\n",
      "Figure 8.2: CDF of z , zb , and the w ait time seen b y passengers, y .\n",
      "Giv en the distribution of zb , w e can compute the distribution of y . I'll start\n",
      "with a simple case and then generalize. Supp ose, as in the previous example,\n",
      "that zb is either 5 min utes with probabilit y 1/3, or 10 min utes with probabilit y\n",
      "2/3.\n",
      "If w e arriv e at a random time during a 5 min ute gap, y is uniform from 0 to 5\n",
      "min utes. If w e arriv e during a 10 min ute gap, y is uniform from 0 to 10. So the\n",
      "o v erall distribution is a mixture of uniform distributions w eigh ted according\n",
      "to the probabilit y of eac h gap.\n",
      "The follo wing function tak es the distribution of zb and computes the distri-\n",
      "bution of y :\n",
      "def PmfOfWaitTime(pmf_zb):\n",
      "metapmf = thinkbayes.Pmf()\n",
      "for gap, prob in pmf_zb.Items():\n",
      "uniform = MakeUniformPmf(0, gap)\n",
      "metapmf.Set(uniform, prob)\n",
      "pmf_y = thinkbayes.MakeMixture(metapmf)\n",
      "return pmf_y\n",
      "PmfOfWaitTime mak es a meta-Pmf that maps from eac h uniform distribution\n",
      "to its probabilit y . Then it uses MakeMixture , whic h w e sa w in Section 5.6, to\n",
      "compute the mixture.\n",
      "PmfOfWaitTime also uses MakeUniformPmf , de\u001cned here:\n",
      "def MakeUniformPmf(low, high):\n",
      "pmf = thinkbayes.Pmf()' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 99}\n",
      "------------------------\n",
      "page_content='8.3. W ait times 83\n",
      "for x in MakeRange(low=low, high=high):\n",
      "pmf.Set(x, 1)\n",
      "pmf.Normalize()\n",
      "return pmf\n",
      "low and high are the range of the uniform distribution, (b oth ends included).\n",
      "Finally , MakeUniformPmf uses MakeRange , de\u001cned here:\n",
      "def MakeRange(low, high, skip=10):\n",
      "return range(low, high+skip, skip)\n",
      "MakeRange de\u001cnes a set of p ossible v alues for w ait time (expressed in seconds).\n",
      "By default it divides the range in to 10 second in terv als.\n",
      "T o encapsulate the pro cess of computing these distributions, I created a class\n",
      "called WaitTimeCalculator :\n",
      "class WaitTimeCalculator(object):\n",
      "def __init__(self, pmf_z):\n",
      "self.pmf_z = pmf_z\n",
      "self.pmf_zb = BiasPmf(pmf)\n",
      "self.pmf_y = self.PmfOfWaitTime(self.pmf_zb)\n",
      "self.pmf_x = self.pmf_y\n",
      "The parameter, pmf_z , is the un biased distribution of z . pmf_zb is the biased\n",
      "distribution of gap time, as seen b y passengers.\n",
      "pmf_y is the distribution of w ait time. pmf_x is the distribution of elapsed time,\n",
      "whic h is the same as the distribution of w ait time. T o see wh y , remem b er that\n",
      "for a particular v alue of zp , the distribution of y is uniform from 0 to zp . Also\n",
      "x = zp - y\n",
      "So the distribution of x is also uniform from 0 to zp .\n",
      "Figure 8.2 sho ws the distribution of z , zb , and y based on the data I collected\n",
      "from the Red Line w eb site.\n",
      "T o presen t these distributions, I am switc hing from Pmfs to Cdfs. Most p eople\n",
      "are more familiar with Pmfs, but I think Cdfs are easier to in terpret, once y ou\n",
      "get used to them. And if y ou w an t to plot sev eral distributions on the same\n",
      "axes, Cdfs are the w a y to go.\n",
      "The mean of z is 7.8 min utes. The mean of zb is 8.8 min utes, ab out 13%\n",
      "higher. The mean of y is 4.4, half the mean of zb .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 100}\n",
      "------------------------\n",
      "page_content='84 Chapter 8. Observ er Bias\n",
      "0 5 10 15 20\n",
      "Time (min)0.00.20.40.60.81.0CDFprior x\n",
      "posterior x\n",
      "pred y\n",
      "Figure 8.3: Prior and p osterior of x and predicted y .\n",
      "As an aside, the Red Line sc hedule rep orts that trains run ev ery 9 min utes\n",
      "during p eak times. This is close to the a v erage of zb , but higher than the\n",
      "a v erage of z . I exc hanged email with a represen tativ e of the MBT A, who\n",
      "con\u001crmed that the rep orted time b et w een trains is delib erately conserv ativ e\n",
      "in order to accoun t for v ariabilit y .\n",
      "8.4 Predicting w ait times\n",
      "Let's get bac k to the motiv ating question: supp ose that when I arriv e at the\n",
      "platform I see 10 p eople w aiting. Ho w long should I exp ect to w ait un til the\n",
      "next train arriv es?\n",
      "As alw a ys, let's start with the easiest v ersion of the problem and w ork our w a y\n",
      "up. Supp ose w e are giv en the actual distribution of z , and w e kno w that the\n",
      "passenger arriv al rate, λ , is 2 passengers p er min ute.\n",
      "In that case w e can:\n",
      "1. Use the distribution of z to compute the prior distribution of zp , the\n",
      "time b et w een trains as seen b y a passenger.\n",
      "2. Then w e can use the n um b er of passengers to estimate the distribution\n",
      "of x , the elapsed time since the last train.\n",
      "3. Finally , w e use the relation y = zp - x to get the distribution of y .\n",
      "The \u001crst step is to create a WaitTimeCalculator that encapsulates the distri-\n",
      "butions of zp , x , and y , prior to taking in to accoun t the n um b er of passengers.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 101}\n",
      "------------------------\n",
      "page_content='8.4. Predicting w ait times 85\n",
      "wtc = WaitTimeCalculator(pmf_z)\n",
      "pmf_z is the giv en distribution of gap times.\n",
      "The next step is to mak e an ElapsedTimeEstimator (de\u001cned b elo w), whic h\n",
      "encapsulates the p osterior distribution of x and the predictiv e distribution of\n",
      "y .\n",
      "ete = ElapsedTimeEstimator(wtc,\n",
      "lam=2.0/60,\n",
      "num_passengers=15)\n",
      "The parameters are the WaitTimeCalculator , the passenger arriv al rate, lam\n",
      "(expressed in passengers p er second), and the observ ed n um b er of passengers,\n",
      "let's sa y 15.\n",
      "Here is the de\u001cnition of ElapsedTimeEstimator :\n",
      "class ElapsedTimeEstimator(object):\n",
      "def __init__(self, wtc, lam, num_passengers):\n",
      "self.prior_x = Elapsed(wtc.pmf_x)\n",
      "self.post_x = self.prior_x.Copy()\n",
      "self.post_x.Update((lam, num_passengers))\n",
      "self.pmf_y = PredictWaitTime(wtc.pmf_zb, self.post_x)\n",
      "prior_x and posterior_x are the prior and p osterior distributions of elapsed\n",
      "time. pmf_y is the predictiv e distribution of w ait time.\n",
      "ElapsedTimeEstimator uses Elapsed and PredictWaitTime , de\u001cned b elo w.\n",
      "Elapsed is a Suite that represen ts the h yp othetical distribution of x . The prior\n",
      "distribution of x comes straigh t from the WaitTimeCalculator . Then w e use\n",
      "the data, whic h consists of the arriv al rate, lam , and the n um b er of passengers\n",
      "on the platform, to compute the p osterior distribution.\n",
      "Here's the de\u001cnition of Elapsed :\n",
      "class Elapsed(thinkbayes.Suite):\n",
      "def Likelihood(self, data, hypo):\n",
      "x = hypo\n",
      "lam, k = data\n",
      "like = thinkbayes.EvalPoissonPmf(k, lam * x)\n",
      "return like' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 102}\n",
      "------------------------\n",
      "page_content='86 Chapter 8. Observ er Bias\n",
      "As alw a ys, Likelihood tak es a h yp othesis and data, and computes the lik eli-\n",
      "ho o d of the data under the h yp othesis. In this case hypo is the elapsed time\n",
      "since the last train and data is a tuple of lam and the n um b er of passengers.\n",
      "The lik eliho o d of the data is the probabilit y of getting k arriv als in x time, giv en\n",
      "arriv al rate lam . W e compute that using the PMF of the P oisson distribution.\n",
      "Finally , here's the de\u001cnition of PredictWaitTime :\n",
      "def PredictWaitTime(pmf_zb, pmf_x):\n",
      "pmf_y = pmf_zb - pmf_x\n",
      "RemoveNegatives(pmf_y)\n",
      "return pmf_y\n",
      "pmf_zb is the distribution of gaps b et w een trains; pmf_x is the distribution of\n",
      "elapsed time, based on the observ ed n um b er of passengers. Since y = zb -\n",
      "x , w e can compute\n",
      "pmf_y = pmf_zb - pmf_x\n",
      "The subtraction op erator in v ok es Pmf.__sub__ , whic h en umerates all pairs of\n",
      "zb and x , computes the di\u001berences, and adds the results to pmf_y .\n",
      "The resulting Pmf includes some negativ e v alues, whic h w e kno w are imp os-\n",
      "sible. F or example, if y ou arriv e during a gap of 5 min utes, y ou can't w ait\n",
      "more than 5 min utes. RemoveNegatives remo v es the imp ossible v alues from\n",
      "the distribution and renormalizes.\n",
      "def RemoveNegatives(pmf):\n",
      "for val in pmf.Values():\n",
      "if val < 0:\n",
      "pmf.Remove(val)\n",
      "pmf.Normalize()\n",
      "Figure 8.3 sho ws the results. The prior distribution of x is the same as the\n",
      "distribution of y in Figure 8.2. The p osterior distribution of x sho ws that, after\n",
      "seeing 15 passengers on the platform, w e b eliev e that the time since the last\n",
      "train is probably 5-10 min utes. The predictiv e distribution of y indicates that\n",
      "w e exp ect the next train in less than 5 min utes, with ab out 80% con\u001cdence.\n",
      "8.5 Estimating the arriv al rate\n",
      "The analysis so far has b een based on the assumption that w e kno w (1) the\n",
      "distribution of gaps and (2) the passenger arriv al rate. No w w e are ready to\n",
      "relax the second assumption.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 103}\n",
      "------------------------\n",
      "page_content='8.5. Estimating the arriv al rate 87\n",
      "0 1 2 3 4 5\n",
      "Arrival rate (passengers / min)0.00.20.40.60.81.0CDFprior\n",
      "posterior\n",
      "Figure 8.4: Prior and p osterior distributions of lam based on \u001cv e da ys of\n",
      "passenger data.\n",
      "Supp ose that y ou just mo v ed to Boston, so y ou don't kno w m uc h ab out the\n",
      "passenger arriv al rate on the Red Line. After a few da ys of comm uting, y ou\n",
      "could mak e a guess, at least qualitativ ely . With a little more e\u001bort, y ou could\n",
      "estimateλ quan titativ ely .\n",
      "Eac h da y when y ou arriv e at the platform, y ou should note the time and the\n",
      "n um b er of passengers w aiting (if the platform is to o big, y ou could c ho ose a\n",
      "sample area). Then y ou should record y our w ait time and the n um b er of new\n",
      "arriv als while y ou are w aiting.\n",
      "After \u001cv e da ys, y ou migh t ha v e data lik e this:\n",
      "k1 y k2\n",
      "-- --- --\n",
      "17 4.6 9\n",
      "22 1.0 0\n",
      "23 1.4 4\n",
      "18 5.4 12\n",
      "4 5.8 11\n",
      "where k1 is the n um b er of passengers w aiting when y ou arriv e, y is y our w ait\n",
      "time in min utes, and k2 is the n um b er of passengers who arriv e while y ou are\n",
      "w aiting.\n",
      "Ov er the course of one w eek, y ou w aited 18 min utes and sa w 36 passengers\n",
      "arriv e, so y ou w ould estimate that the arriv al rate is 2 passengers p er min ute.\n",
      "F or practical purp oses that estimate is go o d enough, but for the sak e of com-' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 104}\n",
      "------------------------\n",
      "page_content='88 Chapter 8. Observ er Bias\n",
      "pleteness I will compute a p osterior distribution for λ and sho w ho w to use\n",
      "that distribution in the rest of the analysis.\n",
      "ArrivalRate is a Suite that represen ts h yp otheses ab out λ . As alw a ys,\n",
      "Likelihood tak es a h yp othesis and data, and computes the lik eliho o d of the\n",
      "data under the h yp othesis.\n",
      "In this case the h yp othesis is a v alue of λ . The data is a pair, y, k , where y\n",
      "is a w ait time and k is the n um b er of passengers that arriv ed.\n",
      "class ArrivalRate(thinkbayes.Suite):\n",
      "def Likelihood(self, data, hypo):\n",
      "lam = hypo\n",
      "y, k = data\n",
      "like = thinkbayes.EvalPoissonPmf(k, lam * y)\n",
      "return like\n",
      "This Likelihood migh t lo ok familiar; it is almost iden tical to\n",
      "Elapsed.Likelihood in Section 8.4. The di\u001berence is that in\n",
      "Elapsed.Likelihood the h yp othesis is x , the elapsed time; in\n",
      "ArrivalRate.Likelihood the h yp othesis is lam , the arriv al rate. But\n",
      "in b oth cases the lik eliho o d is the probabilit y of seeing k arriv als in some\n",
      "p erio d of time, giv en lam .\n",
      "ArrivalRateEstimator encapsulates the pro cess of estimating λ . The pa-\n",
      "rameter, passenger_data , is a list of k1, y, k2 tuples, as in the table ab o v e.\n",
      "class ArrivalRateEstimator(object):\n",
      "def __init__(self, passenger_data):\n",
      "low, high = 0, 5\n",
      "n = 51\n",
      "hypos = numpy.linspace(low, high, n) / 60\n",
      "self.prior_lam = ArrivalRate(hypos)\n",
      "self.post_lam = self.prior_lam.Copy()\n",
      "for k1, y, k2 in passenger_data:\n",
      "self.post_lam.Update((y, k2))\n",
      "__init__ builds hypos , whic h is a sequence of h yp othetical v alues for lam ,\n",
      "then builds the prior distribution, prior_lam . The for lo op up dates the prior\n",
      "with data, yielding the p osterior distribution, post_lam .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 105}\n",
      "------------------------\n",
      "page_content='8.6. Incorp orating uncertain t y 89\n",
      "0 2 4 6 8 10\n",
      "Wait time (min)0.00.20.40.60.81.0CDFmix\n",
      "Figure 8.5: Predictiv e distributions of y for p ossible v alues of lam .\n",
      "Figure 8.4 sho ws the prior and p osterior distributions. As exp ected, the mean\n",
      "and median of the p osterior are near the observ ed rate, 2 passengers p er\n",
      "min ute. But the spread of the p osterior distribution captures our uncertain t y\n",
      "ab outλ based on a small sample.\n",
      "8.6 Incorp orating uncertain t y\n",
      "Whenev er there is uncertain t y ab out one of the inputs to an analysis, w e can\n",
      "tak e it in to accoun t b y a pro cess lik e this:\n",
      "1. Implemen t the analysis based on a deterministic v alue of the uncertain\n",
      "parameter (in this case λ ).\n",
      "2. Compute the distribution of the uncertain parameter.\n",
      "3. Run the analysis for eac h v alue of the parameter, and generate a set of\n",
      "predictiv e distributions.\n",
      "4. Compute a mixture of the predictiv e distributions, using the w eigh ts\n",
      "from the distribution of the parameter.\n",
      "W e ha v e already done steps (1) and (2). I wrote a class called\n",
      "WaitMixtureEstimator to handle steps (3) and (4).\n",
      "class WaitMixtureEstimator(object):\n",
      "def __init__(self, wtc, are, num_passengers=15):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 106}\n",
      "------------------------\n",
      "page_content='90 Chapter 8. Observ er Bias\n",
      "self.metapmf = thinkbayes.Pmf()\n",
      "for lam, prob in sorted(are.post_lam.Items()):\n",
      "ete = ElapsedTimeEstimator(wtc, lam, num_passengers)\n",
      "self.metapmf.Set(ete.pmf_y, prob)\n",
      "self.mixture = thinkbayes.MakeMixture(self.metapmf)\n",
      "wtc is the WaitTimeCalculator that con tains the distribution of zb . are is\n",
      "the ArrivalTimeEstimator that con tains the distribution of lam .\n",
      "The \u001crst line mak es a meta-Pmf that maps from eac h p ossible distribution\n",
      "of y to its probabilit y . F or eac h v alue of lam , w e use ElapsedTimeEstimator\n",
      "to compute the corresp onding distribution of y and store it in the Meta-Pmf.\n",
      "Then w e use MakeMixture to compute the mixture.\n",
      "Figure 8.5 sho ws the results. The shaded lines in the bac kground are the\n",
      "distributions of y for eac h v alue of lam , with line thic kness that represen ts\n",
      "lik eliho o d. The dark line is the mixture of these distributions.\n",
      "In this case w e could get a v ery similar result using a single p oin t estimate of\n",
      "lam . So it w as not necessary , for practical purp oses, to include the uncertain t y\n",
      "of the estimate.\n",
      "In general, it is imp ortan t to include v ariabilit y if the system resp onse is non-\n",
      "linear; that is, if small c hanges in the input can cause big c hanges in the output.\n",
      "In this case, p osterior v ariabilit y in lam is small and the system resp onse is\n",
      "appro ximately linear for small p erturbations.\n",
      "8.7 Decision analysis\n",
      "A t this p oin t w e can use the n um b er of passengers on the platform to predict\n",
      "the distribution of w ait times. No w let's get to the second part of the question:\n",
      "when should I stop w aiting for the train and go catc h a taxi?\n",
      "Remem b er that in the original scenario, I am trying to get to South Station\n",
      "to catc h the comm uter rail. Supp ose I lea v e the o\u001ece with enough time that\n",
      "I can w ait 15 min utes and still mak e m y connection at South Station.\n",
      "In that case I w ould lik e to kno w the probabilit y that y exceeds 15 min utes\n",
      "as a function of num_passengers . It is easy enough to use the analysis from\n",
      "Section 8.4 and run it for a range of num_passengers .\n",
      "But there's a problem. The analysis is sensitiv e to the frequency of long dela ys,\n",
      "and b ecause long dela ys are rare, it is hard to estimate their frequency .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 107}\n",
      "------------------------\n",
      "page_content='8.7. Decision analysis 91\n",
      "0 5 10 15 20 25 30 35\n",
      "Num passengers0.000.020.040.060.080.100.12P(y > 15 min)\n",
      "Figure 8.6: Probabilit y that w ait time exceeds 15 min utes as a function of the\n",
      "n um b er of passengers on the platform.\n",
      "I only ha v e data from one w eek, and the longest dela y I observ ed w as 15\n",
      "min utes. So I can't estimate the frequency of longer dela ys accurately .\n",
      "Ho w ev er, I can use previous observ ations to mak e at least a coarse estimate.\n",
      "When I comm uted b y Red Line for a y ear, I sa w three long dela ys caused b y\n",
      "a signaling problem, a p o w er outage, and \u0010p olice activit y\u0011 at another stop. So\n",
      "I estimate that there are ab out 3 ma jor dela ys p er y ear.\n",
      "But remem b er that m y observ ations are biased. I am more lik ely to observ e\n",
      "long dela ys b ecause they a\u001bect a large n um b er of passengers. So w e should\n",
      "treat m y observ ations as a sample of zb rather than z . Here's ho w w e can do\n",
      "that.\n",
      "During m y y ear of comm uting, I to ok the Red Line home ab out 220 times. So\n",
      "I tak e the observ ed gap times, gap_times , generate a sample of 220 gaps, and\n",
      "compute their Pmf:\n",
      "n = 220\n",
      "cdf_z = thinkbayes.MakeCdfFromList(gap_times)\n",
      "sample_z = cdf_z.Sample(n)\n",
      "pmf_z = thinkbayes.MakePmfFromList(sample_z)\n",
      "Next I bias pmf_z to get the distribution of zb , dra w a sample, and then add\n",
      "in dela ys of 30, 40, and 50 min utes (expressed in seconds):\n",
      "cdf_zp = BiasPmf(pmf_z).MakeCdf()\n",
      "sample_zb = cdf_zp.Sample(n) + [1800, 2400, 3000]\n",
      "Cdf.Sample is more e\u001ecien t than Pmf.Sample , so it is usually faster to con v ert\n",
      "a Pmf to a Cdf b efore sampling.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 108}\n",
      "------------------------\n",
      "page_content='92 Chapter 8. Observ er Bias\n",
      "Next I use the sample of zb to estimate a Pdf using KDE, and then con v ert\n",
      "the Pdf to a Pmf:\n",
      "pdf_zb = thinkbayes.EstimatedPdf(sample_zb)\n",
      "xs = MakeRange(low=60)\n",
      "pmf_zb = pdf_zb.MakePmf(xs)\n",
      "Finally I un bias the distribution of zb to get the distribution of z , whic h I use\n",
      "to create the WaitTimeCalculator :\n",
      "pmf_z = UnbiasPmf(pmf_zb)\n",
      "wtc = WaitTimeCalculator(pmf_z)\n",
      "This pro cess is complicated, but all of the steps are op erations w e ha v e seen\n",
      "b efore. No w w e are ready to compute the probabilit y of a long w ait.\n",
      "def ProbLongWait(num_passengers, minutes):\n",
      "ete = ElapsedTimeEstimator(wtc, lam, num_passengers)\n",
      "cdf_y = ete.pmf_y.MakeCdf()\n",
      "prob = 1 - cdf_y.Prob(minutes * 60)\n",
      "Giv en the n um b er of passengers on the platform, ProbLongWait mak es an\n",
      "ElapsedTimeEstimator , extracts the distribution of w ait time, and computes\n",
      "the probabilit y that w ait time exceeds minutes .\n",
      "Figure 8.6 sho ws the result. When the n um b er of passengers is less than 20,\n",
      "w e infer that the system is op erating normally , so the probabilit y of a long\n",
      "dela y is small. If there are 30 passengers, w e estimate that it has b een 15\n",
      "min utes since the last train; that's longer than a normal dela y , so w e infer that\n",
      "something is wrong and exp ect longer dela ys.\n",
      "If w e are willing to accept a 10% c hance of missing the connection at South\n",
      "Station, w e should sta y and w ait as long as there are few er than 30 passengers,\n",
      "and tak e a taxi if there are more.\n",
      "Or, to tak e this analysis one step further, w e could quan tify the cost of missing\n",
      "the connection and the cost of taking a taxi, then c ho ose the threshold that\n",
      "minimizes exp ected cost.\n",
      "8.8 Discussion\n",
      "The analysis so far has b een based on the assumption that the arriv al rate\n",
      "of passengers is the same ev ery da y . F or a comm uter train during rush hour,\n",
      "that migh t not b e a bad assumption, but there are some ob vious exceptions.\n",
      "F or example, if there is a sp ecial ev en t nearb y , a large n um b er of p eople migh t' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 109}\n",
      "------------------------\n",
      "page_content='8.9. Exercises 93\n",
      "arriv e at the same time. In that case, the estimate of lam w ould b e to o lo w,\n",
      "so the estimates of x and y w ould b e to o high.\n",
      "If sp ecial ev en ts are as common as ma jor dela ys, it w ould b e imp ortan t to\n",
      "include them in the mo del. W e could do that b y extending the distribution of\n",
      "lam to include o ccasional large v alues.\n",
      "W e started with the assumption that w e kno w distribution of z . As an alter-\n",
      "nativ e, a passenger could estimate z , but it w ould not b e easy . As a passenger,\n",
      "y ou only observ e only y our o wn w ait time, y . Unless y ou skip the \u001crst train\n",
      "and w ait for the second, y ou don't observ e the gap b et w een trains, z .\n",
      "Ho w ev er, w e could mak e some inferences ab out zb . If w e note the n um b er of\n",
      "passengers w aiting when w e arriv e, w e can estimate the elapsed time since the\n",
      "last train, x . Then w e observ e y . If w e add the p osterior distribution of x to\n",
      "the observ ed y , w e get a distribution that represen ts our p osterior b elief ab out\n",
      "the observ ed v alue of zb .\n",
      "W e can use this distribution to up date our b eliefs ab out the distribution of zb .\n",
      "Finally , w e can compute the in v erse of BiasPmf to get from the distribution\n",
      "of zb to the distribution of z .\n",
      "I lea v e this analysis as an exercise for the reader. One suggestion: y ou should\n",
      "read Chapter 15 \u001crst. Y ou can \u001cnd the outline of a solution in http://\n",
      "thinkbayes.com/redline.py . F or more information see Section 0.3.\n",
      "8.9 Exercises\n",
      "Exercise 8.1 This exercise is from MacKa y , Information The ory, Infer enc e,\n",
      "and L e arning A lgorithms :\n",
      "Unstable particles are emitted from a source and deca y at a dis-\n",
      "tancex , a real n um b er that has an exp onen tial probabilit y distri-\n",
      "bution with [parameter] λ . Deca y ev en ts can only b e observ ed if\n",
      "they o ccur in a windo w extending from x= 1 cm tox= 20 cm.\n",
      "N deca ys are observ ed at lo cations {1.5,2,3,4,5,12} cm. What is\n",
      "the p osterior distribution of λ ?\n",
      "Y ou can do wnload a solution to this exercise from http://thinkbayes.com/\n",
      "decay.py .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 110}\n",
      "------------------------\n",
      "page_content='94 Chapter 8. Observ er Bias' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 111}\n",
      "------------------------\n",
      "page_content='Chapter 9\n",
      "T wo Dimensions\n",
      "9.1 P ain tball\n",
      "P ain tball is a sp ort in whic h comp eting teams try to sho ot eac h other with\n",
      "guns that \u001cre pain t-\u001clled p ellets that break on impact, lea ving a colorful mark\n",
      "on the target. It is usually pla y ed in an arena decorated with barriers and\n",
      "other ob jects that can b e used as co v er.\n",
      "Supp ose y ou are pla ying pain tball in an indo or arena 30 feet wide and 50 feet\n",
      "long. Y ou are standing near one of the 30 fo ot w alls, and y ou susp ect that\n",
      "one of y our opp onen ts has tak en co v er nearb y . Along the w all, y ou see sev eral\n",
      "pain t spatters, all the same color, that y ou think y our opp onen t \u001cred recen tly .\n",
      "The spatters are at 15, 16, 18, and 21 feet, measured from the lo w er-left corner\n",
      "of the ro om. Based on these data, where do y ou think y our opp onen t is hiding?\n",
      "Figure 9.1 sho ws a diagram of the arena. Using the lo w er-left corner of the\n",
      "ro om as the origin, I denote the unkno wn lo cation of the sho oter with co ordi-\n",
      "natesα andβ , or alpha and beta . The lo cation of a spatter is lab eled x . The\n",
      "angle the opp onen t sho ots at is θ or theta .\n",
      "The P ain tball problem is a mo di\u001ced v ersion of the Ligh thouse problem, a\n",
      "common example of Ba y esian analysis. My notation follo ws the presen tation\n",
      "of the problem in D.S. Sivia's, Data A nalysis: a Bayesian T utorial, Se c ond\n",
      "Edition (Oxford, 2006).\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "paintball.py . F or more information see Section 0.3.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 112}\n",
      "------------------------\n",
      "page_content='96 Chapter 9. T w o Dimensions\n",
      "αβ\n",
      "θ\n",
      "xshooter\n",
      "wall\n",
      "Figure 9.1: Diagram of the la y out for the pain tball problem.\n",
      "9.2 The suite\n",
      "T o get started, w e need a Suite that represen ts a set of h yp otheses ab out the\n",
      "lo cation of the opp onen t. Eac h h yp othesis is a pair of co ordinates: (alpha,\n",
      "beta) .\n",
      "Here is the de\u001cnition of the P ain tball suite:\n",
      "class Paintball(thinkbayes.Suite, thinkbayes.Joint):\n",
      "def __init__(self, alphas, betas, locations):\n",
      "self.locations = locations\n",
      "pairs = [(alpha, beta)\n",
      "for alpha in alphas\n",
      "for beta in betas]\n",
      "thinkbayes.Suite.__init__(self, pairs)\n",
      "Paintball inherits from Suite , whic h w e ha v e seen b efore, and Joint , whic h\n",
      "I will explain so on.\n",
      "alphas is the list of p ossible v alues for alpha ; betas is the list of v alues for\n",
      "beta . pairs is a list of all (alpha, beta) pairs.\n",
      "locations is a list of p ossible lo cations along the w all; it is stored for use in\n",
      "Likelihood .\n",
      "The ro om is 30 feet wide and 50 feet long, so here's the co de that creates the\n",
      "suite:\n",
      "alphas = range(0, 31)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 113}\n",
      "------------------------\n",
      "page_content='9.3. T rigonometry 97\n",
      "0 10 20 30 40 50\n",
      "Distance0.00.20.40.60.81.0Prob\n",
      "alpha\n",
      "beta\n",
      "Figure 9.2: P osterior CDF s for alpha and beta , giv en the data.\n",
      "betas = range(1, 51)\n",
      "locations = range(0, 31)\n",
      "suite = Paintball(alphas, betas, locations)\n",
      "This prior distribution assumes that all lo cations in the ro om are equally lik ely .\n",
      "Giv en a map of the ro om, w e migh t c ho ose a more detailed prior, but w e'll\n",
      "start simple.\n",
      "9.3 T rigonometry\n",
      "No w w e need a lik eliho o d function, whic h means w e ha v e to \u001cgure out the\n",
      "lik eliho o d of hitting an y sp ot along the w all, giv en the lo cation of the opp onen t.\n",
      "As a simple mo del, imagine that the opp onen t is lik e a rotating turret, equally\n",
      "lik ely to sho ot in an y direction. In that case, he is most lik ely to hit the w all\n",
      "at lo cation alpha , and less lik ely to hit the w all far a w a y from alpha .\n",
      "With a little trigonometry , w e can compute the probabilit y of hitting an y sp ot\n",
      "along the w all. Imagine that the sho oter \u001cres a shot at angle θ ; the p ellet\n",
      "w ould hit the w all at lo cation x , where\n",
      "x−α=βtanθ' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 114}\n",
      "------------------------\n",
      "page_content='98 Chapter 9. T w o Dimensions\n",
      "0 5 10 15 20 25 30\n",
      "Distance0.0100.0150.0200.0250.0300.0350.0400.0450.0500.055Probbeta = 10\n",
      "beta = 20\n",
      "beta = 40\n",
      "Figure 9.3: PMF of lo cation giv en alpha=10 , for sev eral v alues of beta .\n",
      "Solving this equation for θ yields\n",
      "θ=tan−1(x−α\n",
      "β)\n",
      "So giv en a lo cation on the w all, w e can \u001cnd θ .\n",
      "T aking the deriv ativ e of the \u001crst equation with resp ect to θ yields\n",
      "dx\n",
      "dθ=β\n",
      "cos2θ\n",
      "This deriv ativ e is what I'll call the \u0010stra\u001cng sp eed\u0011, whic h is the sp eed of the\n",
      "target lo cation along the w all as θ increases. The probabilit y of hitting a giv en\n",
      "p oin t on the w all is in v ersely related to stra\u001cng sp eed.\n",
      "If w e kno w the co ordinates of the sho oter and a lo cation along the w all, w e\n",
      "can compute stra\u001cng sp eed:\n",
      "def StrafingSpeed(alpha, beta, x):\n",
      "theta = math.atan2(x - alpha, beta)\n",
      "speed = beta / math.cos(theta)**2\n",
      "return speed\n",
      "alpha and beta are the co ordinates of the sho oter; x is the lo cation of a\n",
      "spatter. The result is the deriv ativ e of x with resp ect to theta .\n",
      "No w w e can compute a Pmf that represen ts the probabilit y of hitting an y\n",
      "lo cation on the w all. MakeLocationPmf tak es alpha and beta , the co ordinates\n",
      "of the sho oter, and locations , a list of p ossible v alues of x .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 115}\n",
      "------------------------\n",
      "page_content='9.4. Lik eliho o d 99\n",
      "def MakeLocationPmf(alpha, beta, locations):\n",
      "pmf = thinkbayes.Pmf()\n",
      "for x in locations:\n",
      "prob = 1.0 / StrafingSpeed(alpha, beta, x)\n",
      "pmf.Set(x, prob)\n",
      "pmf.Normalize()\n",
      "return pmf\n",
      "MakeLocationPmf computes the probabilit y of hitting eac h lo cation, whic h is\n",
      "in v ersely related to stra\u001cng sp eed. The result is a Pmf of lo cations and their\n",
      "probabilities.\n",
      "Figure 9.3 sho ws the Pmf of lo cation with alpha = 10 and a range of v alues\n",
      "for beta . F or all v alues of b eta the most lik ely spatter lo cation is x = 10 ; as\n",
      "beta increases, so do es the spread of the Pmf.\n",
      "9.4 Lik eliho o d\n",
      "No w all w e need is a lik eliho o d function. W e can use MakeLocationPmf to\n",
      "compute the lik eliho o d of an y v alue of x , giv en the co ordinates of the opp onen t.\n",
      "def Likelihood(self, data, hypo):\n",
      "alpha, beta = hypo\n",
      "x = data\n",
      "pmf = MakeLocationPmf(alpha, beta, self.locations)\n",
      "like = pmf.Prob(x)\n",
      "return like\n",
      "Again, alpha and beta are the h yp othetical co ordinates of the sho oter, and x\n",
      "is the lo cation of an observ ed spatter.\n",
      "pmf con tains the probabilit y of eac h lo cation, giv en the co ordinates of the\n",
      "sho oter. F rom this Pmf, w e select the probabilit y of the observ ed lo cation.\n",
      "And w e're done. T o up date the suite, w e can use UpdateSet , whic h is inherited\n",
      "from Suite .\n",
      "suite.UpdateSet([15, 16, 18, 21])\n",
      "The result is a distribution that maps eac h (alpha, beta) pair to a p osterior\n",
      "probabilit y .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 116}\n",
      "------------------------\n",
      "page_content='100 Chapter 9. T w o Dimensions\n",
      "9.5 Join t distributions\n",
      "When eac h v alue in a distribution is a tuple of v ariables, it is called a join t\n",
      "distribution b ecause it represen ts the distributions of the v ariables together,\n",
      "that is \u0010join tly\u0011. A join t distribution con tains the distributions of the v ariables,\n",
      "as w ell as information ab out the relationships among them.\n",
      "Giv en a join t distribution, w e can compute the distributions of eac h v ariable\n",
      "indep enden tly , whic h are called the marginal distributions .\n",
      "thinkbayes.Joint pro vides a metho d that computes marginal distributions:\n",
      "# class Joint:\n",
      "def Marginal(self, i):\n",
      "pmf = Pmf()\n",
      "for vs, prob in self.Items():\n",
      "pmf.Incr(vs[i], prob)\n",
      "return pmf\n",
      "i is the index of the v ariable w e w an t; in this example i=0 indicates the\n",
      "distribution of alpha , and i=1 indicates the distribution of beta .\n",
      "Here's the co de that extracts the marginal distributions:\n",
      "marginal_alpha = suite.Marginal(0)\n",
      "marginal_beta = suite.Marginal(1)\n",
      "Figure 9.2 sho ws the results (con v erted to CDF s). The median v alue for alpha\n",
      "is 18, near the cen ter of mass of the observ ed spatters. F or beta , the most\n",
      "lik ely v alues are close to the w all, but b ey ond 10 feet the distribution is almost\n",
      "uniform, whic h indicates that the data do not distinguish strongly b et w een\n",
      "these p ossible lo cations.\n",
      "Giv en the p osterior marginals, w e can compute credible in terv als for eac h\n",
      "co ordinate indep enden tly:\n",
      "print ' alpha CI ' , marginal_alpha.CredibleInterval(50)\n",
      "print ' beta CI ' , marginal_beta.CredibleInterval(50)\n",
      "The 50% credible in terv als are (14, 21) for alpha and (5, 31) for beta . So\n",
      "the data pro vide evidence that the sho oter is in the near side of the ro om. But\n",
      "it is not strong evidence. The 90% credible in terv als co v er most of the ro om!\n",
      "9.6 Conditional distributions\n",
      "The marginal distributions con tain information ab out the v ariables indep en-\n",
      "den tly , but they do not capture the dep endence b et w een v ariables, if an y .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 117}\n",
      "------------------------\n",
      "page_content='9.6. Conditional distributions 101\n",
      "0 5 10 15 20 25 30\n",
      "Distance0.000.010.020.030.040.050.060.070.080.09Probbeta = 10\n",
      "beta = 20\n",
      "beta = 40\n",
      "Figure 9.4: P osterior distributions for alpha conditioned on sev eral v alues of\n",
      "beta .\n",
      "One w a y to visualize dep endence is b y computing conditional distributions .\n",
      "thinkbayes.Joint pro vides a metho d that do es that:\n",
      "def Conditional(self, i, j, val):\n",
      "pmf = Pmf()\n",
      "for vs, prob in self.Items():\n",
      "if vs[j] != val: continue\n",
      "pmf.Incr(vs[i], prob)\n",
      "pmf.Normalize()\n",
      "return pmf\n",
      "Again, i is the index of the v ariable w e w an t; j is the index of the conditioning\n",
      "v ariable, and val is the conditional v alue.\n",
      "The result is the distribution of the i th v ariable under the condition that the\n",
      "j th v ariable is val .\n",
      "F or example, the follo wing co de computes the conditional distributions of\n",
      "alpha for a range of v alues of beta :\n",
      "betas = [10, 20, 40]\n",
      "for beta in betas:\n",
      "cond = suite.Conditional(0, 1, beta)\n",
      "Figure 9.4 sho ws the results, whic h w e could fully describ e as \u0010p osterior con-\n",
      "ditional marginal distributions.\u0011 Whew!' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 118}\n",
      "------------------------\n",
      "page_content='102 Chapter 9. T w o Dimensions\n",
      "0 5 10 15 20 25 30\n",
      "alpha01020304050beta\n",
      "255075\n",
      "Figure 9.5: Credible in terv als for the co ordinates of the opp onen t.\n",
      "If the v ariables w ere indep enden t, the conditional distributions w ould all b e the\n",
      "same. Since they are all di\u001beren t, w e can tell the v ariables are dep enden t. F or\n",
      "example, if w e kno w (someho w) that beta = 10 , the conditional distribution\n",
      "of alpha is fairly narro w. F or larger v alues of beta , the distribution of alpha\n",
      "is wider.\n",
      "9.7 Credible in terv als\n",
      "Another w a y to visualize the p osterior join t distribution is to compute credible\n",
      "in terv als. When w e lo ok ed at credible in terv als in Section 3.5, I skipp ed o v er a\n",
      "subtle p oin t: for a giv en distribution, there are man y in terv als with the same\n",
      "lev el of credibilit y . F or example, if y ou w an t a 50% credible in terv al, y ou could\n",
      "c ho ose an y set of v alues whose probabilit y adds up to 50%.\n",
      "When the v alues are one-dimensional, it is most common to c ho ose the cen tral\n",
      "credible in terv al ; for example, the cen tral 50% credible in terv al con tains all\n",
      "v alues b et w een the 25th and 75th p ercen tiles.\n",
      "In m ultiple dimensions it is less ob vious what the righ t credible in terv al should\n",
      "b e. The b est c hoice migh t dep end on con text, but one common c hoice is the\n",
      "maxim um lik eliho o d credible in terv al, whic h con tains the most lik ely v alues\n",
      "that add up to 50% (or some other p ercen tage).\n",
      "thinkbayes.Joint pro vides a metho d that computes maxim um lik eliho o d\n",
      "credible in terv als.\n",
      "# class Joint:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 119}\n",
      "------------------------\n",
      "page_content='9.7. Credible in terv als 103\n",
      "def MaxLikeInterval(self, percentage=90):\n",
      "interval = []\n",
      "total = 0\n",
      "t = [(prob, val) for val, prob in self.Items()]\n",
      "t.sort(reverse=True)\n",
      "for prob, val in t:\n",
      "interval.append(val)\n",
      "total += prob\n",
      "if total >= percentage/100.0:\n",
      "break\n",
      "return interval\n",
      "The \u001crst step is to mak e a list of the v alues in the suite, sorted in descending\n",
      "order b y probabilit y . Next w e tra v erse the list, adding eac h v alue to the\n",
      "in terv al, un til the total probabilit y exceeds percentage . The result is a list\n",
      "of v alues from the suite. Notice that this set of v alues is not necessarily\n",
      "con tiguous.\n",
      "T o visualize the in terv als, I wrote a function that \u0010colors\u0011 eac h v alue according\n",
      "to ho w man y in terv als it app ears in:\n",
      "def MakeCrediblePlot(suite):\n",
      "d = dict((pair, 0) for pair in suite.Values())\n",
      "percentages = [75, 50, 25]\n",
      "for p in percentages:\n",
      "interval = suite.MaxLikeInterval(p)\n",
      "for pair in interval:\n",
      "d[pair] += 1\n",
      "return d\n",
      "d is a dictionary that maps from eac h v alue in the suite to the n um b er of\n",
      "in terv als it app ears in. The lo op computes in terv als for sev eral p ercen tages\n",
      "and mo di\u001ces d .\n",
      "Figure 9.5 sho ws the result. The 25% credible in terv al is the dark est region\n",
      "near the b ottom w all. F or higher p ercen tages, the credible in terv al is bigger,\n",
      "of course, and sk ew ed to w ard the righ t side of the ro om.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 120}\n",
      "------------------------\n",
      "page_content='104 Chapter 9. T w o Dimensions\n",
      "9.8 Discussion\n",
      "This c hapter sho ws that the Ba y esian framew ork from the previous c hapters\n",
      "can b e extended to handle a t w o-dimensional parameter space. The only\n",
      "di\u001berence is that eac h h yp othesis is represen ted b y a tuple of parameters.\n",
      "I also presen ted Joint , whic h is a paren t class that pro vides metho ds that\n",
      "apply to join t distributions: Marginal , Conditional , and MakeLikeInterval .\n",
      "In ob ject-orien ted terms, Joint is a mixin (see http://en.wikipedia.org/\n",
      "wiki/Mixin ).\n",
      "There is a lot of new v o cabulary in this c hapter, so let's review:\n",
      "Join t distribution: A distribution that represen ts all p ossible v alues in a\n",
      "m ultidimensional space and their probabilities. The example in this\n",
      "c hapter is a t w o-dimensional space made up of the co ordinates alpha and\n",
      "beta . The join t distribution represen ts the probabilit y of eac h ( alpha ,\n",
      "beta ) pair.\n",
      "Marginal distribution: The distribution of one parameter in a join t distri-\n",
      "bution, treating the other parameters as unkno wn. F or example, Fig-\n",
      "ure 9.2 sho ws the distributions of alpha and beta indep enden tly .\n",
      "Conditional distribution: The distribution of one parameter in a join t dis-\n",
      "tribution, conditioned on one or more of the other parameters. Figure 9.4\n",
      "sho ws sev eral distributions for alpha , conditioned on di\u001beren t v alues of\n",
      "beta .\n",
      "Giv en the join t distribution, y ou can compute marginal and conditional distri-\n",
      "butions. With enough conditional distributions, y ou could re-create the join t\n",
      "distribution, at least appro ximately . But giv en the marginal distributions y ou\n",
      "cannot re-create the join t distribution b ecause y ou ha v e lost information ab out\n",
      "the dep endence b et w een v ariables.\n",
      "If there are n p ossible v alues for eac h of t w o parameters, most op erations on the\n",
      "join t distribution tak e time prop ortional to n2. If there are d parameters, run\n",
      "time is prop ortional to nd, whic h quic kly b ecomes impractical as the n um b er\n",
      "of dimensions increases.\n",
      "If y ou can pro cess a million h yp otheses in a reasonable amoun t of time, y ou\n",
      "could handle t w o dimensions with 1000 v alues for eac h parameter, or three\n",
      "dimensions with 100 v alues eac h, or six dimensions with 10 v alues eac h.\n",
      "If y ou need more dimensions, or more v alues p er dimension, there are opti-\n",
      "mizations y ou can try . I presen t an example in Chapter 15.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 121}\n",
      "------------------------\n",
      "page_content='9.9. Exercises 105\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "paintball.py . F or more information see Section 0.3.\n",
      "9.9 Exercises\n",
      "Exercise 9.1 In our simple mo del, the opp onen t is equally lik ely to sho ot in\n",
      "an y direction. As an exercise, let's consider impro v emen ts to this mo del.\n",
      "The analysis in this c hapter suggests that a sho oter is most lik ely to hit the\n",
      "closest w all. But in realit y , if the opp onen t is close to a w all, he is unlik ely to\n",
      "sho ot at the w all b ecause he is unlik ely to see a target b et w een himself and\n",
      "the w all.\n",
      "Design an impro v ed mo del that tak es this b eha vior in to accoun t. T ry to \u001cnd\n",
      "a mo del that is more realistic, but not to o complicated.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 122}\n",
      "------------------------\n",
      "page_content='106 Chapter 9. T w o Dimensions' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 123}\n",
      "------------------------\n",
      "page_content='Chapter 10\n",
      "Approximate Bayesian\n",
      "Computation\n",
      "10.1 The V ariabilit y Hyp othesis\n",
      "I ha v e a soft sp ot for crank science. Recen tly I visited Norum b ega T o w er, whic h\n",
      "is an enduring mon umen t to the crac kp ot theories of Eb en Norton Horsford,\n",
      "in v en tor of double-acting baking p o wder and fak e history . But that's not what\n",
      "this c hapter is ab out.\n",
      "This c hapter is ab out the V ariabilit y Hyp othesis, whic h\n",
      "\"originated in the early nineteen th cen tury with Johann Mec k el,\n",
      "who argued that males ha v e a greater range of abilit y than females,\n",
      "esp ecially in in telligence. In other w ords, he b eliev ed that most\n",
      "geniuses and most men tally retarded p eople are men. Because he\n",
      "considered males to b e the 'sup erior animal,' Mec k el concluded\n",
      "that females' lac k of v ariation w as a sign of inferiorit y .\"\n",
      "F rom http://en.wikipedia.org/wiki/Variability_\n",
      "hypothesis .\n",
      "I particularly lik e that last part, b ecause I susp ect that if it turns out that\n",
      "w omen are actually more v ariable, Mec k el w ould tak e that as a sign of inferi-\n",
      "orit y , to o. An yw a y , y ou will not b e surprised to hear that the evidence for the\n",
      "V ariabilit y Hyp othesis is w eak.\n",
      "Nev ertheless, it came up in m y class recen tly when w e lo ok ed at data from the\n",
      "CDC's Beha vioral Risk F actor Surv eillance System (BRFSS), sp eci\u001ccally the\n",
      "self-rep orted heigh ts of adult American men and w omen. The dataset includes\n",
      "resp onses from 154407 men and 254722 w omen. Here's what w e found:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 124}\n",
      "------------------------\n",
      "page_content='108 Chapter 10. Appro ximate Ba y esian Computation\n",
      " The a v erage heigh t for men is 178 cm; the a v erage heigh t for w omen is\n",
      "163 cm. So men are taller, on a v erage. No surprise there.\n",
      " F or men the standard deviation is 7.7 cm; for w omen it is 7.3 cm. So in\n",
      "absolute terms, men's heigh ts are more v ariable.\n",
      " But to compare v ariabilit y b et w een groups, it is more meaningful to use\n",
      "the co e\u001ecien t of v ariation (CV), whic h is the standard deviation divided\n",
      "b y the mean. It is a dimensionless measure of v ariabilit y relativ e to scale.\n",
      "F or men CV is 0.0433; for w omen it is 0.0444.\n",
      "That's v ery close, so w e could conclude that this dataset pro vides w eak evi-\n",
      "dence against the V ariabilit y Hyp othesis. But w e can use Ba y esian metho ds\n",
      "to mak e that conclusion more precise. And answ ering this question giv es me\n",
      "a c hance to demonstrate some tec hniques for w orking with large datasets.\n",
      "I will pro ceed in a few steps:\n",
      "1. W e'll start with the simplest implemen tation, but it only w orks for\n",
      "datasets smaller than 1000 v alues.\n",
      "2. By computing probabilities under a log transform, w e can scale up to\n",
      "the full size of the dataset, but the computation gets slo w.\n",
      "3. Finally , w e sp eed things up substan tially with Appro ximate Ba y esian\n",
      "Computation, also kno wn as ABC.\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "variability.py . F or more information see Section 0.3.\n",
      "10.2 Mean and standard deviation\n",
      "In Chapter 9 w e estimated t w o parameters sim ultaneously using a join t distri-\n",
      "bution. In this c hapter w e use the same metho d to estimate the parameters of\n",
      "a Gaussian distribution: the mean, mu , and the standard deviation, sigma .\n",
      "F or this problem, I de\u001cne a Suite called Height that represen ts a map from\n",
      "eac h mu, sigma pair to its probabilit y:\n",
      "class Height(thinkbayes.Suite, thinkbayes.Joint):\n",
      "def __init__(self, mus, sigmas):\n",
      "pairs = [(mu, sigma)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 125}\n",
      "------------------------\n",
      "page_content='10.2. Mean and standard deviation 109\n",
      "for mu in mus\n",
      "for sigma in sigmas]\n",
      "thinkbayes.Suite.__init__(self, pairs)\n",
      "mus is a sequence of p ossible v alues for mu ; sigmas is a sequence of v alues for\n",
      "sigma . The prior distribution is uniform o v er all mu, sigma pairs.\n",
      "The lik eliho o d function is easy . Giv en h yp othetical v alues of mu and sigma , w e\n",
      "compute the lik eliho o d of a particular v alue, x . That's what EvalGaussianPdf\n",
      "do es, so all w e ha v e to do is use it:\n",
      "# class Height\n",
      "def Likelihood(self, data, hypo):\n",
      "x = data\n",
      "mu, sigma = hypo\n",
      "like = thinkbayes.EvalGaussianPdf(x, mu, sigma)\n",
      "return like\n",
      "If y ou ha v e studied statistics from a mathematical p ersp ectiv e, y ou kno w that\n",
      "when y ou ev aluate a PDF, y ou get a probabilit y densit y . In order to get a\n",
      "probabilit y , y ou ha v e to in tegrate probabilit y densities o v er some range.\n",
      "But for our purp oses, w e don't need a probabilit y; w e just need something\n",
      "prop ortional to the probabilit y w e w an t. A probabilit y densit y do es that job\n",
      "nicely .\n",
      "The hardest part of this problem turns out to b e c ho osing appropriate ranges\n",
      "for mus and sigmas . If the range is to o small, w e omit some p ossibilities with\n",
      "non-negligible probabilit y and get the wrong answ er. If the range is to o big,\n",
      "w e get the righ t answ er, but w aste computational p o w er.\n",
      "So this is an opp ortunit y to use classical estimation to mak e Ba y esian tec h-\n",
      "niques more e\u001ecien t. Sp eci\u001ccally , w e can use classical estimators to \u001cnd a\n",
      "lik ely lo cation for mu and sigma , and use the standard errors of those esti-\n",
      "mates to c ho ose a lik ely spread.\n",
      "If the true parameters of the distribution are µ andσ , and w e tak e a sample\n",
      "ofn v alues, an estimator of µ is the sample mean, m .\n",
      "And an estimator of σ is the sample standard v ariance, s .\n",
      "The standard error of the estimated µ iss/√n and the standard error of the\n",
      "estimatedσ iss/√\n",
      "2(n−1) .\n",
      "Here's the co de to compute all that:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 126}\n",
      "------------------------\n",
      "page_content='110 Chapter 10. Appro ximate Ba y esian Computation\n",
      "def FindPriorRanges(xs, num_points, num_stderrs=3.0):\n",
      "# compute m and s\n",
      "n = len(xs)\n",
      "m = numpy.mean(xs)\n",
      "s = numpy.std(xs)\n",
      "# compute ranges for m and s\n",
      "stderr_m = s / math.sqrt(n)\n",
      "mus = MakeRange(m, stderr_m, num_stderrs)\n",
      "stderr_s = s / math.sqrt(2 * (n-1))\n",
      "sigmas = MakeRange(s, stderr_s, num_stderrs)\n",
      "return mus, sigmas\n",
      "xs is the dataset. num_points is the desired n um b er of v alues in the range.\n",
      "num_stderrs is the width of the range on eac h side of the estimate, in n um b er\n",
      "of standard errors.\n",
      "The return v alue is a pair of sequences, mus and sigmas .\n",
      "Here's MakeRange :\n",
      "def MakeRange(estimate, stderr, num_stderrs):\n",
      "spread = stderr * num_stderrs\n",
      "array = numpy.linspace(estimate-spread,\n",
      "estimate+spread,\n",
      "num_points)\n",
      "return array\n",
      "numpy.linspace mak es an arra y of equally spaced elemen ts b et w een\n",
      "estimate-spread and estimate+spread , including b oth.\n",
      "10.3 Up date\n",
      "Finally here's the co de to mak e and up date the suite:\n",
      "mus, sigmas = FindPriorRanges(xs, num_points)\n",
      "suite = Height(mus, sigmas)\n",
      "suite.UpdateSet(xs)\n",
      "print suite.MaximumLikelihood()\n",
      "This pro cess migh t seem b ogus, b ecause w e use the data to c ho ose the range\n",
      "of the prior distribution, and then use the data again to do the up date. In\n",
      "general, using the same data t wice is, in fact, b ogus.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 127}\n",
      "------------------------\n",
      "page_content='10.4. The p osterior distribution of CV 111\n",
      "But in this case it is ok. Really . W e use the data to c ho ose the range for the\n",
      "prior, but only to a v oid computing a lot of probabilities that w ould ha v e b een\n",
      "v ery small an yw a y . With num_stderrs=4 , the range is big enough to co v er\n",
      "all v alues with non-negligible lik eliho o d. After that, making it bigger has no\n",
      "e\u001bect on the results.\n",
      "In e\u001bect, the prior is uniform o v er all v alues of mu and sigma , but for compu-\n",
      "tational e\u001eciency w e ignore all the v alues that don't matter.\n",
      "10.4 The p osterior distribution of CV\n",
      "Once w e ha v e the p osterior join t distribution of mu and sigma , w e can compute\n",
      "the distribution of CV for men and w omen, and then the probabilit y that one\n",
      "exceeds the other.\n",
      "T o compute the distribution of CV, w e en umerate pairs of mu and sigma :\n",
      "def CoefVariation(suite):\n",
      "pmf = thinkbayes.Pmf()\n",
      "for (mu, sigma), p in suite.Items():\n",
      "pmf.Incr(sigma/mu, p)\n",
      "return pmf\n",
      "Then w e use thinkbayes.PmfProbGreater to compute the probabilit y that\n",
      "men are more v ariable.\n",
      "The analysis itself is simple, but there are t w o more issues w e ha v e to deal\n",
      "with:\n",
      "1. As the size of the dataset increases, w e run in to a series of computational\n",
      "problems due to the limitations of \u001doating-p oin t arithmetic.\n",
      "2. The dataset con tains a n um b er of extreme v alues that are almost cer-\n",
      "tainly errors. W e will need to mak e the estimation pro cess robust in the\n",
      "presence of these outliers.\n",
      "The follo wing sections explain these problems and their solutions.\n",
      "10.5 Under\u001do w\n",
      "If w e select the \u001crst 100 v alues from the BRFSS dataset and run the analysis\n",
      "I just describ ed, it runs without errors and w e get p osterior distributions that\n",
      "lo ok reasonable.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 128}\n",
      "------------------------\n",
      "page_content='112 Chapter 10. Appro ximate Ba y esian Computation\n",
      "If w e select the \u001crst 1000 v alues and run the program again, w e get an error\n",
      "in Pmf.Normalize :\n",
      "ValueError: total probability is zero.\n",
      "The problem is that w e are using probabilit y densities to compute lik eliho o ds,\n",
      "and densities from con tin uous distributions tend to b e small. And if y ou tak e\n",
      "1000 small v alues and m ultiply them together, the result is v ery small. In this\n",
      "case it is so small it can't b e represen ted b y a \u001doating-p oin t n um b er, so it gets\n",
      "rounded do wn to zero, whic h is called under\u001do w . And if all probabilities in\n",
      "the distribution are 0, it's not a distribution an y more.\n",
      "A p ossible solution is to renormalize the Pmf after eac h up date, or after eac h\n",
      "batc h of 100. That w ould w ork, but it w ould b e slo w.\n",
      "A b etter alternativ e is to compute lik eliho o ds under a log transform. That\n",
      "w a y , instead of m ultiplying small v alues, w e can add up log lik eliho o ds. Pmf\n",
      "pro vides metho ds Log , LogUpdateSet and Exp to mak e this pro cess easy .\n",
      "Log computes the log of the probabilities in a Pmf:\n",
      "# class Pmf\n",
      "def Log(self):\n",
      "m = self.MaxLike()\n",
      "for x, p in self.d.iteritems():\n",
      "if p:\n",
      "self.Set(x, math.log(p/m))\n",
      "else:\n",
      "self.Remove(x)\n",
      "Before applying the log transform Log uses MaxLike to \u001cnd m , the highest\n",
      "probabilit y in the Pmf. It divide all probabilities b y m , so the highest proba-\n",
      "bilit y gets normalized to 1, whic h yields a log of 0. The other log probabilities\n",
      "are all negativ e. If there are an y v alues in the Pmf with probabilit y 0, they\n",
      "are remo v ed.\n",
      "While the Pmf is under a log transform, w e can't use Update , UpdateSet ,\n",
      "or Normalize . The result w ould b e nonsensical; if y ou try , Pmf raises an\n",
      "exception. Instead, w e ha v e to use LogUpdate and LogUpdateSet .\n",
      "Here's the implemen tation of LogUpdateSet :\n",
      "# class Suite\n",
      "def LogUpdateSet(self, dataset):\n",
      "for data in dataset:\n",
      "self.LogUpdate(data)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 129}\n",
      "------------------------\n",
      "page_content='10.6. Log-lik eliho o d 113\n",
      "LogUpdateSet lo ops through the data and calls LogUpdate :\n",
      "# class Suite\n",
      "def LogUpdate(self, data):\n",
      "for hypo in self.Values():\n",
      "like = self.LogLikelihood(data, hypo)\n",
      "self.Incr(hypo, like)\n",
      "LogUpdate is just lik e Update except that it calls LogLikelihood instead of\n",
      "Likelihood , and Incr instead of Mult .\n",
      "Using log-lik eliho o ds a v oids the problem with under\u001do w, but while the Pmf is\n",
      "under the log transform, there's not m uc h w e can do with it. W e ha v e to use\n",
      "Exp to in v ert the transform:\n",
      "# class Pmf\n",
      "def Exp(self):\n",
      "m = self.MaxLike()\n",
      "for x, p in self.d.iteritems():\n",
      "self.Set(x, math.exp(p-m))\n",
      "If the log-lik eliho o ds are large negativ e n um b ers, the resulting lik eliho o ds\n",
      "migh t under\u001do w. So Exp \u001cnds the maxim um log-lik eliho o d, m , and shifts all\n",
      "the lik eliho o ds up b y m . The resulting distribution has a maxim um lik eliho o d\n",
      "of 1. This pro cess in v erts the log transform with minimal loss of precision.\n",
      "10.6 Log-lik eliho o d\n",
      "No w all w e need is LogLikelihood .\n",
      "# class Height\n",
      "def LogLikelihood(self, data, hypo):\n",
      "x = data\n",
      "mu, sigma = hypo\n",
      "loglike = scipy.stats.norm.logpdf(x, mu, sigma)\n",
      "return loglike\n",
      "norm.logpdf computes the log-lik eliho o d of the Gaussian PDF.\n",
      "Here's what the whole up date pro cess lo oks lik e:\n",
      "suite.Log()\n",
      "suite.LogUpdateSet(xs)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 130}\n",
      "------------------------\n",
      "page_content='114 Chapter 10. Appro ximate Ba y esian Computation\n",
      "suite.Exp()\n",
      "suite.Normalize()\n",
      "T o review, Log puts the suite under a log transform. LogUpdateSet calls\n",
      "LogUpdate , whic h calls LogLikelihood . LogUpdate uses Pmf.Incr , b ecause\n",
      "adding a log-lik eliho o d is the same as m ultiplying b y a lik eliho o d.\n",
      "After the up date, the log-lik eliho o ds are large negativ e n um b ers, so Exp shifts\n",
      "them up b efore in v erting the transform, whic h is ho w w e a v oid under\u001do w.\n",
      "Once the suite is transformed bac k, the probabilities are \u0010linear\u0011 again, whic h\n",
      "means \u0010not logarithmic\u0011, so w e can use Normalize again.\n",
      "Using this algorithm, w e can pro cess the en tire dataset without under\u001do w, but\n",
      "it is still slo w. On m y computer it migh t tak e an hour. W e can do b etter.\n",
      "10.7 A little optimization\n",
      "This section uses math and computational optimization to sp eed things up\n",
      "b y a factor of 100. But the follo wing section presen ts an algorithm that is\n",
      "ev en faster. So if y ou w an t to get righ t to the go o d stu\u001b, feel free to skip this\n",
      "section.\n",
      "Suite.LogUpdateSet calls LogUpdate once for eac h data p oin t. W e can sp eed\n",
      "it up b y computing the log-lik eliho o d of the en tire dataset at once.\n",
      "W e'll start with the Gaussian PDF:\n",
      "1\n",
      "σ√\n",
      "2πexp[\n",
      "−1\n",
      "2(x−µ\n",
      "σ)2]\n",
      "and compute the log (dropping the constan t term):\n",
      "−logσ−1\n",
      "2(x−µ\n",
      "σ)2\n",
      "Giv en a sequence of v alues, xi , the total log-lik eliho o d is\n",
      "∑\n",
      "i−logσ−1\n",
      "2(xi−µ\n",
      "σ)2\n",
      "Pulling out the terms that don't dep end on i , w e get\n",
      "−nlogσ−1\n",
      "2σ2∑\n",
      "i(xi−µ)2' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 131}\n",
      "------------------------\n",
      "page_content='10.7. A little optimization 115\n",
      "whic h w e can translate in to Python:\n",
      "# class Height\n",
      "def LogUpdateSetFast(self, data):\n",
      "xs = tuple(data)\n",
      "n = len(xs)\n",
      "for hypo in self.Values():\n",
      "mu, sigma = hypo\n",
      "total = Summation(xs, mu)\n",
      "loglike = -n * math.log(sigma) - total / 2 / sigma**2\n",
      "self.Incr(hypo, loglike)\n",
      "By itself, this w ould b e a small impro v emen t, but it creates an opp ortunit y\n",
      "for a bigger one. Notice that the summation only dep ends on mu , not sigma ,\n",
      "so w e only ha v e to compute it once for eac h v alue of mu .\n",
      "T o a v oid recomputing, I factor out a function that computes the summation,\n",
      "and memoize it so it stores previously computed results in a dictionary (see\n",
      "http://en.wikipedia.org/wiki/Memoization ):\n",
      "def Summation(xs, mu, cache={}):\n",
      "try:\n",
      "return cache[xs, mu]\n",
      "except KeyError:\n",
      "ds = [(x-mu)**2 for x in xs]\n",
      "total = sum(ds)\n",
      "cache[xs, mu] = total\n",
      "return total\n",
      "cache stores previously computed sums. The try statemen t returns a result\n",
      "from the cac he if p ossible; otherwise it computes the summation, then cac hes\n",
      "and returns the result.\n",
      "The only catc h is that w e can't use a list as a k ey in the cac he, b ecause it is\n",
      "not a hashable t yp e. That's wh y LogUpdateSetFast con v erts the dataset to\n",
      "a tuple.\n",
      "This optimization sp eeds up the computation b y ab out a factor of 100, pro-\n",
      "cessing the en tire dataset (154 407 men and 254 722 w omen) in less than a\n",
      "min ute on m y not-v ery-fast computer.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 132}\n",
      "------------------------\n",
      "page_content='116 Chapter 10. Appro ximate Ba y esian Computation\n",
      "10.8 ABC\n",
      "But ma yb e y ou don't ha v e that kind of time. In that case, Appro ximate\n",
      "Ba y esian Computation (ABC) migh t b e the w a y to go. The motiv ation b ehind\n",
      "ABC is that the lik eliho o d of an y particular dataset is:\n",
      "1. V ery small, esp ecially for large datasets, whic h is wh y w e had to use the\n",
      "log transform,\n",
      "2. Exp ensiv e to compute, whic h is wh y w e had to do so m uc h optimization,\n",
      "and\n",
      "3. Not really what w e w an t an yw a y .\n",
      "W e don't really care ab out the lik eliho o d of seeing the exact dataset w e sa w.\n",
      "Esp ecially for con tin uous v ariables, w e care ab out the lik eliho o d of seeing an y\n",
      "dataset lik e the one w e sa w.\n",
      "F or example, in the Euro problem, w e don't care ab out the order of the coin\n",
      "\u001dips, only the total n um b er of heads and tails. And in the lo comotiv e problem,\n",
      "w e don't care ab out whic h particular trains w ere seen, only the n um b er of\n",
      "trains and the maxim um of the serial n um b ers.\n",
      "Similarly , in the BRFSS sample, w e don't really w an t to kno w the probabilit y\n",
      "of seeing one particular set of v alues (esp ecially since there are h undreds of\n",
      "thousands of them). It is more relev an t to ask, \u0010If w e sample 100,000 p eople\n",
      "from a p opulation with h yp othetical v alues of µ andσ , what w ould b e the\n",
      "c hance of collecting a sample with the observ ed mean and v ariance?\u0011\n",
      "F or samples from a Gaussian distribution, w e can answ er this question e\u001e-\n",
      "cien tly b ecause w e can \u001cnd the distribution of the sample statistics analytically .\n",
      "In fact, w e already did it when w e computed the range of the prior.\n",
      "If y ou dra w n v alues from a Gaussian distribution with parameters µ andσ ,\n",
      "and compute the sample mean, m , the distribution of m is Gaussian with\n",
      "parameters µ andσ/√n .\n",
      "Similarly , the distribution of the sample standard deviation, s , is Gaussian\n",
      "with parameters σ andσ/√\n",
      "2(n−1) .\n",
      "W e can use these sample distributions to compute the lik eliho o d of the sample\n",
      "statistics,m ands , giv en h yp othetical v alues for µ andσ . Here's a new v ersion\n",
      "of LogUpdateSet that do es it:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 133}\n",
      "------------------------\n",
      "page_content='10.9. Robust estimation 117\n",
      "def LogUpdateSetABC(self, data):\n",
      "xs = data\n",
      "n = len(xs)\n",
      "# compute sample statistics\n",
      "m = numpy.mean(xs)\n",
      "s = numpy.std(xs)\n",
      "for hypo in sorted(self.Values()):\n",
      "mu, sigma = hypo\n",
      "# compute log likelihood of m, given hypo\n",
      "stderr_m = sigma / math.sqrt(n)\n",
      "loglike = EvalGaussianLogPdf(m, mu, stderr_m)\n",
      "#compute log likelihood of s, given hypo\n",
      "stderr_s = sigma / math.sqrt(2 * (n-1))\n",
      "loglike += EvalGaussianLogPdf(s, sigma, stderr_s)\n",
      "self.Incr(hypo, loglike)\n",
      "On m y computer this function pro cesses the en tire dataset in ab out a second,\n",
      "and the result agrees with the exact result with ab out 5 digits of precision.\n",
      "10.9 Robust estimation\n",
      "W e are almost ready to lo ok at results, but w e ha v e one more problem to deal\n",
      "with. There are a n um b er of outliers in this dataset that are almost certainly\n",
      "errors. F or example, there are three adults with rep orted heigh t of 61 cm,\n",
      "whic h w ould place them among the shortest living adults in the w orld. A t the\n",
      "other end, there are four w omen with rep orted heigh t 229 cm, just short of\n",
      "the tallest w omen in the w orld.\n",
      "It is not imp ossible that these v alues are correct, but it is unlik ely , whic h\n",
      "mak es it hard to kno w ho w to deal with them. And w e ha v e to get it righ t,\n",
      "b ecause these extreme v alues ha v e a disprop ortionate e\u001bect on the estimated\n",
      "v ariabilit y .\n",
      "Because ABC is based on summary statistics, rather than the en tire dataset,\n",
      "w e can mak e it more robust b y c ho osing summary statistics that are robust in\n",
      "the presence of outliers. F or example, rather than use the sample mean and' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 134}\n",
      "------------------------\n",
      "page_content='118 Chapter 10. Appro ximate Ba y esian Computation\n",
      "178.46 178.48 178.50 178.52 178.54\n",
      "Mean height (cm)7.287.297.307.317.327.337.347.35Stddev (cm)\n",
      "0.0010.0020.002\n",
      "0.0030.0040.005\n",
      "0.006Posterior joint distribution\n",
      "Figure 10.1: Con tour plot of the p osterior join t distribution of mean and\n",
      "standard deviation of heigh t for men in the U.S.\n",
      "163.46 163.47 163.48 163.49 163.50 163.51 163.52 163.53\n",
      "Mean height (cm)6.997.007.017.027.037.04Stddev (cm)\n",
      "0.0010.0020.002\n",
      "0.0030.0040.005\n",
      "0.006Posterior joint distribution\n",
      "Figure 10.2: Con tour plot of the p osterior join t distribution of mean and\n",
      "standard deviation of heigh t for w omen in the U.S.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 135}\n",
      "------------------------\n",
      "page_content='10.9. Robust estimation 119\n",
      "standard deviation, w e could use the median and in ter-quartile range (IQR),\n",
      "whic h is the di\u001berence b et w een the 25th and 75th p ercen tiles.\n",
      "More generally , w e could compute an in ter-p ercen tile range (IPR) that spans\n",
      "an y giv en fraction of the distribution, p :\n",
      "def MedianIPR(xs, p):\n",
      "cdf = thinkbayes.MakeCdfFromList(xs)\n",
      "median = cdf.Percentile(50)\n",
      "alpha = (1-p) / 2\n",
      "ipr = cdf.Value(1-alpha) - cdf.Value(alpha)\n",
      "return median, ipr\n",
      "xs is a sequence of v alues. p is the desired range; for example, p=0.5 yields\n",
      "the in ter-quartile range.\n",
      "MedianIPR w orks b y computing the CDF of xs , then extracting the median\n",
      "and the di\u001berence b et w een t w o p ercen tiles.\n",
      "W e can con v ert from ipr to an estimate of sigma using the Gaussian CDF\n",
      "to compute the fraction of the distribution co v ered b y a giv en n um b er of\n",
      "standard deviations. F or example, it is a w ell-kno wn rule of th um b that 68%\n",
      "of a Gaussian distribution falls within one standard deviation of the mean,\n",
      "whic h lea v es 16% in eac h tail. If w e compute the range b et w een the 16th and\n",
      "84th p ercen tiles, w e exp ect the result to b e 2 * sigma . So w e can estimate\n",
      "sigma b y computing the 68% IPR and dividing b y 2.\n",
      "More generally w e could use an y n um b er of sigmas . MedianS p erforms the\n",
      "more general v ersion of this computation:\n",
      "def MedianS(xs, num_sigmas):\n",
      "half_p = thinkbayes.StandardGaussianCdf(num_sigmas) - 0.5\n",
      "median, ipr = MedianIPR(xs, half_p * 2)\n",
      "s = ipr / 2 / num_sigmas\n",
      "return median, s\n",
      "Again, xs is the sequence of v alues; num_sigmas is the n um b er of standard de-\n",
      "viations the results should b e based on. The result is median , whic h estimates\n",
      "µ , and s , whic h estimates σ .\n",
      "Finally , in LogUpdateSetABC w e can replace the sample mean and standard\n",
      "deviation with median and s . And that prett y m uc h do es it.\n",
      "It migh t seem o dd that w e are using observ ed p ercen tiles to estimate µ andσ ,\n",
      "but it is an example of the \u001dexibilit y of the Ba y esian approac h. In e\u001bect w e are' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 136}\n",
      "------------------------\n",
      "page_content='120 Chapter 10. Appro ximate Ba y esian Computation\n",
      "0.0405 0.0410 0.0415 0.0420 0.0425 0.0430 0.0435\n",
      "Coefficient of variation0.00.20.40.60.81.0Probability\n",
      "male\n",
      "female\n",
      "Figure 10.3: P osterior distributions of CV for men and w omen, based on robust\n",
      "estimators.\n",
      "asking, \u0010Giv en h yp othetical v alues for µ andσ , and a sampling pro cess that\n",
      "has some c hance of in tro ducing errors, what is the lik eliho o d of generating a\n",
      "giv en set of sample statistics?\u0011\n",
      "W e are free to c ho ose an y sample statistics w e lik e, up to a p oin t: µ and\n",
      "σ determine the lo cation and spread of a distribution, so w e need to c ho ose\n",
      "statistics that capture those c haracteristics. F or example, if w e c hose the 49th\n",
      "and 51st p ercen tiles, w e w ould get v ery little information ab out spread, so it\n",
      "w ould lea v e the estimate of σ relativ ely unconstrained b y the data. All v alues\n",
      "of sigma w ould ha v e nearly the same lik eliho o d of pro ducing the observ ed\n",
      "v alues, so the p osterior distribution of sigma w ould lo ok a lot lik e the prior.\n",
      "10.10 Who is more v ariable?\n",
      "Finally w e are ready to answ er the question w e started with: is the co e\u001ecien t\n",
      "of v ariation greater for men than for w omen?\n",
      "Using ABC based on the median and IPR with num_sigmas=1 , I computed\n",
      "p osterior join t distributions for mu and sigma . Figures 10.1 and 10.2 sho w\n",
      "the results as a con tour plot with mu on the x-axis, sigma on the y-axis, and\n",
      "probabilit y on the z-axis.\n",
      "F or eac h join t distribution, I computed the p osterior distribution of CV. Fig-\n",
      "ure 10.3 sho ws these distributions for men and w omen. The mean for men is\n",
      "0.0410; for w omen it is 0.0429. Since there is no o v erlap b et w een the distribu-' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 137}\n",
      "------------------------\n",
      "page_content='10.11. Discussion 121\n",
      "tions, w e conclude with near certain t y that w omen are more v ariable in heigh t\n",
      "than men.\n",
      "So is that the end of the V ariabilit y Hyp othesis? Sadly , no. It turns\n",
      "out that this result dep ends on the c hoice of the in ter-p ercen tile range.\n",
      "With num_sigmas=1 , w e conclude that w omen are more v ariable, but with\n",
      "num_sigmas=2 w e conclude with equal con\u001cdence that men are more v ariable.\n",
      "The reason for the di\u001berence is that there are more men of short stature, and\n",
      "their distance from the mean is greater.\n",
      "So our ev aluation of the V ariabilit y Hyp othesis dep ends on the in terpretation\n",
      "of \u0010v ariabilit y .\u0011 With num_sigmas=1 w e fo cus on p eople near the mean. As\n",
      "w e increase num_sigmas , w e giv e more w eigh t to the extremes.\n",
      "T o decide whic h emphasis is appropriate, w e w ould need a more precise state-\n",
      "men t of the h yp othesis. As it is, the V ariabilit y Hyp othesis ma y b e to o v ague\n",
      "to ev aluate.\n",
      "Nev ertheless, it help ed me demonstrate sev eral new ideas and, I hop e y ou\n",
      "agree, it mak es an in teresting example.\n",
      "10.11 Discussion\n",
      "There are t w o w a ys y ou migh t think of ABC. One in terpretation is that it is,\n",
      "as the name suggests, an appro ximation that is faster to compute than the\n",
      "exact v alue.\n",
      "But remem b er that Ba y esian analysis is alw a ys based on mo deling decisions,\n",
      "whic h implies that there is no \u0010exact\u0011 solution. F or an y in teresting ph ysical\n",
      "system there are man y p ossible mo dels, and eac h mo del yields di\u001beren t results.\n",
      "T o in terpret the results, w e ha v e to ev aluate the mo dels.\n",
      "So another in terpretation of ABC is that it represen ts an alternativ e mo del\n",
      "of the lik eliho o d. When w e compute p(D|H) , w e are asking \u0010What is the\n",
      "lik eliho o d of the data under a giv en h yp othesis?\u0011\n",
      "F or large datasets, the lik eliho o d of the data is v ery small, whic h is a hin t that\n",
      "w e migh t not b e asking the righ t question. What w e really w an t to kno w is\n",
      "the lik eliho o d of an y outcome lik e the data, where the de\u001cnition of \u0010lik e\u0011 is\n",
      "y et another mo deling decision.\n",
      "The underlying idea of ABC is that t w o datasets are alik e if they yield the\n",
      "same summary statistics. But in some cases, lik e the example in this c hapter,\n",
      "it is not ob vious whic h summary statistics to c ho ose.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 138}\n",
      "------------------------\n",
      "page_content='122 Chapter 10. Appro ximate Ba y esian Computation\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "variability.py . F or more information see Section 0.3.\n",
      "10.12 Exercises\n",
      "Exercise 10.1 An \u0010e\u001bect size\u0011 is a statistic in tended to measure the di\u001berence\n",
      "b et w een t w o groups (see http://en.wikipedia.org/wiki/Effect_size ).\n",
      "F or example, w e could use data from the BRFSS to estimate the di\u001berence\n",
      "in heigh t b et w een men and w omen. By sampling v alues from the p osterior\n",
      "distributions of µ andσ , w e could generate the p osterior distribution of this\n",
      "di\u001berence.\n",
      "But it migh t b e b etter to use a dimensionless measure of e\u001bect size, rather\n",
      "than a di\u001berence measured in cm. One option is to use divide through b y the\n",
      "standard deviation (similar to what w e did with the co e\u001ecien t of v ariation).\n",
      "If the parameters for Group 1 are (µ1,σ1) , and the parameters for Group 2 are\n",
      "(µ2,σ2) , the dimensionless e\u001bect size is\n",
      "µ1−µ2\n",
      "(σ1+σ2)/2\n",
      "W rite a function that tak es join t distributions of mu and sigma for t w o groups\n",
      "and returns the p osterior distribution of e\u001bect size.\n",
      "Hin t: if en umerating all pairs from the t w o distributions tak es to o long, con-\n",
      "sider random sampling.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 139}\n",
      "------------------------\n",
      "page_content='Chapter 11\n",
      "Hypothesis T esting\n",
      "11.1 Bac k to the Euro problem\n",
      "In Section 4.1 I presen ted a problem from MacKa y's Information The ory,\n",
      "Infer enc e, and L e arning A lgorithms :\n",
      "A statistical statemen t app eared in \u0010The Guardian\" on F rida y Jan-\n",
      "uary 4, 2002:\n",
      "When spun on edge 250 times, a Belgian one-euro coin\n",
      "came up heads 140 times and tails 110. `It lo oks v ery\n",
      "suspicious to me,' said Barry Bligh t, a statistics lecturer\n",
      "at the London Sc ho ol of Economics. `If the coin w ere\n",
      "un biased, the c hance of getting a result as extreme as\n",
      "that w ould b e less than 7%.'\n",
      "But do these data giv e evidence that the coin is biased rather than\n",
      "fair?\n",
      "W e estimated the probabilit y that the coin w ould land face up, but w e didn't\n",
      "really answ er MacKa y's question: Do the data giv e evidence that the coin is\n",
      "biased?\n",
      "In Chapter 4 I prop osed that data are in fa v or of a h yp othesis if the data are\n",
      "more lik ely under the h yp othesis than under the alternativ e or, equiv alen tly ,\n",
      "if the Ba y es factor is greater than 1.\n",
      "In the Euro example, w e ha v e t w o h yp otheses to consider: I'll use F for the\n",
      "h yp othesis that the coin is fair and B for the h yp othesis that it is biased.\n",
      "If the coin is fair, it is easy to compute the lik eliho o d of the data, p(D|F) . In\n",
      "fact, w e already wrote the function that do es it.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 140}\n",
      "------------------------\n",
      "page_content='124 Chapter 11. Hyp othesis T esting\n",
      "def Likelihood(self, data, hypo):\n",
      "x = hypo / 100.0\n",
      "head, tails = data\n",
      "like = x**heads * (1-x)**tails\n",
      "return like\n",
      "T o use it w e can create a Euro suite and in v ok e Likelihood :\n",
      "suite = Euro()\n",
      "likelihood = suite.Likelihood(data, 50)\n",
      "p(D|F) is5.5·10−76, whic h do esn't tell us m uc h except that the probabilit y\n",
      "of seeing an y particular dataset is v ery small. It tak es t w o lik eliho o ds to mak e\n",
      "a ratio, so w e also ha v e to compute p(D|B) .\n",
      "It is not ob vious ho w to compute the lik eliho o d of B , b ecause it's not ob vious\n",
      "what \u0010biased\u0011 means.\n",
      "One p ossibilit y is to c heat and lo ok at the data b efore w e de\u001cne the h yp othesis.\n",
      "In that case w e w ould sa y that \u0010biased\u0011 means that the probabilit y of heads is\n",
      "140/250.\n",
      "actual_percent = 100.0 * 140 / 250\n",
      "likelihood = suite.Likelihood(data, actual_percent)\n",
      "This v ersion of B I call B_cheat ; the lik eliho o d of b_cheat is34·10−76and\n",
      "the lik eliho o d ratio is 6.1. So w e w ould sa y that the data are evidence in fa v or\n",
      "of this v ersion of B .\n",
      "But using the data to form ulate the h yp othesis is ob viously b ogus. By that\n",
      "de\u001cnition, an y dataset w ould b e evidence in fa v or of B , unless the observ ed\n",
      "p ercen tage of heads is exactly 50%.\n",
      "11.2 Making a fair comparison\n",
      "T o mak e a legitimate comparison, w e ha v e to de\u001cne B without lo oking at the\n",
      "data. So let's try a di\u001beren t de\u001cnition. If y ou insp ect a Belgian Euro coin,\n",
      "y ou migh t notice that the \u0010heads\u0011 side is more prominen t than the \u0010tails\u0011 side.\n",
      "Y ou migh t exp ect the shap e to ha v e some e\u001bect on x , but b e unsure whether\n",
      "it mak es heads more or less lik ely . So y ou migh t sa y \u0010I think the coin is biased\n",
      "so thatx is either 0.6 or 0.4, but I am not sure whic h.\u0011\n",
      "W e can think of this v ersion, whic h I'll call B_two as a h yp othesis made up of\n",
      "t w o sub-h yp otheses. W e can compute the lik eliho o d for eac h sub-h yp othesis\n",
      "and then compute the a v erage lik eliho o d.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 141}\n",
      "------------------------\n",
      "page_content='11.2. Making a fair comparison 125\n",
      "like40 = suite.Likelihood(data, 40)\n",
      "like60 = suite.Likelihood(data, 60)\n",
      "likelihood = 0.5 * like40 + 0.5 * like60\n",
      "The lik eliho o d ratio (or Ba y es factor) for b_two is 1.3, whic h means the data\n",
      "pro vide w eak evidence in fa v or of b_two .\n",
      "More generally , supp ose y ou susp ect that the coin is biased, but y ou ha v e no\n",
      "clue ab out the v alue of x . In that case y ou migh t build a Suite, whic h I call\n",
      "b_uniform , to represen t sub-h yp otheses from 0 to 100.\n",
      "b_uniform = Euro(xrange(0, 101))\n",
      "b_uniform.Remove(50)\n",
      "b_uniform.Normalize()\n",
      "I initialize b_uniform with v alues from 0 to 100. I remo v ed the sub-h yp othesis\n",
      "thatx is 50%, b ecause if x is 50% the coin is fair, but it has almost no e\u001bect\n",
      "on the result whether y ou remo v e it or not.\n",
      "T o compute the lik eliho o d of b_uniform w e compute the lik eliho o d of eac h\n",
      "sub-h yp othesis and accum ulate a w eigh ted a v erage.\n",
      "def SuiteLikelihood(suite, data):\n",
      "total = 0\n",
      "for hypo, prob in suite.Items():\n",
      "like = suite.Likelihood(data, hypo)\n",
      "total += prob * like\n",
      "return total\n",
      "The lik eliho o d ratio for b_uniform is 0.47, whic h means that the data are\n",
      "w eak evidence against b_uniform , compared to F .\n",
      "If y ou think ab out the computation p erformed b y SuiteLikelihood , y ou\n",
      "migh t notice that it is similar to an up date. T o refresh y our memory , here's\n",
      "the Update function:\n",
      "def Update(self, data):\n",
      "for hypo in self.Values():\n",
      "like = self.Likelihood(data, hypo)\n",
      "self.Mult(hypo, like)\n",
      "return self.Normalize()\n",
      "And here's Normalize :\n",
      "def Normalize(self):\n",
      "total = self.Total()\n",
      "factor = 1.0 / total\n",
      "for x in self.d:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 142}\n",
      "------------------------\n",
      "page_content='126 Chapter 11. Hyp othesis T esting\n",
      "self.d[x] *= factor\n",
      "return total\n",
      "The return v alue from Normalize is the total of the probabilities in the Suite,\n",
      "whic h is the a v erage of the lik eliho o ds for the sub-h yp otheses, w eigh ted b y the\n",
      "prior probabilities. And Update passes this v alue along, so instead of using\n",
      "SuiteLikelihood , w e could compute the lik eliho o d of b_uniform lik e this:\n",
      "likelihood = b_uniform.Update(data)\n",
      "11.3 The triangle prior\n",
      "In Chapter 4 w e also considered a triangle-shap ed prior that giv es higher\n",
      "probabilit y to v alues of x near 50%. If w e think of this prior as a suite of\n",
      "sub-h yp otheses, w e can compute its lik eliho o d lik e this:\n",
      "b_triangle = TrianglePrior()\n",
      "likelihood = b_triangle.Update(data)\n",
      "The lik eliho o d ratio for b_triangle is 0.84, compared to F , so again w e w ould\n",
      "sa y that the data are w eak evidence against B .\n",
      "The follo wing table sho ws the priors w e ha v e considered, the lik eliho o d of eac h,\n",
      "and the lik eliho o d ratio (or Ba y es factor) relativ e to F .\n",
      "Hyp othesis Lik eliho o d Ba y es\n",
      "×10−76F actor\n",
      "F 5.5 \u0015\n",
      "B_cheat 34 6.1\n",
      "B_two 7.4 1.3\n",
      "B_uniform 2.6 0.47\n",
      "B_triangle 4.6 0.84\n",
      "Dep ending on whic h de\u001cnition w e c ho ose, the data migh t pro vide evidence\n",
      "for or against the h yp othesis that the coin is biased, but in either case it is\n",
      "relativ ely w eak evidence.\n",
      "In summary , w e can use Ba y esian h yp othesis testing to compare the lik eli-\n",
      "ho o d ofF andB , but w e ha v e to do some w ork to sp ecify precisely what\n",
      "B means. This sp eci\u001ccation dep ends on bac kground information ab out coins\n",
      "and their b eha vior when spun, so p eople could reasonably disagree ab out the\n",
      "righ t de\u001cnition.\n",
      "My presen tation of this example follo ws Da vid MacKa y's discussion, and comes\n",
      "to the same conclusion. Y ou can do wnload the co de I used in this c hapter from\n",
      "http://thinkbayes.com/euro3.py . F or more information see Section 0.3.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 143}\n",
      "------------------------\n",
      "page_content='11.4. Discussion 127\n",
      "11.4 Discussion\n",
      "The Ba y es factor for B_uniform is 0.47, whic h means that the data pro vide\n",
      "evidence against this h yp othesis, compared to F . In the previous section I\n",
      "c haracterized this evidence as \u0010w eak,\u0011 but didn't sa y wh y .\n",
      "P art of the answ er is historical. Harold Je\u001breys, an early prop onen t of Ba y esian\n",
      "statistics, suggested a scale for in terpreting Ba y es factors:\n",
      "Ba y es Strength\n",
      "F actor\n",
      "1 \u0015 3 Barely w orth men tioning\n",
      "3 \u0015 10 Substan tial\n",
      "10 \u0015 30 Strong\n",
      "30 \u0015 100 V ery strong\n",
      "> 100 Decisiv e\n",
      "In the example, the Ba y es factor is 0.47 in fa v or of B_uniform , so it is 2.1 in\n",
      "fa v or ofF , whic h Je\u001breys w ould consider \u0010barely w orth men tioning.\u0011 Other\n",
      "authors ha v e suggested v ariations on the w ording. T o a v oid arguing ab out\n",
      "adjectiv es, w e could think ab out o dds instead.\n",
      "If y our prior o dds are 1:1, and y ou see evidence with Ba y es factor 2, y our\n",
      "p osterior o dds are 2:1. In terms of probabilit y , the data c hanged y our degree\n",
      "of b elief from 50% to 66%. F or most real w orld problems, that c hange w ould\n",
      "b e small relativ e to mo deling errors and other sources of uncertain t y .\n",
      "On the other hand, if y ou had seen evidence with Ba y es factor 100, y our\n",
      "p osterior o dds w ould b e 100:1 or more than 99%. Whether or not y ou agree\n",
      "that suc h evidence is \u0010decisiv e,\u0011 it is certainly strong.\n",
      "11.5 Exercises\n",
      "Exercise 11.1 Some p eople b eliev e in the existence of extra-sensory p ercep-\n",
      "tion (ESP); for example, the abilit y of some p eople to guess the v alue of an\n",
      "unseen pla ying card with probabilit y b etter than c hance.\n",
      "What is y our prior degree of b elief in this kind of ESP? Do y ou think it is as\n",
      "lik ely to exist as not? Or are y ou more sk eptical ab out it? W rite do wn y our\n",
      "prior o dds.\n",
      "No w compute the strength of the evidence it w ould tak e to con vince y ou that\n",
      "ESP is at least 50% lik ely to exist. What Ba y es factor w ould b e needed to\n",
      "mak e y ou 90% sure that ESP exists?' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 144}\n",
      "------------------------\n",
      "page_content='128 Chapter 11. Hyp othesis T esting\n",
      "Exercise 11.2 Supp ose that y our answ er to the previous question is 1000;\n",
      "that is, evidence with Ba y es factor 1000 in fa v or of ESP w ould b e su\u001ecien t to\n",
      "c hange y our mind.\n",
      "No w supp ose that y ou read a pap er in a resp ectable p eer-review ed scien ti\u001cc\n",
      "journal that presen ts evidence with Ba y es factor 1000 in fa v or of ESP . W ould\n",
      "that c hange y our mind?\n",
      "If not, ho w do y ou resolv e the apparen t con tradiction? Y ou migh t \u001cnd it\n",
      "helpful to read ab out Da vid Hume's article, \u0010Of Miracles,\u0011 at http://en.\n",
      "wikipedia.org/wiki/Of_Miracles .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 145}\n",
      "------------------------\n",
      "page_content='Chapter 12\n",
      "Evidence\n",
      "12.1 In terpreting SA T scores\n",
      "Supp ose y ou are the Dean of A dmission at a small engineering college in Mas-\n",
      "sac h usetts, and y ou are considering t w o candidates, Alice and Bob, whose\n",
      "quali\u001ccations are similar in man y w a ys, with the exception that Alice got a\n",
      "higher score on the Math p ortion of the SA T, a standardized test in tended to\n",
      "measure preparation for college-lev el w ork in mathematics.\n",
      "If Alice got 780 and Bob got a 740 (out of a p ossible 800), y ou migh t w an t\n",
      "to kno w whether that di\u001berence is evidence that Alice is b etter prepared than\n",
      "Bob, and what the strength of that evidence is.\n",
      "No w in realit y , b oth scores are v ery go o d, and b oth candidates are probably\n",
      "w ell prepared for college math. So the real Dean of A dmission w ould probably\n",
      "suggest that w e c ho ose the candidate who b est demonstrates the other skills\n",
      "and attitudes w e lo ok for in studen ts. But as an example of Ba y esian h yp oth-\n",
      "esis testing, let's stic k with a narro w er question: \u0010Ho w strong is the evidence\n",
      "that Alice is b etter prepared than Bob?\u0011\n",
      "T o answ er that question, w e need to mak e some mo deling decisions. I'll start\n",
      "with a simpli\u001ccation I kno w is wrong; then w e'll come bac k and impro v e the\n",
      "mo del. I pretend, temp orarily , that all SA T questions are equally di\u001ecult.\n",
      "A ctually , the designers of the SA T c ho ose questions with a range of di\u001ecult y ,\n",
      "b ecause that impro v es the abilit y to measure statistical di\u001berences b et w een\n",
      "test-tak ers.\n",
      "But if w e c ho ose a mo del where all questions are equally di\u001ecult, w e can de\u001cne\n",
      "a c haracteristic, p_correct , for eac h test-tak er, whic h is the probabilit y of\n",
      "answ ering an y question correctly . This simpli\u001ccation mak es it easy to compute\n",
      "the lik eliho o d of a giv en score.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 146}\n",
      "------------------------\n",
      "page_content='130 Chapter 12. Evidence\n",
      "12.2 The scale\n",
      "In order to understand SA T scores, w e ha v e to understand the scoring and\n",
      "scaling pro cess. Eac h test-tak er gets a ra w score based on the n um b er of\n",
      "correct and incorrect questions. The ra w score is con v erted to a scaled score\n",
      "in the range 200\u0015800.\n",
      "In 2009, there w ere 54 questions on the math SA T. The ra w score for eac h\n",
      "test-tak er is the n um b er of questions answ ered correctly min us a p enalt y of\n",
      "1/4 p oin t for eac h question answ ered incorrectly .\n",
      "The College Board, whic h administers the SA T, publishes the map from ra w\n",
      "scores to scaled scores. I ha v e do wnloaded that data and wrapp ed it in an\n",
      "In terp olator ob ject that pro vides a forw ard lo okup (from ra w score to scaled)\n",
      "and a rev erse lo okup (from scaled score to ra w).\n",
      "Y ou can do wnload the co de for this example from http://thinkbayes.com/\n",
      "sat.py . F or more information see Section 0.3.\n",
      "12.3 The prior\n",
      "The College Board also publishes the distribution of scaled scores for all test-\n",
      "tak ers. If w e con v ert eac h scaled score to a ra w score, and divide b y the\n",
      "n um b er of questions, the result is an estimate of p_correct . So w e can use\n",
      "the distribution of ra w scores to mo del the prior distribution of p_correct .\n",
      "Here is the co de that reads and pro cesses the data:\n",
      "class Exam(object):\n",
      "def __init__(self):\n",
      "self.scale = ReadScale()\n",
      "scores = ReadRanks()\n",
      "score_pmf = thinkbayes.MakePmfFromDict(dict(scores))\n",
      "self.raw = self.ReverseScale(score_pmf)\n",
      "self.max_score = max(self.raw.Values())\n",
      "self.prior = DivideValues(self.raw, self.max_score)\n",
      "Exam encapsulates the information w e ha v e ab out the exam. ReadScale and\n",
      "ReadRanks read \u001cles and return ob jects that con tain the data: self.scale is\n",
      "the Interpolator that con v erts from ra w to scaled scores and bac k; scores\n",
      "is a list of (score, frequency) pairs.\n",
      "score_pmf is the Pmf of scaled scores. self.raw is the Pmf of ra w scores,\n",
      "and self.prior is the Pmf of p_correct .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 147}\n",
      "------------------------\n",
      "page_content='12.3. The prior 131\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "p_correct0.00.20.40.60.81.0CDFprior\n",
      "Figure 12.1: Prior distribution of p_correct for SA T test-tak ers.\n",
      "Figure 12.1 sho ws the prior distribution of p_correct . This distribution is\n",
      "appro ximately Gaussian, but it is compressed at the extremes. By design,\n",
      "the SA T has the most p o w er to discriminate b et w een test-tak ers within t w o\n",
      "standard deviations of the mean, and less p o w er outside that range.\n",
      "F or eac h test-tak er, I de\u001cne a Suite called Sat that represen ts the distribution\n",
      "of p_correct . Here's the de\u001cnition:\n",
      "class Sat(thinkbayes.Suite):\n",
      "def __init__(self, exam, score):\n",
      "thinkbayes.Suite.__init__(self)\n",
      "self.exam = exam\n",
      "self.score = score\n",
      "# start with the prior distribution\n",
      "for p_correct, prob in exam.prior.Items():\n",
      "self.Set(p_correct, prob)\n",
      "# update based on an exam score\n",
      "self.Update(score)\n",
      "__init__ tak es an Exam ob ject and a scaled score. It mak es a cop y of the\n",
      "prior distribution and then up dates itself based on the exam score.\n",
      "As usual, w e inherit Update from Suite and pro vide Likelihood :\n",
      "def Likelihood(self, data, hypo):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 148}\n",
      "------------------------\n",
      "page_content='132 Chapter 12. Evidence\n",
      "0.70 0.75 0.80 0.85 0.90 0.95 1.00\n",
      "p_correct0.00.20.40.60.81.0CDFposterior 780\n",
      "posterior 740\n",
      "Figure 12.2: P osterior distributions of p_correct for Alice and Bob.\n",
      "p_correct = hypo\n",
      "score = data\n",
      "k = self.exam.Reverse(score)\n",
      "n = self.exam.max_score\n",
      "like = thinkbayes.EvalBinomialPmf(k, n, p_correct)\n",
      "return like\n",
      "hypo is a h yp othetical v alue of p_correct , and data is a scaled score.\n",
      "T o k eep things simple, I in terpret the ra w score as the n um b er of correct an-\n",
      "sw ers, ignoring the p enalt y for wrong answ ers. With this simpli\u001ccation, the\n",
      "lik eliho o d is giv en b y the binomial distribution, whic h computes the probabil-\n",
      "it y ofk correct resp onses out of n questions.\n",
      "12.4 P osterior\n",
      "Figure 12.2 sho ws the p osterior distributions of p_correct for Alice and Bob\n",
      "based on their exam scores. W e can see that they o v erlap, so it is p ossible\n",
      "that p_correct is actually higher for Bob, but it seems unlik ely .\n",
      "Whic h brings us bac k to the original question, \u0010Ho w strong is the evidence that\n",
      "Alice is b etter prepared than Bob?\u0011 W e can use the p osterior distributions of\n",
      "p_correct to answ er this question.\n",
      "T o form ulate the question in terms of Ba y esian h yp othesis testing, I de\u001cne t w o\n",
      "h yp otheses:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 149}\n",
      "------------------------\n",
      "page_content='12.4. P osterior 133\n",
      "A : p_correct is higher for Alice than for Bob.\n",
      "B : p_correct is higher for Bob than for Alice.\n",
      "T o compute the lik eliho o d of A , w e can en umerate all pairs of v alues from\n",
      "the p osterior distributions and add up the total probabilit y of the cases where\n",
      "p_correct is higher for Alice than for Bob. And w e already ha v e a function,\n",
      "thinkbayes.PmfProbGreater , that do es that.\n",
      "So w e can de\u001cne a Suite that computes the p osterior probabilities of A andB :\n",
      "class TopLevel(thinkbayes.Suite):\n",
      "def Update(self, data):\n",
      "a_sat, b_sat = data\n",
      "a_like = thinkbayes.PmfProbGreater(a_sat, b_sat)\n",
      "b_like = thinkbayes.PmfProbLess(a_sat, b_sat)\n",
      "c_like = thinkbayes.PmfProbEqual(a_sat, b_sat)\n",
      "a_like += c_like / 2\n",
      "b_like += c_like / 2\n",
      "self.Mult( ' A ' , a_like)\n",
      "self.Mult( ' B ' , b_like)\n",
      "self.Normalize()\n",
      "Usually when w e de\u001cne a new Suite, w e inherit Update and pro vide\n",
      "Likelihood . In this case I o v erride Update , b ecause it is easier to ev aluate\n",
      "the lik eliho o d of b oth h yp otheses at the same time.\n",
      "The data passed to Update are Sat ob jects that represen t the p osterior distri-\n",
      "butions of p_correct .\n",
      "a_like is the total probabilit y that p_correct is higher for Alice; b_like is\n",
      "that probabilit y that it is higher for Bob.\n",
      "c_like is the probabilit y that they are \u0010equal,\u0011 but this equalit y is an artifact\n",
      "of the decision to mo del p_correct with a set of discrete v alues. If w e use\n",
      "more v alues, c_like is smaller, and in the extreme, if p_correct is con tin uous,\n",
      "c_like is zero. So I treat c_like as a kind of round-o\u001b error and split it ev enly\n",
      "b et w een a_like and b_like .\n",
      "Here is the co de that creates TopLevel and up dates it:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 150}\n",
      "------------------------\n",
      "page_content='134 Chapter 12. Evidence\n",
      "exam = Exam()\n",
      "a_sat = Sat(exam, 780)\n",
      "b_sat = Sat(exam, 740)\n",
      "top = TopLevel( ' AB ' )\n",
      "top.Update((a_sat, b_sat))\n",
      "top.Print()\n",
      "The lik eliho o d of A is 0.79 and the lik eliho o d of B is 0.21. The lik eliho o d ratio\n",
      "(or Ba y es factor) is 3.8, whic h means that these test scores are evidence that\n",
      "Alice is b etter than Bob at answ ering SA T questions. If w e b eliev ed, b efore\n",
      "seeing the test scores, that A andB w ere equally lik ely , then after seeing the\n",
      "scores w e should b eliev e that the probabilit y of A is 79%, whic h means there\n",
      "is still a 21% c hance that Bob is actually b etter prepared.\n",
      "12.5 A b etter mo del\n",
      "Remem b er that the analysis w e ha v e done so far is based on the simpli\u001ccation\n",
      "that all SA T questions are equally di\u001ecult. In realit y , some are easier than\n",
      "others, whic h means that the di\u001berence b et w een Alice and Bob migh t b e ev en\n",
      "smaller.\n",
      "But ho w big is the mo deling error? If it is small, w e conclude that the \u001crst\n",
      "mo del\u0016based on the simpli\u001ccation that all questions are equally di\u001ecult\u0016is\n",
      "go o d enough. If it's large, w e need a b etter mo del.\n",
      "In the next few sections, I dev elop a b etter mo del and disco v er (sp oiler alert!)\n",
      "that the mo deling error is small. So if y ou are satis\u001ced with the simple mo del,\n",
      "y ou can skip to the next c hapter. If y ou w an t to see ho w the more realistic\n",
      "mo del w orks, read on...\n",
      " Assume that eac h test-tak er has some degree of efficacy , whic h mea-\n",
      "sures their abilit y to answ er SA T questions.\n",
      " Assume that eac h question has some lev el of difficulty .\n",
      " Finally , assume that the c hance that a test-tak er answ ers a question cor-\n",
      "rectly is related to efficacy and difficulty according to this function:\n",
      "def ProbCorrect(efficacy, difficulty, a=1):\n",
      "return 1 / (1 + math.exp(-a * (efficacy - difficulty)))' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 151}\n",
      "------------------------\n",
      "page_content='12.5. A b etter mo del 135\n",
      "This function is a simpli\u001ced v ersion of the curv e used in item resp onse the-\n",
      "ory , whic h y ou can read ab out at http://en.wikipedia.org/wiki/Item_\n",
      "response_theory . efficacy and difficulty are considered to b e on the\n",
      "same scale, and the probabilit y of getting a question righ t dep ends only on the\n",
      "di\u001berence b et w een them.\n",
      "When efficacy and difficulty are equal, the probabilit y of getting the\n",
      "question righ t is 50%. As efficacy increases, this probabilit y approac hes\n",
      "100%. As it decreases (or as difficulty increases), the probabilit y approac hes\n",
      "0%.\n",
      "Giv en the distribution of efficacy across test-tak ers and the distribution of\n",
      "difficulty across questions, w e can compute the exp ected distribution of ra w\n",
      "scores. W e'll do that in t w o steps. First, for a p erson with giv en efficacy ,\n",
      "w e'll compute the distribution of ra w scores.\n",
      "def PmfCorrect(efficacy, difficulties):\n",
      "pmf0 = thinkbayes.Pmf([0])\n",
      "ps = [ProbCorrect(efficacy, diff) for diff in difficulties]\n",
      "pmfs = [BinaryPmf(p) for p in ps]\n",
      "dist = sum(pmfs, pmf0)\n",
      "return dist\n",
      "difficulties is a list of di\u001eculties, one for eac h question. ps is a list of\n",
      "probabilities, and pmfs is a list of t w o-v alued Pmf ob jects; here's the function\n",
      "that mak es them:\n",
      "def BinaryPmf(p):\n",
      "pmf = thinkbayes.Pmf()\n",
      "pmf.Set(1, p)\n",
      "pmf.Set(0, 1-p)\n",
      "return pmf\n",
      "dist is the sum of these Pmfs. Remem b er from Section 5.4 that when w e add\n",
      "up Pmf ob jects, the result is the distribution of the sums. In order to use\n",
      "Python's sum to add up Pmfs, w e ha v e to pro vide pmf0 whic h is the iden tit y\n",
      "for Pmfs, so pmf + pmf0 is alw a ys pmf .\n",
      "If w e kno w a p erson's e\u001ecacy , w e can compute their distribution of ra w scores.\n",
      "F or a group of p eople with a di\u001beren t e\u001ecacies, the resulting distribution of\n",
      "ra w scores is a mixture. Here's the co de that computes the mixture:\n",
      "# class Exam:\n",
      "def MakeRawScoreDist(self, efficacies):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 152}\n",
      "------------------------\n",
      "page_content='136 Chapter 12. Evidence\n",
      "0 10 20 30 40 50 60\n",
      "raw score0.00.20.40.60.81.0CDFdata\n",
      "model\n",
      "Figure 12.3: A ctual distribution of ra w scores and a mo del to \u001ct it.\n",
      "pmfs = thinkbayes.Pmf()\n",
      "for efficacy, prob in efficacies.Items():\n",
      "scores = PmfCorrect(efficacy, self.difficulties)\n",
      "pmfs.Set(scores, prob)\n",
      "mix = thinkbayes.MakeMixture(pmfs)\n",
      "return mix\n",
      "MakeRawScoreDist tak es efficacies , whic h is a Pmf that represen ts the dis-\n",
      "tribution of e\u001ecacy across test-tak ers. I assume it is Gaussian with mean 0\n",
      "and standard deviation 1.5. This c hoice is mostly arbitrary . The probabilit y\n",
      "of getting a question correct dep ends on the di\u001berence b et w een e\u001ecacy and\n",
      "di\u001ecult y , so w e can c ho ose the units of e\u001ecacy and then calibrate the units of\n",
      "di\u001ecult y accordingly .\n",
      "pmfs is a meta-Pmf that con tains one Pmf for eac h lev el of e\u001ecacy , and maps\n",
      "to the fraction of test-tak ers at that lev el. MakeMixture tak es the meta-pmf\n",
      "and computes the distribution of the mixture (see Section 5.6).\n",
      "12.6 Calibration\n",
      "If w e w ere giv en the distribution of di\u001ecult y , w e could use MakeRawScoreDist\n",
      "to compute the distribution of ra w scores. But for us the problem is the other\n",
      "w a y around: w e are giv en the distribution of ra w scores and w e w an t to infer\n",
      "the distribution of di\u001ecult y .\n",
      "I assume that the distribution of di\u001ecult y is uniform with parameters center' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 153}\n",
      "------------------------\n",
      "page_content='12.7. P osterior distribution of e\u001ecacy 137\n",
      "and width . MakeDifficulties mak es a list of di\u001eculties with these parame-\n",
      "ters.\n",
      "def MakeDifficulties(center, width, n):\n",
      "low, high = center-width, center+width\n",
      "return numpy.linspace(low, high, n)\n",
      "By trying out a few com binations, I found that center=-0.05 and width=1.8\n",
      "yield a distribution of ra w scores similar to the actual data, as sho wn in Fig-\n",
      "ure 12.3.\n",
      "So, assuming that the distribution of di\u001ecult y is uniform, its range is ap-\n",
      "pro ximately -1.85 to 1.75 , giv en that e\u001ecacy is Gaussian with mean 0 and\n",
      "standard deviation 1.5.\n",
      "The follo wing table sho ws the range of ProbCorrect for test-tak ers at di\u001beren t\n",
      "lev els of e\u001ecacy:\n",
      "Di\u001ecult y\n",
      "E\u001ecacy -1.85 -0.05 1.75\n",
      "3.00 0.99 0.95 0.78\n",
      "1.50 0.97 0.82 0.44\n",
      "0.00 0.86 0.51 0.15\n",
      "-1.50 0.59 0.19 0.04\n",
      "-3.00 0.24 0.05 0.01\n",
      "Someone with e\u001ecacy 3 (t w o standard deviations ab o v e the mean) has a 99%\n",
      "c hance of answ ering the easiest questions on the exam, and a 78% c hance of\n",
      "answ ering the hardest. On the other end of the range, someone t w o standard\n",
      "deviations b elo w the mean has only a 24% c hance of answ ering the easiest\n",
      "questions.\n",
      "12.7 P osterior distribution of e\u001ecacy\n",
      "No w that the mo del is calibrated, w e can compute the p osterior distribution\n",
      "of e\u001ecacy for Alice and Bob. Here is a v ersion of the Sat class that uses the\n",
      "new mo del:\n",
      "class Sat2(thinkbayes.Suite):\n",
      "def __init__(self, exam, score):\n",
      "self.exam = exam\n",
      "self.score = score' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 154}\n",
      "------------------------\n",
      "page_content='138 Chapter 12. Evidence\n",
      "0 1 2 3 4\n",
      "efficacy0.00.20.40.60.81.0CDFposterior 780\n",
      "posterior 740\n",
      "Figure 12.4: P osterior distributions of e\u001ecacy for Alice and Bob.\n",
      "# start with the Gaussian prior\n",
      "efficacies = thinkbayes.MakeGaussianPmf(0, 1.5, 3)\n",
      "thinkbayes.Suite.__init__(self, efficacies)\n",
      "# update based on an exam score\n",
      "self.Update(score)\n",
      "Update in v ok es Likelihood , whic h computes the lik eliho o d of a giv en test\n",
      "score for a h yp othetical lev el of e\u001ecacy .\n",
      "def Likelihood(self, data, hypo):\n",
      "efficacy = hypo\n",
      "score = data\n",
      "raw = self.exam.Reverse(score)\n",
      "pmf = self.exam.PmfCorrect(efficacy)\n",
      "like = pmf.Prob(raw)\n",
      "return like\n",
      "pmf is the distribution of ra w scores for a test-tak er with the giv en e\u001ecacy;\n",
      "like is the probabilit y of the observ ed score.\n",
      "Figure 12.4 sho ws the p osterior distributions of e\u001ecacy for Alice and Bob. As\n",
      "exp ected, the lo cation of Alice's distribution is farther to the righ t, but again\n",
      "there is some o v erlap.\n",
      "Using TopLevel again, w e compare A , the h yp othesis that Alice's e\u001ecacy is\n",
      "higher, and B , the h yp othesis that Bob's is higher. The lik eliho o d ratio is 3.4,\n",
      "a bit smaller than what w e got from the simple mo del (3.8). So this mo del' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 155}\n",
      "------------------------\n",
      "page_content='12.8. Predictiv e distribution 139\n",
      "indicates that the data are evidence in fa v or of A , but a little w eak er than the\n",
      "previous estimate.\n",
      "If our prior b elief is that A andB are equally lik ely , then in ligh t of this\n",
      "evidence w e w ould giv e A a p osterior probabilit y of 77%, lea ving a 23% c hance\n",
      "that Bob's e\u001ecacy is higher.\n",
      "12.8 Predictiv e distribution\n",
      "The analysis w e ha v e done so far generates estimates for Alice and Bob's\n",
      "e\u001ecacy , but since e\u001ecacy is not directly observ able, it is hard to v alidate the\n",
      "results.\n",
      "T o giv e the mo del predictiv e p o w er, w e can use it to answ er a related question:\n",
      "\u0010If Alice and Bob tak e the math SA T again, what is the c hance that Alice will\n",
      "do b etter again?\u0011\n",
      "W e'll answ er this question in t w o steps:\n",
      " W e'll use the p osterior distribution of e\u001ecacy to generate a predictiv e\n",
      "distribution of ra w score for eac h test-tak er.\n",
      " W e'll compare the t w o predictiv e distributions to compute the probabil-\n",
      "it y that Alice gets a higher score again.\n",
      "W e already ha v e most of the co de w e need. T o compute the predictiv e distri-\n",
      "butions, w e can use MakeRawScoreDist again:\n",
      "exam = Exam()\n",
      "a_sat = Sat(exam, 780)\n",
      "b_sat = Sat(exam, 740)\n",
      "a_pred = exam.MakeRawScoreDist(a_sat)\n",
      "b_pred = exam.MakeRawScoreDist(b_sat)\n",
      "Then w e can \u001cnd the lik eliho o d that Alice do es b etter on the second test, Bob\n",
      "do es b etter, or they tie:\n",
      "a_like = thinkbayes.PmfProbGreater(a_pred, b_pred)\n",
      "b_like = thinkbayes.PmfProbLess(a_pred, b_pred)\n",
      "c_like = thinkbayes.PmfProbEqual(a_pred, b_pred)\n",
      "The probabilit y that Alice do es b etter on the second exam is 63%, whic h\n",
      "means that Bob has a 37% c hance of doing as w ell or b etter.\n",
      "Notice that w e ha v e more con\u001cdence ab out Alice's e\u001ecacy than w e do ab out\n",
      "the outcome of the next test. The p osterior o dds are 3:1 that Alice's e\u001ecacy\n",
      "is higher, but only 2:1 that Alice will do b etter on the next exam.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 156}\n",
      "------------------------\n",
      "page_content='140 Chapter 12. Evidence\n",
      "0.80 0.85 0.90 0.95 1.00\n",
      "p_correct Alice0.800.850.900.951.00p_correct Bob\n",
      "Figure 12.5: Join t p osterior distribution of p_correct for Alice and Bob.\n",
      "12.9 Discussion\n",
      "W e started this c hapter with the question, \u0010Ho w strong is the evidence that\n",
      "Alice is b etter prepared than Bob?\u0011 On the face of it, that sounds lik e w e\n",
      "w an t to test t w o h yp otheses: either Alice is more prepared or Bob is.\n",
      "But in order to compute lik eliho o ds for these h yp otheses, w e ha v e to solv e\n",
      "an estimation problem. F or eac h test-tak er w e ha v e to \u001cnd the p osterior\n",
      "distribution of either p_correct or efficacy .\n",
      "V alues lik e this are called n uisance parameters b ecause w e don't care what\n",
      "they are, but w e ha v e to estimate them to answ er the question w e care ab out.\n",
      "One w a y to visualize the analysis w e did in this c hapter is to plot the space\n",
      "of these parameters. thinkbayes.MakeJoint tak es t w o Pmfs, computes their\n",
      "join t distribution, and returns a join t pmf of eac h p ossible pair of v alues and\n",
      "its probabilit y .\n",
      "def MakeJoint(pmf1, pmf2):\n",
      "joint = Joint()\n",
      "for v1, p1 in pmf1.Items():\n",
      "for v2, p2 in pmf2.Items():\n",
      "joint.Set((v1, v2), p1 * p2)\n",
      "return joint\n",
      "This function assumes that the t w o distributions are indep enden t.\n",
      "Figure 12.5 sho ws the join t p osterior distribution of p_correct for Alice and\n",
      "Bob. The diagonal line indicates the part of the space where p_correct is the' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 157}\n",
      "------------------------\n",
      "page_content='12.9. Discussion 141\n",
      "same for Alice and Bob. T o the righ t of this line, Alice is more prepared; to\n",
      "the left, Bob is more prepared.\n",
      "In TopLevel.Update , when w e compute the lik eliho o ds of A andB , w e add\n",
      "up the probabilit y mass on eac h side of this line. F or the cells that fall on the\n",
      "line, w e add up the total mass and split it b et w een A andB .\n",
      "The pro cess w e used in this c hapter\u0016estimating n uisance parameters in order\n",
      "to ev aluate the lik eliho o d of comp eting h yp otheses\u0016is a common Ba y esian\n",
      "approac h to problems lik e this.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 158}\n",
      "------------------------\n",
      "page_content='142 Chapter 12. Evidence' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 159}\n",
      "------------------------\n",
      "page_content='Chapter 13\n",
      "Simulation\n",
      "In this c hapter I describ e m y solution to a problem p osed b y a patien t with a\n",
      "kidney tumor. I think the problem is imp ortan t and relev an t to patien ts with\n",
      "these tumors and do ctors treating them.\n",
      "And I think the solution is in teresting b ecause, although it is a Ba y esian\n",
      "approac h to the problem, the use of Ba y es's theorem is implicit. I presen t the\n",
      "solution and m y co de; at the end of the c hapter I will explain the Ba y esian\n",
      "part.\n",
      "If y ou w an t more tec hnical detail than I presen t here, y ou can read m y pap er\n",
      "on this w ork at http://arxiv.org/abs/1203.6890 .\n",
      "13.1 The Kidney T umor problem\n",
      "I am a frequen t reader and o ccasional con tributor to the online statistics fo-\n",
      "rum at http://reddit.com/r/statistics . In No v em b er 2011, I read the\n",
      "follo wing message:\n",
      "\"I ha v e Stage IV Kidney Cancer and am trying to determine if\n",
      "the cancer formed b efore I retired from the military . ... Giv en\n",
      "the dates of retiremen t and detection is it p ossible to determine\n",
      "when there w as a 50/50 c hance that I dev elop ed the disease? Is it\n",
      "p ossible to determine the probabilit y on the retiremen t date? My\n",
      "tumor w as 15.5 cm x 15 cm at detection. Grade I I.\"\n",
      "I con tacted the author of the message and got more information; I learned\n",
      "that v eterans get di\u001beren t b ene\u001cts if it is \"more lik ely than not\" that a tumor\n",
      "formed while they w ere in military service (among other considerations).' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 160}\n",
      "------------------------\n",
      "page_content='144 Chapter 13. Sim ulation\n",
      "2\n",
      " 1\n",
      " 0 1 2 3 4 5 6 7\n",
      "RDT (volume doublings per year)0.00.20.40.60.81.0CDFDistribution of RDT\n",
      "model\n",
      "data\n",
      "Figure 13.1: CDF of RDT in doublings p er y ear.\n",
      "Because renal tumors gro w slo wly , and often do not cause symptoms, they are\n",
      "sometimes left un treated. As a result, do ctors can observ e the rate of gro wth\n",
      "for un treated tumors b y comparing scans from the same patien t at di\u001beren t\n",
      "times. Sev eral pap ers ha v e rep orted these gro wth rates.\n",
      "I collected data from a pap er b y Zhang et al1. I con tacted the authors to\n",
      "see if I could get ra w data, but they refused on grounds of medical priv acy .\n",
      "Nev ertheless, I w as able to extract the data I needed b y prin ting one of their\n",
      "graphs and measuring it with a ruler.\n",
      "They rep ort gro wth rates in recipro cal doubling time (RDT), whic h is in units\n",
      "of doublings p er y ear. So a tumor with RDT = 1 doubles in v olume eac h\n",
      "y ear; withRDT = 2 it quadruples in the same time, and with RDT =−1 , it\n",
      "halv es. Figure 13.1 sho ws the distribution of RDT for 53 patien ts.\n",
      "The squares are the data p oin ts from the pap er; the line is a mo del I \u001ct to\n",
      "the data. The p ositiv e tail \u001cts an exp onen tial distribution w ell, so I used a\n",
      "mixture of t w o exp onen tials.\n",
      "13.2 A simple mo del\n",
      "It is usually a go o d idea to start with a simple mo del b efore trying something\n",
      "more c hallenging. Sometimes the simple mo del is su\u001ecien t for the problem at\n",
      "hand, and if not, y ou can use it to v alidate the more complex mo del.\n",
      "1Zhang et al, Distribution of Renal T umor Gro wth Rates Determined b y Using Serial\n",
      "V olumetric CT Measuremen ts, Jan uary 2009 R adiolo gy , 250, 137-144.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 161}\n",
      "------------------------\n",
      "page_content='13.2. A simple mo del 145\n",
      "F or m y simple mo del, I assume that tumors gro w with a constan t doubling\n",
      "time, and that they are three-dimensional in the sense that if the maxim um\n",
      "linear measuremen t doubles, the v olume is m ultiplied b y eigh t.\n",
      "I learned from m y corresp onden t that the time b et w een his disc harge from\n",
      "the military and his diagnosis w as 3291 da ys (ab out 9 y ears). So m y \u001crst\n",
      "calculation w as, \u0010If this tumor grew at the median rate, ho w big w ould it ha v e\n",
      "b een at the date of disc harge?\u0011\n",
      "The median v olume doubling time rep orted b y Zhang et al is 811 da ys. As-\n",
      "suming 3-dimensional geometry , the doubling time for a linear measure is three\n",
      "times longer.\n",
      "# time between discharge and diagnosis, in days\n",
      "interval = 3291.0\n",
      "# doubling time in linear measure is doubling time in volume * 3\n",
      "dt = 811.0 * 3\n",
      "# number of doublings since discharge\n",
      "doublings = interval / dt\n",
      "# how big was the tumor at time of discharge (diameter in cm)\n",
      "d1 = 15.5\n",
      "d0 = d1 / 2.0 ** doublings\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "kidney.py . F or more information see Section 0.3.\n",
      "The result, d0 , is ab out 6 cm. So if this tumor formed after the date of dis-\n",
      "c harge, it m ust ha v e gro wn substan tially faster than the median rate. There-\n",
      "fore I concluded that it is \u0010more lik ely than not\u0011 that this tumor formed b efore\n",
      "the date of disc harge.\n",
      "In addition, I computed the gro wth rate that w ould b e implied if this tumor\n",
      "had formed after the date of disc harge. If w e assume an initial size of 0.1 cm,\n",
      "w e can compute the n um b er of doublings to get to a \u001cnal size of 15.5 cm:\n",
      "# assume an initial linear measure of 0.1 cm\n",
      "d0 = 0.1\n",
      "d1 = 15.5\n",
      "# how many doublings would it take to get from d0 to d1\n",
      "doublings = log2(d1 / d0)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 162}\n",
      "------------------------\n",
      "page_content='146 Chapter 13. Sim ulation\n",
      "# what linear doubling time does that imply?\n",
      "dt = interval / doublings\n",
      "# compute the volumetric doubling time and RDT\n",
      "vdt = dt / 3\n",
      "rdt = 365 / vdt\n",
      "dt is linear doubling time, so vdt is v olumetric doubling time, and rdt is\n",
      "recipro cal doubling time.\n",
      "The n um b er of doublings, in linear measure, is 7.3, whic h implies an RDT of\n",
      "2.4. In the data from Zhang et al, only 20% of tumors grew this fast during\n",
      "a p erio d of observ ation. So again, I concluded that is \u0010more lik ely than not\u0011\n",
      "that the tumor formed prior to the date of disc harge.\n",
      "These calculations are su\u001ecien t to answ er the question as p osed, and on b e-\n",
      "half of m y corresp onden t, I wrote a letter explaining m y conclusions to the\n",
      "V eterans' Bene\u001ct A dministration.\n",
      "Later I told a friend, who is an oncologist, ab out m y results. He w as surprised\n",
      "b y the gro wth rates observ ed b y Zhang et al, and b y what they imply ab out\n",
      "the ages of these tumors. He suggested that the results migh t b e in teresting\n",
      "to researc hers and do ctors.\n",
      "But in order to mak e them useful, I w an ted a more general mo del of the\n",
      "relationship b et w een age and size.\n",
      "13.3 A more general mo del\n",
      "Giv en the size of a tumor at time of diagnosis, it w ould b e most useful to kno w\n",
      "the probabilit y that the tumor formed b efore an y giv en date; in other w ords,\n",
      "the distribution of ages.\n",
      "T o \u001cnd it, I run sim ulations of tumor gro wth to get the distribution of size con-\n",
      "ditioned on age. Then w e can use a Ba y esian approac h to get the distribution\n",
      "of age conditioned on size.\n",
      "The sim ulation starts with a small tumor and runs these steps:\n",
      "1. Cho ose a gro wth rate from the distribution of RDT.\n",
      "2. Compute the size of the tumor at the end of an in terv al.\n",
      "3. Record the size of the tumor at eac h in terv al.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 163}\n",
      "------------------------\n",
      "page_content='13.3. A more general mo del 147\n",
      "0 5 10 15 20 25 30 35 40\n",
      "tumor age (years)0.20.51251020diameter (cm, log scale)Simulations of tumor growth\n",
      "Figure 13.2: Sim ulations of tumor gro wth, size vs. time.\n",
      "4. Rep eat un til the tumor exceeds the maxim um relev an t size.\n",
      "F or the initial size I c hose 0.3 cm, b ecause carcinomas smaller than that are\n",
      "less lik ely to b e in v asiv e and less lik ely to ha v e the blo o d supply needed for\n",
      "rapid gro wth (see http://en.wikipedia.org/wiki/Carcinoma_in_situ ).\n",
      "I c hose an in terv al of 245 da ys (ab out 8 mon ths) b ecause that is the median\n",
      "time b et w een measuremen ts in the data source.\n",
      "F or the maxim um size I c hose 20 cm. In the data source, the range of observ ed\n",
      "sizes is 1.0 to 12.0 cm, so w e are extrap olating b ey ond the observ ed range at\n",
      "eac h end, but not b y far, and not in a w a y lik ely to ha v e a strong e\u001bect on the\n",
      "results.\n",
      "The sim ulation is based on one big simpli\u001ccation: the gro wth rate is c hosen\n",
      "indep enden tly during eac h in terv al, so it do es not dep end on age, size, or\n",
      "gro wth rate during previous in terv als.\n",
      "In Section 13.7 I review these assumptions and consider more detailed mo dels.\n",
      "But \u001crst let's lo ok at some examples.\n",
      "Figure 13.2 sho ws the size of sim ulated tumors as a function of age. The\n",
      "dashed line at 10 cm sho ws the range of ages for tumors at that size: the\n",
      "fastest-gro wing tumor gets there in 8 y ears; the slo w est tak es more than 35.\n",
      "I am presen ting results in terms of linear measuremen ts, but the calculations\n",
      "are in terms of v olume. T o con v ert from one to the other, again, I use the\n",
      "v olume of a sphere with the giv en diameter.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 164}\n",
      "------------------------\n",
      "page_content='148 Chapter 13. Sim ulation\n",
      "13.4 Implemen tation\n",
      "Here is the k ernel of the sim ulation:\n",
      "def MakeSequence(rdt_seq, v0=0.01, interval=0.67, vmax=Volume(20.0)):\n",
      "seq = v0,\n",
      "age = 0\n",
      "for rdt in rdt_seq:\n",
      "age += interval\n",
      "final, seq = ExtendSequence(age, seq, rdt, interval)\n",
      "if final > vmax:\n",
      "break\n",
      "return seq\n",
      "rdt_seq is an iterator that yields random v alues from the CDF of gro wth rate.\n",
      "v0 is the initial v olume in mL. interval is the time step in y ears. vmax is the\n",
      "\u001cnal v olume corresp onding to a linear measuremen t of 20 cm.\n",
      "Volume con v erts from linear measuremen t in cm to v olume in mL, based on\n",
      "the simpli\u001ccation that the tumor is a sphere:\n",
      "def Volume(diameter, factor=4*math.pi/3):\n",
      "return factor * (diameter/2.0)**3\n",
      "ExtendSequence computes the v olume of the tumor at the end of the in terv al.\n",
      "def ExtendSequence(age, seq, rdt, interval):\n",
      "initial = seq[-1]\n",
      "doublings = rdt * interval\n",
      "final = initial * 2**doublings\n",
      "new_seq = seq + (final,)\n",
      "cache.Add(age, new_seq, rdt)\n",
      "return final, new_seq\n",
      "age is the age of the tumor at the end of the in terv al. seq is a tuple that\n",
      "con tains the v olumes so far. rdt is the gro wth rate during the in terv al, in\n",
      "doublings p er y ear. interval is the size of the time step in y ears.\n",
      "The return v alues are final , the v olume of the tumor at the end of the in terv al,\n",
      "and new_seq , a new tuple con taining the v olumes in seq plus the new v olume\n",
      "final .\n",
      "Cache.Add records the age and size of eac h tumor at the end of eac h in terv al,\n",
      "as explained in the next section.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 165}\n",
      "------------------------\n",
      "page_content='13.5. Cac hing the join t distribution 149\n",
      "0 5 10 15 20 25 30 35 40\n",
      "ages0.20.51251020diameter (cm, log scale)\n",
      "Figure 13.3: Join t distribution of age and tumor size.\n",
      "13.5 Cac hing the join t distribution\n",
      "Here's ho w the cac he w orks.\n",
      "class Cache(object):\n",
      "def __init__(self):\n",
      "self.joint = thinkbayes.Joint()\n",
      "joint is a join t Pmf that records the frequency of eac h age-size pair, so it\n",
      "appro ximates the join t distribution of age and size.\n",
      "A t the end of eac h sim ulated in terv al, ExtendSequence calls Add :\n",
      "# class Cache\n",
      "def Add(self, age, seq):\n",
      "final = seq[-1]\n",
      "cm = Diameter(final)\n",
      "bucket = round(CmToBucket(cm))\n",
      "self.joint.Incr((age, bucket))\n",
      "Again, age is the age of the tumor, and seq is the sequence of v olumes so far.\n",
      "Before adding the new data to the join t distribution, w e use Diameter to\n",
      "con v ert from v olume to diameter in cen timeters:\n",
      "def Diameter(volume, factor=3/math.pi/4, exp=1/3.0):\n",
      "return 2 * (factor * volume) ** exp\n",
      "And CmToBucket to con v ert from cen timeters to a discrete buc k et n um b er:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 166}\n",
      "------------------------\n",
      "page_content='150 Chapter 13. Sim ulation\n",
      "0 10 20 30 40 50\n",
      "tumor age (years)0.00.20.40.60.81.0CDFDistribution of age for several diameters\n",
      "2 cm\n",
      "5 cm\n",
      "10 cm\n",
      "15 cm\n",
      "Figure 13.4: Distributions of age, conditioned on size.\n",
      "def CmToBucket(x, factor=10):\n",
      "return factor * math.log(x)\n",
      "The buc k ets are equally spaced on a log scale. Using factor=10 yields a\n",
      "reasonable n um b er of buc k ets; for example, 1 cm maps to buc k et 0 and 10 cm\n",
      "maps to buc k et 23.\n",
      "After running the sim ulations, w e can plot the join t distribution as a pseudo-\n",
      "color plot, where eac h cell represen ts the n um b er of tumors observ ed at a giv en\n",
      "size-age pair. Figure 13.3 sho ws the join t distribution after 1000 sim ulations.\n",
      "13.6 Conditional distributions\n",
      "By taking a v ertical slice from the join t distribution, w e can get the distribu-\n",
      "tion of sizes for an y giv en age. By taking a horizon tal slice, w e can get the\n",
      "distribution of ages conditioned on size.\n",
      "Here's the co de that reads the join t distribution and builds the conditional\n",
      "distribution for a giv en size.\n",
      "# class Cache\n",
      "def ConditionalCdf(self, bucket):\n",
      "pmf = self.joint.Conditional(0, 1, bucket)\n",
      "cdf = pmf.MakeCdf()\n",
      "return cdf' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 167}\n",
      "------------------------\n",
      "page_content='13.7. Serial Correlation 151\n",
      "0.5 1 2 5 10 20\n",
      "diameter (cm, log scale)051015202530354045tumor age (years)95th\n",
      "75th\n",
      "50th\n",
      "25th\n",
      "5thCredible interval for age vs diameter\n",
      "Figure 13.5: P ercen tiles of tumor age as a function of size.\n",
      "bucket is the in teger buc k et n um b er corresp onding to tumor size.\n",
      "Joint.Conditional computes the PMF of age conditioned on bucket . The\n",
      "result is the CDF of age conditioned on bucket .\n",
      "Figure 13.4 sho ws sev eral of these CDF s, for a range of sizes. T o summarize\n",
      "these distributions, w e can compute p ercen tiles as a function of size.\n",
      "percentiles = [95, 75, 50, 25, 5]\n",
      "for bucket in cache.GetBuckets():\n",
      "cdf = ConditionalCdf(bucket)\n",
      "ps = [cdf.Percentile(p) for p in percentiles]\n",
      "Figure 13.5 sho ws these p ercen tiles for eac h size buc k et. The data p oin ts are\n",
      "computed from the estimated join t distribution. In the mo del, size and time\n",
      "are discrete, whic h con tributes n umerical errors, so I also sho w a least squares\n",
      "\u001ct for eac h sequence of p ercen tiles.\n",
      "13.7 Serial Correlation\n",
      "The results so far are based on a n um b er of mo deling decisions; let's review\n",
      "them and consider whic h ones are the most lik ely sources of error:\n",
      " T o con v ert from linear measure to v olume, w e assume that tumors are\n",
      "appro ximately spherical. This assumption is probably \u001cne for tumors up\n",
      "to a few cen timeters, but not for v ery large tumors.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 168}\n",
      "------------------------\n",
      "page_content='152 Chapter 13. Sim ulation\n",
      " The distribution of gro wth rates in the sim ulations are based on a con-\n",
      "tin uous mo del w e c hose to \u001ct the data rep orted b y Zhang et al, whic h is\n",
      "based on 53 patien ts. The \u001ct is only appro ximate and, more imp ortan tly ,\n",
      "a larger sample w ould yield a di\u001beren t distribution.\n",
      " The gro wth mo del do es not tak e in to accoun t tumor subt yp e or grade;\n",
      "this assumption is consisten t with the conclusion of Zhang et al: \u0010Gro wth\n",
      "rates in renal tumors of di\u001beren t sizes, subt yp es and grades represen t\n",
      "a wide range and o v erlap substan tially .\u0011 But with a larger sample, a\n",
      "di\u001berence migh t b ecome apparen t.\n",
      " The distribution of gro wth rate do es not dep end on the size of the tumor.\n",
      "This assumption w ould not b e realistic for v ery small and v ery large\n",
      "tumors, whose gro wth is limited b y blo o d supply .\n",
      "But tumors observ ed b y Zhang et al ranged from 1 to 12 cm, and they\n",
      "found no statistically signi\u001ccan t relationship b et w een size and gro wth\n",
      "rate. So if there is a relationship, it is lik ely to b e w eak, at least in this\n",
      "size range.\n",
      " In the sim ulations, gro wth rate during eac h in terv al is indep enden t of\n",
      "previous gro wth rates. In realit y it is plausible that tumors that ha v e\n",
      "gro wn quic kly in the past are more lik ely to gro w quic kly . In other w ords,\n",
      "there is probably a serial correlation in gro wth rate.\n",
      "Of these, the \u001crst and last seem the most problematic. I'll in v estigate serial\n",
      "correlation \u001crst, then come bac k to spherical geometry .\n",
      "T o sim ulate correlated gro wth, I wrote a generator2that yields a correlated\n",
      "series from a giv en Cdf. Here's ho w the algorithm w orks:\n",
      "1. Generate correlated v alues from a Gaussian distribution. This is easy to\n",
      "do b ecause w e can compute the distribution of the next v alue conditioned\n",
      "on the previous v alue.\n",
      "2. T ransform eac h v alue to its cum ulativ e probabilit y using the Gaussian\n",
      "CDF.\n",
      "3. T ransform eac h cum ulativ e probabilit y to the corresp onding v alue using\n",
      "the giv en Cdf.\n",
      "Here's what that lo oks lik e in co de:\n",
      "2If y ou are not familiar with Python generators, see http://wiki.python.org/moin/\n",
      "Generators .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 169}\n",
      "------------------------\n",
      "page_content='13.7. Serial Correlation 153\n",
      "def CorrelatedGenerator(cdf, rho):\n",
      "x = random.gauss(0, 1)\n",
      "yield Transform(x)\n",
      "sigma = math.sqrt(1 - rho**2);\n",
      "while True:\n",
      "x = random.gauss(x * rho, sigma)\n",
      "yield Transform(x)\n",
      "cdf is the desired Cdf; rho is the desired correlation. The v alues of x are\n",
      "Gaussian; Transform con v erts them to the desired distribution.\n",
      "The \u001crst v alue of x is Gaussian with mean 0 and standard deviation 1. F or\n",
      "subsequen t v alues, the mean and standard deviation dep end on the previous\n",
      "v alue. Giv en the previous x , the mean of the next v alue is x * rho , and the\n",
      "v ariance is 1 - rho**2 .\n",
      "Transform maps from eac h Gaussian v alue, x , to a v alue from the giv en Cdf,\n",
      "y .\n",
      "def Transform(x):\n",
      "p = thinkbayes.GaussianCdf(x)\n",
      "y = cdf.Value(p)\n",
      "return y\n",
      "GaussianCdf computes the CDF of the standard Gaussian distribution at\n",
      "x , returning a cum ulativ e probabilit y . Cdf.Value maps from a cum ulativ e\n",
      "probabilit y to the corresp onding v alue in cdf .\n",
      "Dep ending on the shap e of cdf , information can b e lost in transformation, so\n",
      "the actual correlation migh t b e lo w er than rho . F or example, when I generate\n",
      "10000 v alues from the distribution of gro wth rates with rho=0.4 , the actual\n",
      "correlation is 0.37. But since w e are guessing at the righ t correlation an yw a y ,\n",
      "that's close enough.\n",
      "Remem b er that MakeSequence tak es an iterator as an argumen t. That in ter-\n",
      "face allo ws it to w ork with di\u001beren t generators:\n",
      "iterator = UncorrelatedGenerator(cdf)\n",
      "seq1 = MakeSequence(iterator)\n",
      "iterator = CorrelatedGenerator(cdf, rho)\n",
      "seq2 = MakeSequence(iterator)\n",
      "In this example, seq1 and seq2 are dra wn from the same distribution, but the\n",
      "v alues in seq1 are uncorrelated and the v alues in seq2 are correlated with a\n",
      "co e\u001ecien t of appro ximately rho .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 170}\n",
      "------------------------\n",
      "page_content='154 Chapter 13. Sim ulation\n",
      "Serial Diameter P ercen tiles of age\n",
      "Correlation (cm) 5th 25th 50th 75th 95th\n",
      "0.0 6.0 10.7 15.4 19.5 23.5 30.2\n",
      "0.4 6.0 9.4 15.4 20.8 26.2 36.9\n",
      "T able 13.1: P ercen tiles of tumor age conditioned on size.\n",
      "No w w e can see what e\u001bect serial correlation has on the results; the follo w-\n",
      "ing table sho ws p ercen tiles of age for a 6 cm tumor, using the uncorrelated\n",
      "generator and a correlated generator with target ρ= 0.4 .\n",
      "Correlation mak es the fastest gro wing tumors faster and the slo w est slo w er, so\n",
      "the range of ages is wider. The di\u001berence is mo dest for lo w p ercen tiles, but\n",
      "for the 95th p ercen tile it is more than 6 y ears. T o compute these p ercen tiles\n",
      "precisely , w e w ould need a b etter estimate of the actual serial correlation.\n",
      "Ho w ev er, this mo del is su\u001ecien t to answ er the question w e started with: giv en\n",
      "a tumor with a linear dimension of 15.5 cm, what is the probabilit y that it\n",
      "formed more than 8 y ears ago?\n",
      "Here's the co de:\n",
      "# class Cache\n",
      "def ProbOlder(self, cm, age):\n",
      "bucket = CmToBucket(cm)\n",
      "cdf = self.ConditionalCdf(bucket)\n",
      "p = cdf.Prob(age)\n",
      "return 1-p\n",
      "cm is the size of the tumor; age is the age threshold in y ears. ProbOlder\n",
      "con v erts size to a buc k et n um b er, gets the Cdf of age conditioned on buc k et,\n",
      "and computes the probabilit y that age exceeds the giv en v alue.\n",
      "With no serial correlation, the probabilit y that a 15.5 cm tumor is older than\n",
      "8 y ears is 0.999, or almost certain. With correlation 0.4, faster-gro wing tumors\n",
      "are more lik ely , but the probabilit y is still 0.995. Ev en with correlation 0.8,\n",
      "the probabilit y is 0.978.\n",
      "Another lik ely source of error is the assumption that tumors are appro ximately\n",
      "spherical. F or a tumor with linear dimensions 15.5 x 15 cm, this assumption\n",
      "is probably not v alid. If, as seems lik ely , a tumor this size is relativ ely \u001dat, it\n",
      "migh t ha v e the same v olume as a 6 cm sphere. With this smaller v olume and\n",
      "correlation 0.8, the probabilit y of age greater than 8 is still 95%.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 171}\n",
      "------------------------\n",
      "page_content='13.8. Discussion 155\n",
      "So ev en taking in to accoun t mo deling errors, it is unlik ely that suc h a large\n",
      "tumor could ha v e formed less than 8 y ears prior to the date of diagnosis.\n",
      "13.8 Discussion\n",
      "W ell, w e got through a whole c hapter without using Ba y es's theorem or the\n",
      "Suite class that encapsulates Ba y esian up dates. What happ ened?\n",
      "One w a y to think ab out Ba y es's theorem is as an algorithm for in v erting\n",
      "conditional probabilities. Giv en p(B|A) , w e can compute p(A|B) , pro vided\n",
      "w e kno w p(A) andp(B) . Of course this algorithm is only useful if, for some\n",
      "reason, it is easier to compute p(B|A) than p(A|B) .\n",
      "In this example, it is. By running sim ulations, w e can estimate the distribu-\n",
      "tion of size conditioned on age, or p(size|age) . But it is harder to get the\n",
      "distribution of age conditioned on size, or p(age|size) . So this seems lik e a\n",
      "p erfect opp ortunit y to use Ba y es's theorem.\n",
      "The reason I didn't is computational e\u001eciency . T o estimate p(size|age) for\n",
      "an y giv en size, y ou ha v e to run a lot of sim ulations. Along the w a y , y ou end\n",
      "up computing p(size|age) for a lot of sizes. In fact, y ou end up computing the\n",
      "en tire join t distribution of size and age, p(size,age ) .\n",
      "And once y ou ha v e the join t distribution, y ou don't really need Ba y es's theo-\n",
      "rem, y ou can extract p(age|size) b y taking slices from the join t distribution,\n",
      "as demonstrated in ConditionalCdf .\n",
      "So w e side-stepp ed Ba y es, but he w as with us in spirit.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 172}\n",
      "------------------------\n",
      "page_content='156 Chapter 13. Sim ulation' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 173}\n",
      "------------------------\n",
      "page_content='Chapter 14\n",
      "A Hierarchical Model\n",
      "14.1 The Geiger coun ter problem\n",
      "I got the idea for the follo wing problem from T om Campb ell-Ric k etts, author\n",
      "of the Maxim um En trop y blog at http://maximum- entropy- blog.blogspot.\n",
      "com . And he got the idea from E. T. Ja ynes, author of the classic Pr ob ability\n",
      "The ory: The L o gic of Scienc e :\n",
      "Supp ose that a radioactiv e source emits particles to w ard a Geiger\n",
      "coun ter at an a v erage rate of r particles p er second, but the coun ter\n",
      "only registers a fraction, f , of the particles that hit it. If f is 10%\n",
      "and the coun ter registers 15 particles in a one second in terv al, what\n",
      "is the p osterior distribution of n , the actual n um b er of particles\n",
      "that hit the coun ter, and r , the a v erage rate particles are emitted?\n",
      "T o get started on a problem lik e this, think ab out the c hain of causation that\n",
      "starts with the parameters of the system and ends with the observ ed data:\n",
      "1. The source emits particles at an a v erage rate, r .\n",
      "2. During an y giv en second, the source emits n particles to w ard the coun ter.\n",
      "3. Out of those n particles, some n um b er, k , get coun ted.\n",
      "The probabilit y that an atom deca ys is the same at an y p oin t in time, so ra-\n",
      "dioactiv e deca y is w ell mo deled b y a P oisson pro cess. Giv en r , the distribution\n",
      "ofn is P oisson distribution with parameter r .\n",
      "And if w e assume that the probabilit y of detection for eac h particle is inde-\n",
      "p enden t of the others, the distribution of k is the binomial distribution with\n",
      "parameters n andf .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 174}\n",
      "------------------------\n",
      "page_content='158 Chapter 14. A Hierarc hical Mo del\n",
      "0 100 200 300 400 500\n",
      "Number of particles (n)0.0000.0050.0100.0150.0200.0250.0300.0350.0400.045PMF100\n",
      "250\n",
      "400\n",
      "Figure 14.1: P osterior distribution of n for three v alues of r .\n",
      "Giv en the parameters of the system, w e can \u001cnd the distribution of the data.\n",
      "So w e can solv e what is called the forw ard problem .\n",
      "No w w e w an t to go the other w a y: giv en the data, w e w an t the distribution of\n",
      "the parameters. This is called the in v erse problem . And if y ou can solv e the\n",
      "forw ard problem, y ou can use Ba y esian metho ds to solv e the in v erse problem.\n",
      "14.2 Start simple\n",
      "Let's start with a simple v ersion of the problem where w e kno w the v alue of\n",
      "r . W e are giv en the v alue of f , so all w e ha v e to do is estimate n .\n",
      "I de\u001cne a Suite called Detector that mo dels the b eha vior of the detector and\n",
      "estimatesn .\n",
      "class Detector(thinkbayes.Suite):\n",
      "def __init__(self, r, f, high=500, step=1):\n",
      "pmf = thinkbayes.MakePoissonPmf(r, high, step=step)\n",
      "thinkbayes.Suite.__init__(self, pmf, name=r)\n",
      "self.r = r\n",
      "self.f = f\n",
      "If the a v erage emission rate is r particles p er second, the distribution of n is\n",
      "P oisson with parameter r . high and step determine the upp er b ound for n\n",
      "and the step size b et w een h yp othetical v alues.\n",
      "No w w e need a lik eliho o d function:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 175}\n",
      "------------------------\n",
      "page_content='14.3. Mak e it hierarc hical 159\n",
      "# class Detector\n",
      "def Likelihood(self, data, hypo):\n",
      "k = data\n",
      "n = hypo\n",
      "p = self.f\n",
      "return thinkbayes.EvalBinomialPmf(k, n, p)\n",
      "data is the n um b er of particles detected, and hypo is the h yp othetical n um b er\n",
      "of particles emitted, n .\n",
      "If there are actually n particles, and the probabilit y of detecting an y one of\n",
      "them isf , the probabilit y of detecting k particles is giv en b y the binomial\n",
      "distribution.\n",
      "That's it for the Detector. W e can try it out for a range of v alues of r :\n",
      "f = 0.1\n",
      "k = 15\n",
      "for r in [100, 250, 400]:\n",
      "suite = Detector(r, f, step=1)\n",
      "suite.Update(k)\n",
      "print suite.MaximumLikelihood()\n",
      "Figure 14.1 sho ws the p osterior distribution of n for sev eral giv en v alues of r .\n",
      "14.3 Mak e it hierarc hical\n",
      "In the previous section, w e assume r is kno wn. No w let's relax that assumption.\n",
      "I de\u001cne another Suite, called Emitter , that mo dels the b eha vior of the emitter\n",
      "and estimates r :\n",
      "class Emitter(thinkbayes.Suite):\n",
      "def __init__(self, rs, f=0.1):\n",
      "detectors = [Detector(r, f) for r in rs]\n",
      "thinkbayes.Suite.__init__(self, detectors)\n",
      "rs is a sequence of h yp othetical v alue for r . detectors is a sequence of\n",
      "Detector ob jects, one for eac h v alue of r . The v alues in the Suite are Detectors,\n",
      "so Emitter is a meta-Suite ; that is, a Suite that con tains other Suites as\n",
      "v alues.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 176}\n",
      "------------------------\n",
      "page_content='160 Chapter 14. A Hierarc hical Mo del\n",
      "T o up date the Emitter, w e ha v e to compute the lik eliho o d of the data under\n",
      "eac h h yp othetical v alue of r . But eac h v alue of r is represen ted b y a Detector\n",
      "that con tains a range of v alues for n .\n",
      "T o compute the lik eliho o d of the data for a giv en Detector, w e lo op through\n",
      "the v alues of n and add up the total probabilit y of k . That's what\n",
      "SuiteLikelihood do es:\n",
      "# class Detector\n",
      "def SuiteLikelihood(self, data):\n",
      "total = 0\n",
      "for hypo, prob in self.Items():\n",
      "like = self.Likelihood(data, hypo)\n",
      "total += prob * like\n",
      "return total\n",
      "No w w e can write the Lik eliho o d function for the Emitter:\n",
      "# class Emitter\n",
      "def Likelihood(self, data, hypo):\n",
      "detector = hypo\n",
      "like = detector.SuiteLikelihood(data)\n",
      "return like\n",
      "Eac h hypo is a Detector, so w e can in v ok e SuiteLikelihood to get the lik eli-\n",
      "ho o d of the data under the h yp othesis.\n",
      "After w e up date the Emitter, w e ha v e to up date eac h of the Detectors, to o.\n",
      "# class Emitter\n",
      "def Update(self, data):\n",
      "thinkbayes.Suite.Update(self, data)\n",
      "for detector in self.Values():\n",
      "detector.Update()\n",
      "A mo del lik e this, with m ultiple lev els of Suites, is called hierarc hical .\n",
      "14.4 A little optimization\n",
      "Y ou migh t recognize SuiteLikelihood ; w e sa w it in Section 11.2. A t the\n",
      "time, I p oin ted out that w e didn't really need it, b ecause the total probabilit y' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 177}\n",
      "------------------------\n",
      "page_content='14.5. Extracting the p osteriors 161\n",
      "0 100 200 300 400 500\n",
      "Emission rate0.000.010.020.030.040.050.06PMFposterior r\n",
      "posterior n\n",
      "Figure 14.2: P osterior distributions of n andr .\n",
      "computed b y SuiteLikelihood is exactly the normalizing constan t computed\n",
      "and returned b y Update .\n",
      "So instead of up dating the Emitter and then up dating the Detectors, w e can\n",
      "do b oth steps at the same time, using the result from Detector.Update as\n",
      "the lik eliho o d of Emitter.\n",
      "Here's the streamlined v ersion of Emitter.Likelihood :\n",
      "# class Emitter\n",
      "def Likelihood(self, data, hypo):\n",
      "return hypo.Update(data)\n",
      "And with this v ersion of Likelihood w e can use the default v ersion of Update .\n",
      "So this v ersion has few er lines of co de, and it runs faster b ecause it do es not\n",
      "compute the normalizing constan t t wice.\n",
      "14.5 Extracting the p osteriors\n",
      "After w e up date the Emitter, w e can get the p osterior distribution of r b y\n",
      "lo oping through the Detectors and their probabilities:\n",
      "# class Emitter\n",
      "def DistOfR(self):\n",
      "items = [(detector.r, prob) for detector, prob in self.Items()]\n",
      "return thinkbayes.MakePmfFromItems(items)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 178}\n",
      "------------------------\n",
      "page_content='162 Chapter 14. A Hierarc hical Mo del\n",
      "items is a list of v alues of r and their probabilities. The result is the Pmf of\n",
      "r .\n",
      "T o get the p osterior distribution of n , w e ha v e to compute the mixture of the\n",
      "Detectors. W e can use thinkbayes.MakeMixture , whic h tak es a meta-Pmf\n",
      "that maps from eac h distribution to its probabilit y . And that's exactly what\n",
      "the Emitter is:\n",
      "# class Emitter\n",
      "def DistOfN(self):\n",
      "return thinkbayes.MakeMixture(self)\n",
      "Figure 14.2 sho ws the results. Not surprisingly , the most lik ely v alue for n\n",
      "is 150. Giv en f andn , the exp ected coun t is k=fn , so giv enf andk , the\n",
      "exp ected v alue of n isk/f , whic h is 150.\n",
      "And if 150 particles are emitted in one second, the most lik ely v alue of r is\n",
      "150 particles p er second. So the p osterior distribution of r is also cen tered on\n",
      "150.\n",
      "The p osterior distributions of r andn are similar; the only di\u001berence is that\n",
      "w e are sligh tly less certain ab out n . In general, w e can b e more certain ab out\n",
      "the long-range emission rate, r , than ab out the n um b er of particles emitted in\n",
      "an y particular second, n .\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "jaynes.py . F or more information see Section 0.3.\n",
      "14.6 Discussion\n",
      "The Geiger coun ter problem demonstrates the connection b et w een causation\n",
      "and hierarc hical mo deling. In the example, the emission rate r has a causal\n",
      "e\u001bect on the n um b er of particles, n , whic h has a causal e\u001bect on the particle\n",
      "coun t,k .\n",
      "The hierarc hical mo del re\u001dects the structure of the system, with causes at the\n",
      "top and e\u001bects at the b ottom.\n",
      "1. A t the top lev el, w e start with a range of h yp othetical v alues for r .\n",
      "2. F or eac h v alue of r , w e ha v e a range of v alues for n , and the prior\n",
      "distribution of n dep ends on r .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 179}\n",
      "------------------------\n",
      "page_content='14.7. Exercises 163\n",
      "3. When w e up date the mo del, w e go b ottom-up. W e compute a p oste-\n",
      "rior distribution of n for eac h v alue of r , then compute the p osterior\n",
      "distribution of r .\n",
      "So causal information \u001do ws do wn the hierarc h y , and inference \u001do ws up.\n",
      "14.7 Exercises\n",
      "Exercise 14.1 This exercise is also inspired b y an example in Ja ynes, Pr ob a-\n",
      "bility The ory .\n",
      "Supp ose y ou buy a mosquito trap that is supp osed to reduce the p opulation\n",
      "of mosquito es near y our house. Eac h w eek, y ou empt y the trap and coun t the\n",
      "n um b er of mosquito es captured. After the \u001crst w eek, y ou coun t 30 mosquito es.\n",
      "After the second w eek, y ou coun t 20 mosquito es. Estimate the p ercen tage\n",
      "c hange in the n um b er of mosquito es in y our y ard.\n",
      "T o answ er this question, y ou ha v e to mak e some mo deling decisions. Here are\n",
      "some suggestions:\n",
      " Supp ose that eac h w eek a large n um b er of mosquito es, N , is bred in a\n",
      "w etland near y our home.\n",
      " During the w eek, some fraction of them, f1 , w ander in to y our y ard, and\n",
      "of those some fraction, f2 , are caugh t in the trap.\n",
      " Y our solution should tak e in to accoun t y our prior b elief ab out ho w m uc h\n",
      "N is lik ely to c hange from one w eek to the next. Y ou can do that b y\n",
      "adding a lev el to the hierarc h y to mo del the p ercen t c hange in N .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 180}\n",
      "------------------------\n",
      "page_content='164 Chapter 14. A Hierarc hical Mo del' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 181}\n",
      "------------------------\n",
      "page_content='Chapter 15\n",
      "Dealing with Dimensions\n",
      "15.1 Belly button bacteria\n",
      "Belly Button Bio div ersit y 2.0 (BBB2) is a nation-wide citizen science pro ject\n",
      "with the goal of iden tifying bacterial sp ecies that can b e found in h uman\n",
      "na v els ( http://bbdata.yourwildlife.org ). The pro ject migh t seem whim-\n",
      "sical, but it is part of an increasing in terest in the h uman microbiome, the set\n",
      "of micro organisms that liv e on h uman skin and parts of the b o dy .\n",
      "In their pilot study , BBB2 researc hers collected sw abs from the na v els of 60\n",
      "v olun teers, used m ultiplex p yrosequencing to extract and sequence fragmen ts\n",
      "of 16S rDNA, then iden ti\u001ced the sp ecies or gen us the fragmen ts came from.\n",
      "Eac h iden ti\u001ced fragmen t is called a \u0010read.\u0011\n",
      "W e can use these data to answ er sev eral related questions:\n",
      " Based on the n um b er of sp ecies observ ed, can w e estimate the total\n",
      "n um b er of sp ecies in the en vironmen t?\n",
      " Can w e estimate the prev alence of eac h sp ecies; that is, the fraction of\n",
      "the total p opulation b elonging to eac h sp ecies?\n",
      " If w e are planning to collect additional samples, can w e predict ho w\n",
      "man y new sp ecies w e are lik ely to disco v er?\n",
      " Ho w man y additional reads are needed to increase the fraction of ob-\n",
      "serv ed sp ecies to a giv en threshold?\n",
      "These questions mak e up what is called the Unseen Sp ecies problem .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 182}\n",
      "------------------------\n",
      "page_content='166 Chapter 15. Dealing with Dimensions\n",
      "15.2 Lions and tigers and b ears\n",
      "I'll start with a simpli\u001ced v ersion of the problem where w e kno w that there\n",
      "are exactly three sp ecies. Let's call them lions, tigers and b ears. Supp ose w e\n",
      "visit a wild animal preserv e and see 3 lions, 2 tigers and one b ear.\n",
      "If w e ha v e an equal c hance of observing an y animal in the preserv e, the n um b er\n",
      "of eac h sp ecies w e see is go v erned b y the m ultinomial distribution. If the\n",
      "prev alence of lions and tigers and b ears is p_lion and p_tiger and p_bear ,\n",
      "the lik eliho o d of seeing 3 lions, 2 tigers and one b ear is prop ortional to\n",
      "p_lion**3 * p_tiger**2 * p_bear**1\n",
      "An approac h that is tempting, but not correct, is to use b eta distributions,\n",
      "as in Section 4.5, to describ e the prev alence of eac h sp ecies separately . F or\n",
      "example, w e sa w 3 lions and 3 non-lions; if w e think of that as 3 \u0010heads\u0011 and\n",
      "3 \u0010tails,\u0011 then the p osterior distribution of p_lion is:\n",
      "beta = thinkbayes.Beta()\n",
      "beta.Update((3, 3))\n",
      "print beta.MaximumLikelihood()\n",
      "The maxim um lik eliho o d estimate for p_lion is the observ ed rate, 50%. Sim-\n",
      "ilarly the MLEs for p_tiger and p_bear are 33% and 17%.\n",
      "But there are t w o problems:\n",
      "1. W e ha v e implicitly used a prior for eac h sp ecies that is uniform from 0\n",
      "to 1, but since w e kno w that there are three sp ecies, that prior is not\n",
      "correct. The righ t prior should ha v e a mean of 1/3, and there should b e\n",
      "zero lik eliho o d that an y sp ecies has a prev alence of 100%.\n",
      "2. The distributions for eac h sp ecies are not indep enden t, b ecause the\n",
      "prev alences ha v e to add up to 1. T o capture this dep endence, w e need a\n",
      "join t distribution for the three prev alences.\n",
      "W e can use a Diric hlet distribution to solv e b oth of these problems (see http:\n",
      "//en.wikipedia.org/wiki/Dirichlet_distribution ). In the same w a y w e\n",
      "used the b eta distribution to describ e the distribution of bias for a coin, w e\n",
      "can use a Diric hlet distribution to describ e the join t distribution of p_lion ,\n",
      "p_tiger and p_bear .\n",
      "The Diric hlet distribution is the m ulti-dimensional generalization of the b eta\n",
      "distribution. Instead of t w o p ossible outcomes, lik e heads and tails, the\n",
      "Diric hlet distribution handles an y n um b er of outcomes: in this example, three\n",
      "sp ecies.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 183}\n",
      "------------------------\n",
      "page_content='15.2. Lions and tigers and b ears 167\n",
      "If there are n outcomes, the Diric hlet distribution is describ ed b y n parameters,\n",
      "writtenα1 throughαn .\n",
      "Here's the de\u001cnition, from thinkbayes.py , of a class that represen ts a Diric h-\n",
      "let distribution:\n",
      "class Dirichlet(object):\n",
      "def __init__(self, n):\n",
      "self.n = n\n",
      "self.params = numpy.ones(n, dtype=numpy.int)\n",
      "n is the n um b er of dimensions; initially the parameters are all 1. I use a numpy\n",
      "arra y to store the parameters so I can tak e adv an tage of arra y op erations.\n",
      "Giv en a Diric hlet distribution, the marginal distribution for eac h prev alence is\n",
      "a b eta distribution, whic h w e can compute lik e this:\n",
      "def MarginalBeta(self, i):\n",
      "alpha0 = self.params.sum()\n",
      "alpha = self.params[i]\n",
      "return Beta(alpha, alpha0-alpha)\n",
      "i is the index of the marginal distribution w e w an t. alpha0 is the sum of the\n",
      "parameters; alpha is the parameter for the giv en sp ecies.\n",
      "In the example, the prior marginal distribution for eac h sp ecies is Beta(1,\n",
      "2) . W e can compute the prior means lik e this:\n",
      "dirichlet = thinkbayes.Dirichlet(3)\n",
      "for i in range(3):\n",
      "beta = dirichlet.MarginalBeta(i)\n",
      "print beta.Mean()\n",
      "As exp ected, the prior mean prev alence for eac h sp ecies is 1/3.\n",
      "T o up date the Diric hlet distribution, w e add the observ ations to the parameters\n",
      "lik e this:\n",
      "def Update(self, data):\n",
      "m = len(data)\n",
      "self.params[:m] += data\n",
      "Here data is a sequence of coun ts in the same order as params , so in this\n",
      "example, it should b e the n um b er of lions, tigers and b ears.\n",
      "data can b e shorter than params ; in that case there are some sp ecies that ha v e\n",
      "not b een observ ed.\n",
      "Here's co de that up dates dirichlet with the observ ed data and computes the\n",
      "p osterior marginal distributions.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 184}\n",
      "------------------------\n",
      "page_content='168 Chapter 15. Dealing with Dimensions\n",
      "0.0 0.2 0.4 0.6 0.8 1.0\n",
      "Prevalence0.0000.0050.0100.0150.0200.0250.0300.035Problions\n",
      "tigers\n",
      "bears\n",
      "Figure 15.1: Distribution of prev alences for three sp ecies.\n",
      "data = [3, 2, 1]\n",
      "dirichlet.Update(data)\n",
      "for i in range(3):\n",
      "beta = dirichlet.MarginalBeta(i)\n",
      "pmf = beta.MakePmf()\n",
      "print i, pmf.Mean()\n",
      "Figure 15.1 sho ws the results. The p osterior mean prev alences are 44%, 33%,\n",
      "and 22%.\n",
      "15.3 The hierarc hical v ersion\n",
      "W e ha v e solv ed a simpli\u001ced v ersion of the problem: if w e kno w ho w man y\n",
      "sp ecies there are, w e can estimate the prev alence of eac h.\n",
      "No w let's get bac k to the original problem, estimating the total n um b er of\n",
      "sp ecies. T o solv e this problem I'll de\u001cne a meta-Suite, whic h is a Suite that\n",
      "con tains other Suites as h yp otheses. In this case, the top-lev el Suite con tains\n",
      "h yp otheses ab out the n um b er of sp ecies; the b ottom lev el con tains h yp otheses\n",
      "ab out prev alences.\n",
      "Here's the class de\u001cnition:\n",
      "class Species(thinkbayes.Suite):\n",
      "def __init__(self, ns):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 185}\n",
      "------------------------\n",
      "page_content='15.3. The hierarc hical v ersion 169\n",
      "hypos = [thinkbayes.Dirichlet(n) for n in ns]\n",
      "thinkbayes.Suite.__init__(self, hypos)\n",
      "__init__ tak es a list of p ossible v alues for n and mak es a list of Diric hlet\n",
      "ob jects.\n",
      "Here's the co de that creates the top-lev el suite:\n",
      "ns = range(3, 30)\n",
      "suite = Species(ns)\n",
      "ns is the list of p ossible v alues for n . W e ha v e seen 3 sp ecies, so there ha v e to\n",
      "b e at least that man y . I c hose an upp er b ound that seems reasonable, but w e\n",
      "will c hec k later that the probabilit y of exceeding this b ound is lo w. And at\n",
      "least initially w e assume that an y v alue in this range is equally lik ely .\n",
      "T o up date a hierarc hical mo del, y ou ha v e to up date all lev els. Usually y ou\n",
      "ha v e to up date the b ottom lev el \u001crst and w ork up, but in this case w e can\n",
      "up date the top lev el \u001crst:\n",
      "#class Species\n",
      "def Update(self, data):\n",
      "thinkbayes.Suite.Update(self, data)\n",
      "for hypo in self.Values():\n",
      "hypo.Update(data)\n",
      "Species.Update in v ok es Update in the paren t class, then lo ops through the\n",
      "sub-h yp otheses and up dates them.\n",
      "No w all w e need is a lik eliho o d function:\n",
      "# class Species\n",
      "def Likelihood(self, data, hypo):\n",
      "dirichlet = hypo\n",
      "like = 0\n",
      "for i in range(1000):\n",
      "like += dirichlet.Likelihood(data)\n",
      "return like\n",
      "data is a sequence of observ ed coun ts; hypo is a Diric hlet ob ject.\n",
      "Species.Likelihood calls Dirichlet.Likelihood 1000 times and returns\n",
      "the total.\n",
      "Wh y call it 1000 times? Because Dirichlet.Likelihood do esn't actually\n",
      "compute the lik eliho o d of the data under the whole Diric hlet distribution.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 186}\n",
      "------------------------\n",
      "page_content='170 Chapter 15. Dealing with Dimensions\n",
      "Instead, it dra ws one sample from the h yp othetical distribution and computes\n",
      "the lik eliho o d of the data under the sampled set of prev alences.\n",
      "Here's what it lo oks lik e:\n",
      "# class Dirichlet\n",
      "def Likelihood(self, data):\n",
      "m = len(data)\n",
      "if self.n < m:\n",
      "return 0\n",
      "x = data\n",
      "p = self.Random()\n",
      "q = p[:m]**x\n",
      "return q.prod()\n",
      "The length of data is the n um b er of sp ecies observ ed. If w e see more sp ecies\n",
      "than w e though t existed, the lik eliho o d is 0.\n",
      "Otherwise w e select a random set of prev alences, p , and compute the m ultino-\n",
      "mial PMF, whic h is\n",
      "cxpx1\n",
      "1···pxn\n",
      "n\n",
      "pi is the prev alence of the i th sp ecies, and xi is the observ ed n um b er. The\n",
      "\u001crst term,cx , is the m ultinomial co e\u001ecien t; I lea v e it out of the computation\n",
      "b ecause it is a m ultiplicativ e factor that dep ends only on the data, not the\n",
      "h yp othesis, so it gets normalized a w a y (see http://en.wikipedia.org/wiki/\n",
      "Multinomial_distribution ).\n",
      "m is the n um b er of observ ed sp ecies. W e only need the \u001crst m elemen ts of p ;\n",
      "for the others, xi is 0, sopxi\n",
      "i is 1, and w e can lea v e them out of the pro duct.\n",
      "15.4 Random sampling\n",
      "There are t w o w a ys to generate a random sample from a Diric hlet distri-\n",
      "bution. One is to use the marginal b eta distributions, but in that case\n",
      "y ou ha v e to select one at a time and scale the rest so they add up to\n",
      "1 (see http://en.wikipedia.org/wiki/Dirichlet_distribution#Random_\n",
      "number_generation ).\n",
      "A less ob vious, but faster, w a y is to select v alues from n gamma distributions,\n",
      "then normalize b y dividing through b y the total. Here's the co de:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 187}\n",
      "------------------------\n",
      "page_content='15.4. Random sampling 171\n",
      "0 5 10 15 20 25 30\n",
      "Number of species0.000.020.040.060.080.100.12Prob\n",
      "Figure 15.2: P osterior distribution of n .\n",
      "# class Dirichlet\n",
      "def Random(self):\n",
      "p = numpy.random.gamma(self.params)\n",
      "return p / p.sum()\n",
      "No w w e're ready to lo ok at some results. Here is the co de that extracts the\n",
      "p osterior distribution of n :\n",
      "def DistOfN(self):\n",
      "pmf = thinkbayes.Pmf()\n",
      "for hypo, prob in self.Items():\n",
      "pmf.Set(hypo.n, prob)\n",
      "return pmf\n",
      "DistOfN iterates through the top-lev el h yp otheses and accum ulates the prob-\n",
      "abilit y of eac h n .\n",
      "Figure 15.2 sho ws the result. The most lik ely v alue is 4. V alues from 3 to 7 are\n",
      "reasonably lik ely; after that the probabilities drop o\u001b quic kly . The probabilit y\n",
      "that there are 29 sp ecies is lo w enough to b e negligible; if w e c hose a higher\n",
      "b ound, w e w ould get nearly the same result.\n",
      "Remem b er that this result is based on a uniform prior for n . If w e ha v e\n",
      "bac kground information ab out the n um b er of sp ecies in the en vironmen t, w e\n",
      "migh t c ho ose a di\u001beren t prior.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 188}\n",
      "------------------------\n",
      "page_content='172 Chapter 15. Dealing with Dimensions\n",
      "15.5 Optimization\n",
      "I ha v e to admit that I am proud of this example. The Unseen Sp ecies problem\n",
      "is not easy , and I think this solution is simple and clear, and tak es surprisingly\n",
      "few lines of co de (ab out 50 so far).\n",
      "The only problem is that it is slo w. It's go o d enough for the example with\n",
      "only 3 observ ed sp ecies, but not go o d enough for the b elly button data, with\n",
      "more than 100 sp ecies in some samples.\n",
      "The next few sections presen t a series of optimizations w e need to mak e this\n",
      "solution scale. Before w e get in to the details, here's a road map.\n",
      " The \u001crst step is to recognize that if w e up date the Diric hlet distributions\n",
      "with the same data, the \u001crst m parameters are the same for all of them.\n",
      "The only di\u001berence is the n um b er of h yp othetical unseen sp ecies. So w e\n",
      "don't really need n Diric hlet ob jects; w e can store the parameters in the\n",
      "top lev el of the hierarc h y . Species2 implemen ts this optimization.\n",
      " Species2 also uses the same set of random v alues for all of the h y-\n",
      "p otheses. This sa v es time generating random v alues, but it has a second\n",
      "b ene\u001ct that turns out to b e more imp ortan t: b y giving all h yp otheses the\n",
      "same selection from the sample space, w e mak e the comparison b et w een\n",
      "the h yp otheses more fair, so it tak es few er iterations to con v erge.\n",
      " Ev en with these c hanges there is a ma jor p erformance problem. As the\n",
      "n um b er of observ ed sp ecies increases, the arra y of random prev alences\n",
      "gets bigger, and the c hance of c ho osing one that is appro ximately righ t\n",
      "b ecomes small. So the v ast ma jorit y of iterations yield small lik eliho o ds\n",
      "that don't con tribute m uc h to the total, and don't discriminate b et w een\n",
      "h yp otheses.\n",
      "The solution is to do the up dates one sp ecies at a time. Species4\n",
      "is a simple implemen tation of this strategy using Diric hlet ob jects to\n",
      "represen t the sub-h yp otheses.\n",
      " Finally , Species5 com bines the sub-h yp otheses in to the top lev el and\n",
      "uses numpy arra y op erations to sp eed things up.\n",
      "If y ou are not in terested in the details, feel free to skip to Section 15.9 where\n",
      "w e lo ok at results from the b elly button data.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 189}\n",
      "------------------------\n",
      "page_content='15.6. Collapsing the hierarc h y 173\n",
      "15.6 Collapsing the hierarc h y\n",
      "All of the b ottom-lev el Diric hlet distributions are up dated with the same data,\n",
      "so the \u001crst m parameters are the same for all of them. W e can eliminate them\n",
      "and merge the parameters in to the top-lev el suite. Species2 implemen ts this\n",
      "optimization:\n",
      "class Species2(object):\n",
      "def __init__(self, ns):\n",
      "self.ns = ns\n",
      "self.probs = numpy.ones(len(ns), dtype=numpy.double)\n",
      "self.params = numpy.ones(self.high, dtype=numpy.int)\n",
      "ns is the list of h yp othetical v alues for n ; probs is the list of corresp onding\n",
      "probabilities. And params is the sequence of Diric hlet parameters, initially all\n",
      "1.\n",
      "Species2.Update up dates b oth lev els of the hierarc h y: \u001crst the probabilit y\n",
      "for eac h v alue of n , then the Diric hlet parameters:\n",
      "# class Species2\n",
      "def Update(self, data):\n",
      "like = numpy.zeros(len(self.ns), dtype=numpy.double)\n",
      "for i in range(1000):\n",
      "like += self.SampleLikelihood(data)\n",
      "self.probs *= like\n",
      "self.probs /= self.probs.sum()\n",
      "m = len(data)\n",
      "self.params[:m] += data\n",
      "SampleLikelihood returns an arra y of lik eliho o ds, one for eac h v alue of n .\n",
      "like accum ulates the total lik eliho o d for 1000 samples. self.probs is m ul-\n",
      "tiplied b y the total lik eliho o d, then normalized. The last t w o lines, whic h\n",
      "up date the parameters, are the same as in Dirichlet.Update .\n",
      "No w let's lo ok at SampleLikelihood . There are t w o opp ortunities for opti-\n",
      "mization here:\n",
      " When the h yp othetical n um b er of sp ecies, n , exceeds the observ ed n um-\n",
      "b er, m , w e only need the \u001crst m terms of the m ultinomial PMF; the rest\n",
      "are 1.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 190}\n",
      "------------------------\n",
      "page_content='174 Chapter 15. Dealing with Dimensions\n",
      " If the n um b er of sp ecies is large, the lik eliho o d of the data migh t b e\n",
      "to o small for \u001doating-p oin t (see 10.5). So it is safer to compute log-\n",
      "lik eliho o ds.\n",
      "Again, the m ultinomial PMF is\n",
      "cxpx1\n",
      "1···pxn\n",
      "n\n",
      "So the log-lik eliho o d is\n",
      "logcx+x1logp1+···+xnlogpn\n",
      "whic h is fast and easy to compute. Again, cx it is the same for all h yp otheses,\n",
      "so w e can drop it. Here's the co de:\n",
      "# class Species2\n",
      "def SampleLikelihood(self, data):\n",
      "gammas = numpy.random.gamma(self.params)\n",
      "m = len(data)\n",
      "row = gammas[:m]\n",
      "col = numpy.cumsum(gammas)\n",
      "log_likes = []\n",
      "for n in self.ns:\n",
      "ps = row / col[n-1]\n",
      "terms = data * numpy.log(ps)\n",
      "log_like = terms.sum()\n",
      "log_likes.append(log_like)\n",
      "log_likes -= numpy.max(log_likes)\n",
      "likes = numpy.exp(log_likes)\n",
      "coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
      "likes *= coefs\n",
      "return likes\n",
      "gammas is an arra y of v alues from a gamma distribution; its length is the largest\n",
      "h yp othetical v alue of n . row is just the \u001crst m elemen ts of gammas ; since these\n",
      "are the only elemen ts that dep end on the data, they are the only ones w e need.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 191}\n",
      "------------------------\n",
      "page_content='15.7. One more problem 175\n",
      "F or eac h v alue of n w e need to divide row b y the total of the \u001crst n v alues from\n",
      "gamma . cumsum computes these cum ulativ e sums and stores them in col .\n",
      "The lo op iterates through the v alues of n and accum ulates a list of log-\n",
      "lik eliho o ds.\n",
      "Inside the lo op, ps con tains the ro w of probabilities, normalized with the\n",
      "appropriate cum ulativ e sum. terms con tains the terms of the summation,\n",
      "xilogpi , and log_like con tains their sum.\n",
      "After the lo op, w e w an t to con v ert the log-lik eliho o ds to linear lik eliho o ds, but\n",
      "\u001crst it's a go o d idea to shift them so the largest log-lik eliho o d is 0; that w a y\n",
      "the linear lik eliho o ds are not to o small (see 10.5).\n",
      "Finally , b efore w e return the lik eliho o d, w e ha v e to apply a correction factor,\n",
      "whic h is the n um b er of w a ys w e could ha v e observ ed these m sp ecies, if the\n",
      "total n um b er of sp ecies is n . BinomialCoefficient computes \u0010n c ho ose m\u0011,\n",
      "whic h is written(n\n",
      "m)\n",
      ".\n",
      "As often happ ens, the optimized v ersion is less readable and more error-prone\n",
      "than the original. But that's one reason I think it is a go o d idea to start with\n",
      "the simple v ersion; w e can use it for regression testing. I plotted results from\n",
      "b oth v ersions and con\u001crmed that they are appro ximately equal, and that they\n",
      "con v erge as the n um b er of iterations increases.\n",
      "15.7 One more problem\n",
      "There's more w e could do to optimize this co de, but there's another problem\n",
      "w e need to \u001cx \u001crst. As the n um b er of observ ed sp ecies increases, this v ersion\n",
      "gets noisier and tak es more iterations to con v erge on a go o d answ er.\n",
      "The problem is that if the prev alences w e c ho ose from the Diric hlet distribu-\n",
      "tion, the ps , are not at least appro ximately righ t, the lik eliho o d of the observ ed\n",
      "data is close to zero and almost equally bad for all v alues of n . So most itera-\n",
      "tions don't pro vide an y useful con tribution to the total lik eliho o d. And as the\n",
      "n um b er of observ ed sp ecies, m , gets large, the probabilit y of c ho osing ps with\n",
      "non-negligible lik eliho o d gets small. Really small.\n",
      "F ortunately , there is a solution. Remem b er that if y ou observ e a set of data,\n",
      "y ou can up date the prior distribution with the en tire dataset, or y ou can break\n",
      "it up in to a series of up dates with subsets of the data, and the result is the\n",
      "same either w a y .' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 192}\n",
      "------------------------\n",
      "page_content='176 Chapter 15. Dealing with Dimensions\n",
      "F or this example, the k ey is to p erform the up dates one sp ecies at a time.\n",
      "That w a y when w e generate a random set of ps , only one of them a\u001bects the\n",
      "computed lik eliho o d, so the c hance of c ho osing a go o d one is m uc h b etter.\n",
      "Here's a new v ersion that up dates one sp ecies at a time:\n",
      "class Species4(Species):\n",
      "def Update(self, data):\n",
      "m = len(data)\n",
      "for i in range(m):\n",
      "one = numpy.zeros(i+1)\n",
      "one[i] = data[i]\n",
      "Species.Update(self, one)\n",
      "This v ersion inherits __init__ from Species , so it represen ts the h yp otheses\n",
      "as a list of Diric hlet ob jects (unlik e Species2 ).\n",
      "Update lo ops through the observ ed sp ecies and mak es an arra y , one , with all\n",
      "zeros and one sp ecies coun t. Then it calls Update in the paren t class, whic h\n",
      "computes the lik eliho o ds and up dates the sub-h yp otheses.\n",
      "So in the running example, w e do three up dates. The \u001crst is something lik e \u0010I\n",
      "ha v e seen three lions.\u0011 The second is \u0010I ha v e seen t w o tigers and no additional\n",
      "lions.\u0011 And the third is \u0010I ha v e seen one b ear and no more lions and tigers.\u0011\n",
      "Here's the new v ersion of Likelihood :\n",
      "# class Species4\n",
      "def Likelihood(self, data, hypo):\n",
      "dirichlet = hypo\n",
      "like = 0\n",
      "for i in range(self.iterations):\n",
      "like += dirichlet.Likelihood(data)\n",
      "# correct for the number of unseen species the new one\n",
      "# could have been\n",
      "m = len(data)\n",
      "num_unseen = dirichlet.n - m + 1\n",
      "like *= num_unseen\n",
      "return like\n",
      "This is almost the same as Species.Likelihood . The di\u001berence is the factor,\n",
      "num_unseen . This correction is necessary b ecause eac h time w e see a sp ecies' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 193}\n",
      "------------------------\n",
      "page_content='15.8. W e're not done y et 177\n",
      "for the \u001crst time, w e ha v e to consider that there w ere some n um b er of other\n",
      "unseen sp ecies that w e migh t ha v e seen. F or larger v alues of n there are more\n",
      "unseen sp ecies that w e could ha v e seen, whic h increases the lik eliho o d of the\n",
      "data.\n",
      "This is a subtle p oin t and I ha v e to admit that I did not get it righ t the \u001crst\n",
      "time. But again I w as able to v alidate this v ersion b y comparing it to the\n",
      "previous v ersions.\n",
      "15.8 W e're not done y et\n",
      "P erforming the up dates one sp ecies at a time solv es one problem, but it creates\n",
      "another. Eac h up date tak es time prop ortional to km , wherek is the n um b er\n",
      "of h yp otheses and m is the n um b er of observ ed sp ecies. So if w e do m up dates,\n",
      "the total run time is prop ortional to km2.\n",
      "But w e can sp eed things up using the same tric k w e used in Section 15.6: w e'll\n",
      "get rid of the Diric hlet ob jects and collapse the t w o lev els of the hierarc h y in to\n",
      "a single ob ject. So here's y et another v ersion of Species :\n",
      "class Species5(Species2):\n",
      "def Update(self, data):\n",
      "m = len(data)\n",
      "for i in range(m):\n",
      "self.UpdateOne(i+1, data[i])\n",
      "self.params[i] += data[i]\n",
      "This v ersion inherits __init__ from Species2 , so it uses ns and probs to\n",
      "represen t the distribution of n , and params to represen t the parameters of the\n",
      "Diric hlet distribution.\n",
      "Update is similar to what w e sa w in the previous section. It lo ops through the\n",
      "observ ed sp ecies and calls UpdateOne :\n",
      "# class Species5\n",
      "def UpdateOne(self, i, count):\n",
      "likes = numpy.zeros(len(self.ns), dtype=numpy.double)\n",
      "for i in range(self.iterations):\n",
      "likes += self.SampleLikelihood(i, count)\n",
      "unseen_species = [n-i+1 for n in self.ns]\n",
      "likes *= unseen_species' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 194}\n",
      "------------------------\n",
      "page_content='178 Chapter 15. Dealing with Dimensions\n",
      "self.probs *= likes\n",
      "self.probs /= self.probs.sum()\n",
      "This function is similar to Species2.Update , with t w o c hanges:\n",
      " The in terface is di\u001beren t. Instead of the whole dataset, w e get i , the\n",
      "index of the observ ed sp ecies, and count , ho w man y of that sp ecies w e'v e\n",
      "seen.\n",
      " W e ha v e to apply a correction factor for the n um b er of unseen sp ecies,\n",
      "as in Species4.Likelihood . The di\u001berence here is that w e up date all\n",
      "of the lik eliho o ds at once with arra y m ultiplication.\n",
      "Finally , here's SampleLikelihood :\n",
      "# class Species5\n",
      "def SampleLikelihood(self, i, count):\n",
      "gammas = numpy.random.gamma(self.params)\n",
      "sums = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
      "ps = gammas[i-1] / sums\n",
      "log_likes = numpy.log(ps) * count\n",
      "log_likes -= numpy.max(log_likes)\n",
      "likes = numpy.exp(log_likes)\n",
      "return likes\n",
      "This is similar to Species2.SampleLikelihood ; the di\u001berence is that eac h\n",
      "up date only includes a single sp ecies, so w e don't need a lo op.\n",
      "The run time of this function is prop ortional to the n um b er of h yp otheses, k .\n",
      "It runsm times, so the run time of the up date is prop ortional to km . And the\n",
      "n um b er of iterations w e need to get an accurate result is usually small.\n",
      "15.9 The b elly button data\n",
      "That's enough ab out lions and tigers and b ears. Let's get bac k to b elly but-\n",
      "tons. T o get a sense of what the data lo ok lik e, consider sub ject B1242, whose\n",
      "sample of 400 reads yielded 61 sp ecies with the follo wing coun ts:' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 195}\n",
      "------------------------\n",
      "page_content='15.9. The b elly button data 179\n",
      "92, 53, 47, 38, 15, 14, 12, 10, 8, 7, 7, 5, 5,\n",
      "4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2,\n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "There are a few dominan t sp ecies that mak e up a large fraction of the whole,\n",
      "but man y sp ecies that yielded only a single read. The n um b er of these \u0010sin-\n",
      "gletons\u0011 suggests that there are lik ely to b e at least a few unseen sp ecies.\n",
      "In the example with lions and tigers, w e assume that eac h animal in the\n",
      "preserv e is equally lik ely to b e observ ed. Similarly , for the b elly button data,\n",
      "w e assume that eac h bacterium is equally lik ely to yield a read.\n",
      "In realit y , eac h step in the data-collection pro cess migh t in tro duce biases. Some\n",
      "sp ecies migh t b e more lik ely to b e pic k ed up b y a sw ab, or to yield iden ti\u001cable\n",
      "amplicons. So when w e talk ab out the prev alence of eac h sp ecies, w e should\n",
      "remem b er this source of error.\n",
      "I should also ac kno wledge that I am using the term \u0010sp ecies\u0011 lo osely . First,\n",
      "bacterial sp ecies are not w ell de\u001cned. Second, some reads iden tify a partic-\n",
      "ular sp ecies, others only iden tify a gen us. T o b e more precise, I should sa y\n",
      "\u0010op erational taxonomic unit\u0011, or OTU.\n",
      "No w let's pro cess some of the b elly button data. I de\u001cne a class called Subject\n",
      "to represen t information ab out eac h sub ject in the study:\n",
      "class Subject(object):\n",
      "def __init__(self, code):\n",
      "self.code = code\n",
      "self.species = []\n",
      "Eac h sub ject has a string co de, lik e \u0010B1242\u0011, and a list of (coun t, sp ecies name)\n",
      "pairs, sorted in increasing order b y coun t. Subject pro vides sev eral metho ds\n",
      "to mak e it easy to access these coun ts and sp ecies names. Y ou can see the\n",
      "details in http://thinkbayes.com/species.py . F or more information see\n",
      "Section 0.3.\n",
      "Subject pro vides a metho d named Process that creates and up dates a\n",
      "Species5 suite, whic h represen ts the distributions of n and the prev alences.\n",
      "And Suite2 pro vides DistOfN , whic h returns the p osterior distribution of n .\n",
      "# class Suite2\n",
      "def DistN(self):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 196}\n",
      "------------------------\n",
      "page_content='180 Chapter 15. Dealing with Dimensions\n",
      "60 65 70 75 80 85 90 95 100\n",
      "Number of species0.000.020.040.060.080.100.12ProbB1242\n",
      "Figure 15.3: Distribution of n for sub ject B1242.\n",
      "items = zip(self.ns, self.probs)\n",
      "pmf = thinkbayes.MakePmfFromItems(items)\n",
      "return pmf\n",
      "Figure 15.3 sho ws the distribution of n for sub ject B1242. The probabilit y\n",
      "that there are exactly 61 sp ecies, and no unseen sp ecies, is nearly zero. The\n",
      "most lik ely v alue is 72, with 90% credible in terv al 66 to 79. A t the high end,\n",
      "it is unlik ely that there are as man y as 87 sp ecies.\n",
      "Next w e compute the p osterior distribution of prev alence for eac h sp ecies.\n",
      "Species2 pro vides DistOfPrevalence :\n",
      "# class Species2\n",
      "def DistOfPrevalence(self, index):\n",
      "metapmf = thinkbayes.Pmf()\n",
      "for n, prob in zip(self.ns, self.probs):\n",
      "beta = self.MarginalBeta(n, index)\n",
      "pmf = beta.MakePmf()\n",
      "metapmf.Set(pmf, prob)\n",
      "mix = thinkbayes.MakeMixture(metapmf)\n",
      "return metapmf, mix\n",
      "index indicates whic h sp ecies w e w an t. F or eac h n , w e ha v e a di\u001beren t p oste-\n",
      "rior distribution of prev alence.\n",
      "The lo op iterates through the p ossible v alues of n and their probabilities. F or\n",
      "eac h v alue of n it gets a Beta ob ject represen ting the marginal distribution for' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 197}\n",
      "------------------------\n",
      "page_content='15.10. Predictiv e distributions 181\n",
      "0.00 0.05 0.10 0.15 0.20 0.25\n",
      "Prevalence0.00.20.40.60.81.0Prob\n",
      "1 (92)\n",
      "2 (53)\n",
      "3 (47)\n",
      "4 (38)\n",
      "5 (15)\n",
      "Figure 15.4: Distribution of prev alences for sub ject B1242.\n",
      "the indicated sp ecies. Remem b er that Beta ob jects con tain the parameters\n",
      "alpha and beta ; they don't ha v e v alues and probabilities lik e a Pmf, but they\n",
      "pro vide MakePmf , whic h generates a discrete appro ximation to the con tin uous\n",
      "b eta distribution.\n",
      "metapmf is a meta-Pmf that con tains the distributions of prev alence, condi-\n",
      "tioned on n . MakeMixture com bines the meta-Pmf in to mix , whic h com bines\n",
      "the conditional distributions in to a single distribution of prev alence.\n",
      "Figure 15.4 sho ws results for the \u001cv e sp ecies with the most reads. The most\n",
      "prev alen t sp ecies accoun ts for 23% of the 400 reads, but since there are almost\n",
      "certainly unseen sp ecies, the most lik ely estimate for its prev alence is 20%,\n",
      "with 90% credible in terv al b et w een 17% and 23%.\n",
      "15.10 Predictiv e distributions\n",
      "I in tro duced the hidden sp ecies problem in the form of four related questions.\n",
      "W e ha v e answ ered the \u001crst t w o b y computing the p osterior distribution for n\n",
      "and the prev alence of eac h sp ecies.\n",
      "The other t w o questions are:\n",
      " If w e are planning to collect additional reads, can w e predict ho w man y\n",
      "new sp ecies w e are lik ely to disco v er?\n",
      " Ho w man y additional reads are needed to increase the fraction of ob-\n",
      "serv ed sp ecies to a giv en threshold?' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 198}\n",
      "------------------------\n",
      "page_content='182 Chapter 15. Dealing with Dimensions\n",
      "0 50 100 150 200 250 300 350 400 450\n",
      "# samples2\n",
      "0246810# species\n",
      "Figure 15.5: Sim ulated rarefaction curv es for sub ject B1242.\n",
      "T o answ er predictiv e questions lik e this w e can use the p osterior distributions\n",
      "to sim ulate p ossible future ev en ts and compute predictiv e distributions for the\n",
      "n um b er of sp ecies, and fraction of the total, w e are lik ely to see.\n",
      "The k ernel of these sim ulations lo oks lik e this:\n",
      "1. Cho ose n from its p osterior distribution.\n",
      "2. Cho ose a prev alence for eac h sp ecies, including p ossible unseen sp ecies,\n",
      "using the Diric hlet distribution.\n",
      "3. Generate a random sequence of future observ ations.\n",
      "4. Compute the n um b er of new sp ecies, num_new , as a function of the n um-\n",
      "b er of additional reads, k .\n",
      "5. Rep eat the previous steps and accum ulate the join t distribution of\n",
      "num_new and k .\n",
      "And here's the co de. RunSimulation runs a single sim ulation:\n",
      "# class Subject\n",
      "def RunSimulation(self, num_reads):\n",
      "m, seen = self.GetSeenSpecies()\n",
      "n, observations = self.GenerateObservations(num_reads)\n",
      "curve = []\n",
      "for k, obs in enumerate(observations):' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 199}\n",
      "------------------------\n",
      "page_content='15.10. Predictiv e distributions 183\n",
      "seen.add(obs)\n",
      "num_new = len(seen) - m\n",
      "curve.append((k+1, num_new))\n",
      "return curve\n",
      "num_reads is the n um b er of additional reads to sim ulate. m is the n um b er of\n",
      "seen sp ecies, and seen is a set of strings with a unique name for eac h sp ecies.\n",
      "n is a random v alue from the p osterior distribution, and observations is a\n",
      "random sequence of sp ecies names.\n",
      "Eac h time through the lo op, w e add the new observ ation to seen and record\n",
      "the n um b er of reads and the n um b er of new sp ecies so far.\n",
      "The result of RunSimulation is a rarefaction curv e , represen ted as a list of\n",
      "pairs with the n um b er of reads and the n um b er of new sp ecies.\n",
      "Before w e see the results, let's lo ok at GetSeenSpecies and\n",
      "GenerateObservations .\n",
      "#class Subject\n",
      "def GetSeenSpecies(self):\n",
      "names = self.GetNames()\n",
      "m = len(names)\n",
      "seen = set(SpeciesGenerator(names, m))\n",
      "return m, seen\n",
      "GetNames returns the list of sp ecies names that app ear in the data \u001cles, but\n",
      "for man y sub jects these names are not unique. So I use SpeciesGenerator to\n",
      "extend eac h name with a serial n um b er:\n",
      "def SpeciesGenerator(names, num):\n",
      "i = 0\n",
      "for name in names:\n",
      "yield ' %s-%d ' % (name, i)\n",
      "i += 1\n",
      "while i < num:\n",
      "yield ' unseen-%d ' % i\n",
      "i += 1\n",
      "Giv en a name lik e Corynebacterium , SpeciesGenerator yields\n",
      "Corynebacterium-1 . When the list of names is exhausted, it yields\n",
      "names lik e unseen-62 .\n",
      "Here is GenerateObservations :' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 200}\n",
      "------------------------\n",
      "page_content='184 Chapter 15. Dealing with Dimensions\n",
      "# class Subject\n",
      "def GenerateObservations(self, num_reads):\n",
      "n, prevalences = self.suite.SamplePosterior()\n",
      "names = self.GetNames()\n",
      "name_iter = SpeciesGenerator(names, n)\n",
      "d = dict(zip(name_iter, prevalences))\n",
      "cdf = thinkbayes.MakeCdfFromDict(d)\n",
      "observations = cdf.Sample(num_reads)\n",
      "return n, observations\n",
      "Again, num_reads is the n um b er of additional reads to generate. n and\n",
      "prevalences are samples from the p osterior distribution.\n",
      "cdf is a Cdf ob ject that maps sp ecies names, including the unseen, to cu-\n",
      "m ulativ e probabilities. Using a Cdf mak es it e\u001ecien t to generate a random\n",
      "sequence of sp ecies names.\n",
      "Finally , here is Species2.SamplePosterior :\n",
      "def SamplePosterior(self):\n",
      "pmf = self.DistOfN()\n",
      "n = pmf.Random()\n",
      "prevalences = self.SamplePrevalences(n)\n",
      "return n, prevalences\n",
      "And SamplePrevalences , whic h generates a sample of prev alences conditioned\n",
      "on n :\n",
      "# class Species2\n",
      "def SamplePrevalences(self, n):\n",
      "params = self.params[:n]\n",
      "gammas = numpy.random.gamma(params)\n",
      "gammas /= gammas.sum()\n",
      "return gammas\n",
      "W e sa w this algorithm for generating random v alues from a Diric hlet distribu-\n",
      "tion in Section 15.4.\n",
      "Figure 15.5 sho ws 100 sim ulated rarefaction curv es for sub ject B1242. The\n",
      "curv es are \u0010jittered;\u0011 that is, I shifted eac h curv e b y a random o\u001bset so they\n",
      "w ould not all o v erlap. By insp ection w e can estimate that after 400 more reads\n",
      "w e are lik ely to \u001cnd 2\u00156 new sp ecies.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 201}\n",
      "------------------------\n",
      "page_content='15.11. Join t p osterior 185\n",
      "0 2 4 6 8 10 12 14\n",
      "# new species0.00.20.40.60.81.0Prob\n",
      "k=100\n",
      "k=200\n",
      "k=400\n",
      "k=800\n",
      "Figure 15.6: Distributions of the n um b er of new sp ecies conditioned on the\n",
      "n um b er of additional reads.\n",
      "15.11 Join t p osterior\n",
      "W e can use these sim ulations to estimate the join t distribution of num_new and\n",
      "k , and from that w e can get the distribution of num_new conditioned on an y\n",
      "v alue of k .\n",
      "def MakeJointPredictive(curves):\n",
      "joint = thinkbayes.Joint()\n",
      "for curve in curves:\n",
      "for k, num_new in curve:\n",
      "joint.Incr((k, num_new))\n",
      "joint.Normalize()\n",
      "return joint\n",
      "MakeJointPredictive mak es a Join t ob ject, whic h is a Pmf whose v alues are\n",
      "tuples.\n",
      "curves is a list of rarefaction curv es created b y RunSimulation . Eac h curv e\n",
      "con tains a list of pairs of k and num_new .\n",
      "The resulting join t distribution is a map from eac h pair to its probabilit y of\n",
      "o ccurring. Giv en the join t distribution, w e can use Joint.Conditional get\n",
      "the distribution of num_new conditioned on k (see Section 9.6).\n",
      "Subject.MakeConditionals tak es a list of ks and computes the conditional\n",
      "distribution of num_new for eac h k . The result is a list of Cdf ob jects.\n",
      "def MakeConditionals(curves, ks):\n",
      "joint = MakeJointPredictive(curves)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 202}\n",
      "------------------------\n",
      "page_content='186 Chapter 15. Dealing with Dimensions\n",
      "0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 1.05\n",
      "Fraction of species seen0.00.20.40.60.81.0Probability800\n",
      "100200\n",
      "104001000\n",
      "600\n",
      "Figure 15.7: Complemen tary CDF of co v erage for a range of additional reads.\n",
      "cdfs = []\n",
      "for k in ks:\n",
      "pmf = joint.Conditional(1, 0, k)\n",
      "pmf.name = ' k=%d ' % k\n",
      "cdf = pmf.MakeCdf()\n",
      "cdfs.append(cdf)\n",
      "return cdfs\n",
      "Figure 15.6 sho ws the results. After 100 reads, the median predicted n um b er\n",
      "of new sp ecies is 2; the 90% credible in terv al is 0 to 5. After 800 reads, w e\n",
      "exp ect to see 3 to 12 new sp ecies.\n",
      "15.12 Co v erage\n",
      "The last question w e w an t to answ er is, \u0010Ho w man y additional reads are needed\n",
      "to increase the fraction of observ ed sp ecies to a giv en threshold?\u0011\n",
      "T o answ er this question, w e need a v ersion of RunSimulation that computes\n",
      "the fraction of observ ed sp ecies rather than the n um b er of new sp ecies.\n",
      "# class Subject\n",
      "def RunSimulation(self, num_reads):\n",
      "m, seen = self.GetSeenSpecies()\n",
      "n, observations = self.GenerateObservations(num_reads)' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 203}\n",
      "------------------------\n",
      "page_content='15.12. Co v erage 187\n",
      "curve = []\n",
      "for k, obs in enumerate(observations):\n",
      "seen.add(obs)\n",
      "frac_seen = len(seen) / float(n)\n",
      "curve.append((k+1, frac_seen))\n",
      "return curve\n",
      "Next w e lo op through eac h curv e and mak e a dictionary , d , that maps from\n",
      "the n um b er of additional reads, k , to a list of fracs ; that is, a list of v alues\n",
      "for the co v erage ac hiev ed after k reads.\n",
      "def MakeFracCdfs(self, curves):\n",
      "d = {}\n",
      "for curve in curves:\n",
      "for k, frac in curve:\n",
      "d.setdefault(k, []).append(frac)\n",
      "cdfs = {}\n",
      "for k, fracs in d.iteritems():\n",
      "cdf = thinkbayes.MakeCdfFromList(fracs)\n",
      "cdfs[k] = cdf\n",
      "return cdfs\n",
      "Then for eac h v alue of k w e mak e a Cdf of fracs ; this Cdf represen ts the\n",
      "distribution of co v erage after k reads.\n",
      "Remem b er that the CDF tells y ou the probabilit y of falling b elo w a giv en\n",
      "threshold, so the c omplementary CDF tells y ou the probabilit y of exceeding\n",
      "it. Figure 15.7 sho ws complemen tary CDF s for a range of v alues of k .\n",
      "T o read this \u001cgure, select the lev el of co v erage y ou w an t to ac hiev e along the\n",
      "x -axis. As an example, c ho ose 90%.\n",
      "No w y ou can read up the c hart to \u001cnd the probabilit y of ac hieving 90% co v er-\n",
      "age after k reads. F or example, with 200 reads, y ou ha v e ab out a 40% c hance\n",
      "of getting 90% co v erage. With 1000 reads, y ou ha v e a 90% c hance of getting\n",
      "90% co v erage.\n",
      "With that, w e ha v e answ ered the four questions that mak e up the unseen\n",
      "sp ecies problem. T o v alidate the algorithms in this c hapter with real data, I\n",
      "had to deal with a few more details. But this c hapter is already to o long, so I\n",
      "w on't discuss them here.' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 204}\n",
      "------------------------\n",
      "page_content='188 Chapter 15. Dealing with Dimensions\n",
      "Y ou can read ab out the problems, and ho w I addressed\n",
      "them, at http://allendowney.blogspot.com/2013/05/\n",
      "belly- button- biodiversity- end- game.html .\n",
      "Y ou can do wnload the co de in this c hapter from http://thinkbayes.com/\n",
      "species.py . F or more information see Section 0.3.\n",
      "15.13 Discussion\n",
      "The Unseen Sp ecies problem is an area of activ e researc h, and I b eliev e the\n",
      "algorithm in this c hapter is a no v el con tribution. So in few er than 200 pages\n",
      "w e ha v e made it from the basics of probabilit y to the researc h fron tier. I'm\n",
      "v ery happ y ab out that.\n",
      "My goal for this b o ok is to presen t three related ideas:\n",
      " Ba y esian thinking : The foundation of Ba y esian analysis is the idea of\n",
      "using probabilit y distributions to represen t uncertain b eliefs, using data\n",
      "to up date those distributions, and using the results to mak e predictions\n",
      "and inform decisions.\n",
      " A computational approac h : The premise of this b o ok is that it is\n",
      "easier to understand Ba y esian analysis using computation rather than\n",
      "math, and easier to implemen t Ba y esian metho ds with reusable building\n",
      "blo c ks that can b e rearranged to solv e real-w orld problems quic kly .\n",
      " Iterativ e mo deling : Most real-w orld problems in v olv e mo deling de-\n",
      "cisions and trade-o\u001bs b et w een realism and complexit y . It is often im-\n",
      "p ossible to kno w ahead of time what factors should b e included in the\n",
      "mo del and whic h can b e abstracted a w a y . The b est approac h is to iter-\n",
      "ate, starting with simple mo dels and adding complexit y gradually , using\n",
      "eac h mo del to v alidate the others.\n",
      "These ideas are v ersatile and p o w erful; they are applicable to problems in ev ery\n",
      "area of science and engineering, from simple examples to topics of curren t\n",
      "researc h.\n",
      "If y ou made it this far, y ou should b e prepared to apply these to ols to new\n",
      "problems relev an t to y our w ork. I hop e y ou \u001cnd them useful; let me kno w ho w\n",
      "it go es!' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 205}\n",
      "------------------------\n",
      "page_content='Index\n",
      "ABC, 116\n",
      "abstract t yp e, 18, 58\n",
      "Anaconda, vii\n",
      "Appro ximate Ba y esian Computation,\n",
      "116\n",
      "arriv al rate, 87\n",
      "Axtell, Rob ert, 26\n",
      "bacteria, 165\n",
      "Ba y es factor, 45, 123, 125, 126, 134\n",
      "Ba y es's theorem, 3\n",
      "deriv ation, 3\n",
      "o dds form, 44\n",
      "Ba y esian framew ork, 13\n",
      "Beha vioral Risk F actor Surv eillance\n",
      "System, 107\n",
      "b elly button, 165\n",
      "Bernoulli pro cess, 71\n",
      "b eta distribution, 39, 166\n",
      "Beta ob ject, 39, 181\n",
      "biased coin, 123\n",
      "binomial co e\u001ecien t, 175\n",
      "binomial distribution, 132, 157, 159\n",
      "binomial lik eliho o d function, 39\n",
      "bio div ersit y , 165\n",
      "b ogus, 110, 124\n",
      "Boston, 79\n",
      "Boston Bruins, 69\n",
      "BRFSS, 107, 116\n",
      "buc k et, 150\n",
      "bus stop problem, 77, 78\n",
      "cac he, 115, 148\n",
      "calibration, 137\n",
      "Campb ell-Ric k etts, T om, 157carcinoma, 147\n",
      "causation, 157, 162\n",
      "CDC, 107\n",
      "Cdf, 28, 54, 61, 83, 184\n",
      "Cen ters for Disease Con trol, 107\n",
      "cen tral credible in terv al, 102\n",
      "classical estimation, 109\n",
      "clone, vii\n",
      "co e\u001ecien t of v ariation, 108\n",
      "coin toss, 1\n",
      "collectiv ely exhaustiv e, 6\n",
      "College Board, 130\n",
      "complemen tary CDF, 187\n",
      "concrete t yp e, 18, 58\n",
      "conditional distribution, 101, 104,\n",
      "146, 150, 155, 185\n",
      "conditional probabilit y , 1\n",
      "conjoin t probabilit y , 2\n",
      "conjugate prior, 39\n",
      "conjunction, 3\n",
      "con tin uous distribution, 39\n",
      "con tributors, ix\n",
      "con v ergence, 37, 40\n",
      "co okie problem, 3, 12, 44\n",
      "co okie.p y , 13\n",
      "correlated random v alue, 153\n",
      "co v erage, 186, 187\n",
      "crank science, 107\n",
      "credible in terv al, 27, 100\n",
      "Crom w ell's rule, 41\n",
      "Crom w ell, Oliv er, 41\n",
      "cum ulativ e distribution function, 28,\n",
      "83\n",
      "cum ulativ e probabilit y , 152, 184' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 206}\n",
      "------------------------\n",
      "page_content='190 Index\n",
      "cum ulativ e sum, 175\n",
      "Da vidson-Pilon, Cameron, 56\n",
      "decision analysis, 56, 64, 68, 90\n",
      "degree of b elief, 1\n",
      "densit y , 57, 59, 63, 109\n",
      "dep endence, 2, 100, 102\n",
      "diac hronic in terpretation, 5\n",
      "dice, 11, 21\n",
      "Dice problem, 21\n",
      "dice problem, 24\n",
      "Diric hlet distribution, 166, 182\n",
      "distribution, 11, 54, 68\n",
      "op erations, 46\n",
      "divide-and-conquer, 10\n",
      "doubling time, 144\n",
      "Dungeons and Dragons, 21, 47\n",
      "e\u001ecacy , 134\n",
      "en umeration, 47, 50\n",
      "error, 60\n",
      "ESP , 127\n",
      "Euro problem, 33, 41, 116, 123\n",
      "evidence, 4, 35, 45, 46, 100, 107, 123\u0015\n",
      "127, 129\n",
      "exception, 112\n",
      "exp onen tial distribution, 71, 75, 144\n",
      "exp onen tiation, 50\n",
      "extra-sensory p erception, 127\n",
      "fair coin, 123\n",
      "fork, vii\n",
      "forw ard problem, 158\n",
      "gamma distribution, 170, 174\n",
      "Gaussian distribution, 57, 58, 61, 70,\n",
      "108, 116, 119, 131, 136, 137,\n",
      "152\n",
      "Gaussian PDF, 58\n",
      "Gee, Stev e, 56\n",
      "Geiger coun ter problem, 157, 162\n",
      "generator, 152, 153, 183\n",
      "German tank problem, 22, 30Git, vii\n",
      "GitHub, vii\n",
      "gro wth rate, 152\n",
      "heart attac k, 1\n",
      "heigh t, 108\n",
      "Heuer, Andreas, 71\n",
      "hierarc hical mo del, 160, 162, 168\n",
      "Hoag, Dirk, 77\n",
      "ho c k ey , 69\n",
      "horse racing, 44\n",
      "Horsford, Eb en Norton, 107\n",
      "Hume, Da vid, 128\n",
      "h yp othesis testing, 123\n",
      "implemen tation, 18, 58\n",
      "indep endence, 2, 7, 48, 51, 100, 102,\n",
      "140, 147, 166\n",
      "informativ e prior, 30\n",
      "insect sampling problem, 78\n",
      "installation, viii\n",
      "in ter-quartile range, 119\n",
      "in terface, 18, 58\n",
      "in tuition, 8\n",
      "in v erse problem, 158\n",
      "IQR, 119\n",
      "item resp onse theory , 135\n",
      "iterativ e mo deling, 76\n",
      "iterator, 148\n",
      "Ja ynes, E. T., 157\n",
      "Join t, 100\u0015102, 104, 109\n",
      "join t distribution, 100, 104, 109, 140,\n",
      "149, 150, 155, 166, 182, 185\n",
      "Join t ob ject, 185\n",
      "Join t pmf, 96\n",
      "KDE, 57, 59\n",
      "k ernel densit y estimation, 57, 59\n",
      "Kidney tumor problem, 143\n",
      "least squares \u001ct, 151\n",
      "ligh t bulb problem, 78' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 207}\n",
      "------------------------\n",
      "page_content='Index 191\n",
      "Lik eliho o d, 14\n",
      "lik eliho o d, 5, 60, 62, 63, 86, 97, 99,\n",
      "109, 121, 125, 158\n",
      "lik eliho o d function, 23\n",
      "lik eliho o d ratio, 45, 125, 126, 134\n",
      "linspace, 110\n",
      "lions and tigers and b ears, 166\n",
      "lo comotiv e problem, 22, 30, 116\n",
      "log scale, 150\n",
      "log transform, 112\n",
      "log-lik eliho o d, 113, 174, 175\n",
      "logarithm, 112\n",
      "M and M problem, 6, 17\n",
      "MacKa y , Da vid, 33, 45, 93, 123\n",
      "Mak eMixture, 74, 75, 82, 90, 136, 181\n",
      "marginal distribution, 100, 104, 167\n",
      "matplotlib, viii\n",
      "maxim um, 50\n",
      "maxim um lik eliho o d, 27, 35, 68, 102,\n",
      "110, 113, 166\n",
      "mean squared error, 24\n",
      "Mec k el, Johann, 107\n",
      "median, 35\n",
      "memoization, 115\n",
      "meta-Pmf, 74, 75, 82, 90, 136, 181\n",
      "meta-Suite, 159, 168\n",
      "microbiome, 165\n",
      "mixture, 52, 73\u001575, 82, 89, 90, 144,\n",
      "181\n",
      "mo deling, v, 30, 41, 76, 121, 129, 144,\n",
      "146\n",
      "mo deling error, 134, 151, 155\n",
      "Mon t y Hall problem, 8, 15\n",
      "Mosteller, F rederic k, 22\n",
      "Mult, 13\n",
      "m ultinomial co e\u001ecien t, 170\n",
      "m ultinomial distribution, 166, 170,\n",
      "174\n",
      "m utually exclusiv e, 6\n",
      "National Ho c k ey League, 70na v el, 165\n",
      "NHL, 70\n",
      "non-linear, 90\n",
      "normal distribution, 58\n",
      "normalize, 64\n",
      "normalizing constan t, 5, 7, 44, 161\n",
      "n uisance parameter, 140\n",
      "NumPy , viii\n",
      "n ump y , 59, 61, 65, 70, 88, 110, 137,\n",
      "167, 170, 172\u0015174, 176\u0015178,\n",
      "184\n",
      "ob jectivit y , 30\n",
      "observ er bias, 81, 91\n",
      "o dds, 43\n",
      "Olin College, 79\n",
      "Oliv er's blo o d problem, 45\n",
      "op erational taxonomic unit, 179\n",
      "optimization, 37, 114, 115, 161, 172\n",
      "OTU, 179\n",
      "o v ertime, 75\n",
      "P ain tball problem, 95\n",
      "parameter, 39\n",
      "PDF, 40, 70\n",
      "Pdf, 57\n",
      "PEP 8, viii\n",
      "p ercen tile, 28, 151, 154\n",
      "Pmf, 54, 57\n",
      "Pmf class, 11\n",
      "Pmf metho ds, 12\n",
      "P oisson distribution, 71\u001573, 86, 158\n",
      "P oisson pro cess, vi, 69, 71, 75, 78, 80,\n",
      "157\n",
      "p osterior, 5\n",
      "p osterior distribution, 13, 35\n",
      "p o w er la w, 26\n",
      "predictiv e distribution, 78, 85, 86, 89,\n",
      "139, 181\n",
      "prev alence, 165, 168, 179\n",
      "Price is Righ t, 55\n",
      "prior, 5' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 208}\n",
      "------------------------\n",
      "page_content='192 Index\n",
      "prior distribution, 12, 25\n",
      "Prob, 12\n",
      "probabilit y , 57\n",
      "conditional, 1\n",
      "conjoin t, 2\n",
      "probabilit y densit y , 57\n",
      "probabilit y densit y function, 40, 57, 70\n",
      "probabilit y mass function, 11\n",
      "pro cess, 71\n",
      "pseudo color plot, 150\n",
      "p yrosequencing, 165\n",
      "radioactiv e deca y , 157\n",
      "random sample, 170, 184\n",
      "rarefaction curv e, 183, 185\n",
      "ra w score, 132\n",
      "rDNA, 165\n",
      "Red Line problem, 79\n",
      "Reddit, 41, 143\n",
      "regression testing, vii, 175, 177\n",
      "renormalize, 13\n",
      "rep ository , vii\n",
      "robust estimation, 119\n",
      "sample bias, 179\n",
      "sample statistics, 116\n",
      "SA T, 129\n",
      "scaled score, 130\n",
      "SciPy , viii\n",
      "scip y , 58, 59, 113\n",
      "serial correlation, 152, 153\n",
      "Sho w case, 55\n",
      "sim ulation, 47, 50, 53, 146, 148, 182\n",
      "Sivia, D.S., 95\n",
      "sp ecies, 165, 179\n",
      "sphere, 147, 151\n",
      "standardized test, 129\n",
      "stic k, 8\n",
      "stra\u001cng sp eed, 98\n",
      "sub jectiv e prior, 5\n",
      "sub jectivit y , 30\n",
      "sudden death, 75suite, 6\n",
      "Suite class, 16\n",
      "summary statistic, 68, 119, 121\n",
      "sw amping the priors, 37, 40\n",
      "switc h, 8\n",
      "table metho d, 7\n",
      "template metho d pattern, 18\n",
      "total probabilit y , 6\n",
      "triangle distribution, 37, 126\n",
      "trigonometry , 97\n",
      "tumor t yp e, 152\n",
      "tuple, 38\n",
      "uncertain t y , 89\n",
      "under\u001do w, 112, 174\n",
      "uniform distribution, 171\n",
      "uniform distribution, 34, 52, 82\n",
      "uninformativ e prior, 30\n",
      "Unseen Sp ecies problem, 165\n",
      "Up date, 13\n",
      "V ancouv er Can uc ks, 69\n",
      "V ariabilit y Hyp othesis, 107\n",
      "V eterans' Bene\u001ct A dministration, 146\n",
      "v olume, 147\n",
      "W eibull distribution, 78\n",
      "w ord frequency , 11' metadata={'source': '/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf', 'page': 209}\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# vector stores\n",
    "\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "#vector datenbank\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "# load data\n",
    "# statt wie oben die dokumente reinzuschreiben, laden wir die dokumente als elemente in eine liste\n",
    "loader = TextLoader(r\"./Data/Internal/budget.txt\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "#loader = TextLoader(r\"./Data/Internal/lostpassword.txt\", encoding=\"utf-8\")\n",
    "#data.extend(loader.load())\n",
    "# PDF reinladen\n",
    "loader = PyPDFLoader(r\"/Users/drenizerama/Blume Repo/rag-systems/Workshop-GenAI/Data/thinkbayes.pdf\")\n",
    "data.extend(loader.load())\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=30000, chunk_overlap=1000, separators=[\".\", \"\\n\"])\n",
    "documents = splitter.split_documents(data)\n",
    "\n",
    "# statt llm ist es hier embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=azure_key,\n",
    "    api_version=azure_version,\n",
    "    azure_deployment=azure_embeddings,\n",
    "    azure_endpoint=azure_endpoint,\n",
    ")\n",
    "db = Chroma.from_documents(documents, embeddings, persist_directory=\"./chroma/presentation\")\n",
    "\n",
    "for document in documents:\n",
    "    print(document)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bayes beispiel\n",
    "\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# lokal abspeichern?\n",
    "db = Chroma(persist_directory=\"./chroma/presentation\", embedding_function=embeddings)\n",
    "retriever = db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian thinking involves updating the probability of a hypothesis based on new data, which is encapsulated in Bayes's theorem. This approach starts with an initial probability (prior) and adjusts it in light of new evidence (likelihood) to form an updated probability (posterior). Bayesian thinking is a way to incorporate new information over time to refine the understanding or prediction of a hypothesis.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer = retrieval_chain.invoke({\"input\": \"What is bayesian thinking?\"})\n",
    "print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of step two when losing a password is \"Access the Password Recovery Page.\"\n"
     ]
    }
   ],
   "source": [
    "# retriever\n",
    "\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "db = Chroma(persist_directory=\"./chroma/presentation\", embedding_function=embeddings)\n",
    "retriever = db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "answer = retrieval_chain.invoke({\"input\": \"What is the title of step two when losing a password?\"})\n",
    "print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To apply for a budget for a team event at Tech Innovators Inc., follow these steps:\n",
      "\n",
      "1. **Plan Your Event**:\n",
      "   - Define the purpose and set objectives.\n",
      "   - Draft a detailed proposal with the event’s purpose, objectives, and expected outcomes.\n",
      "\n",
      "2. **Estimate the Budget**:\n",
      "   - List all potential expenses and obtain quotes from vendors.\n",
      "   - Create a budget plan summarizing the total estimated cost.\n",
      "\n",
      "3. **Submit a Budget Request**:\n",
      "   - Log in to the Tech Innovators HR portal using your credentials.\n",
      "   - Navigate to the “Budget Request” section and fill out the form with event details.\n",
      "   - Attach your budget plan and supporting documents, then submit the request.\n",
      "\n",
      "4. **Review and Approval**:\n",
      "   - HR and finance departments will review your request for alignment with policies and reasonable budgeting.\n",
      "   - You will receive an email notification of approval or denial.\n",
      "\n",
      "5. **Coordinate with HR and Finance**:\n",
      "   - Follow up with HR and coordinate with finance to finalize the budget and allocation of funds.\n",
      "\n",
      "For any questions, contact HR at hr@techinnovators.com or (123) 456-7890.\n"
     ]
    }
   ],
   "source": [
    "answer = retrieval_chain.invoke({\"input\": \"Give a concise description how I can apply for a budget.\"})\n",
    "print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey kiddo! Let me tell you a story about two guides from a company called Tech Innovators.\n",
      "\n",
      "First, there's a guide about planning a fun party for your team. Imagine you and your friends want to throw a big party, but you need some money to do it. This guide helps you ask the grown-ups (like your teachers) for money to buy things like decorations, snacks, and games. You need to write down why you want to have the party, what you hope to do, and how much everything will cost. Then, you ask the grown-ups for approval, and if they say yes, you can start planning and having fun!\n",
      "\n",
      "Second, there's a guide about what to do if you forget your secret code to get into a special clubhouse. If you forget your code, you can click on a “Forgot Password” button, and they'll send you a special link to change it. You have to prove it's really you by answering some questions or entering a special code. Once you make a new secret code, you can get back into the clubhouse and play again. \n",
      "\n",
      "Both guides also tell you who to talk to if you need help—like calling a teacher if you have questions. Pretty cool, right?\n"
     ]
    }
   ],
   "source": [
    "summary_prompt = ChatPromptTemplate.from_template(\"\"\"Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old would understand.\n",
    "\n",
    "Text: {context}\"\"\")\n",
    "\n",
    "summary_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=summary_prompt,\n",
    "    document_prompt=document_prompt,\n",
    ")\n",
    "\n",
    "answer = summary_chain.invoke(\n",
    "    {\"context\": documents}\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Combined Summary of Planning a Team Party and Handling a Forgotten Work Password:**\n",
      "\n",
      "**Planning a Team Party:**\n",
      "\n",
      "1. **Purpose**: Enhance team cohesion and enjoyment.\n",
      "2. **Planning**:\n",
      "   - Define the party's purpose.\n",
      "   - List activities.\n",
      "   - Develop a detailed plan.\n",
      "3. **Budgeting**:\n",
      "   - List purchases.\n",
      "   - Determine costs.\n",
      "   - Calculate total budget.\n",
      "4. **Requesting Funds**:\n",
      "   - Log into company site.\n",
      "   - Navigate to funding request.\n",
      "   - Submit form with details and costs.\n",
      "5. **Approval**:\n",
      "   - HR reviews concept.\n",
      "   - Finance evaluates budget.\n",
      "   - Await funding confirmation.\n",
      "6. **Coordination**:\n",
      "   - Contact HR for queries.\n",
      "   - Collaborate with finance on budget.\n",
      "7. **Preparation**:\n",
      "   - Confirm vendor details.\n",
      "   - Inform team of logistics.\n",
      "8. **Post-Party**:\n",
      "   - Submit receipts for reimbursement.\n",
      "   - Write event report.\n",
      "9. **Assistance**:\n",
      "   - Contact HR for help.\n",
      "\n",
      "**Handling a Forgotten Work Password:**\n",
      "\n",
      "1. **Visit the Login Page**.\n",
      "2. **Select “Forgot Password”**.\n",
      "3. **Verify Your Identity**.\n",
      "4. **Create a New Password**.\n",
      "5. **Log In**.\n",
      "6. **Update Saved Passwords**.\n",
      "7. **Maintain Security**.\n",
      "8. **Notify HR and Security**.\n",
      "9. **Seek Assistance**.\n",
      "10. **Contact IT Support**: Email it-support@techinnovators.com or call (123) 456-7890.\n",
      "\n",
      "By following these structured steps, you are prepared to effectively plan a team party and handle the situation if you forget your work password.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "from langchain.chains.combine_documents import collapse_docs, split_list_of_docs\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "partial_format_document = partial(format_document, prompt=document_prompt)\n",
    "\n",
    "# The chain we'll apply to each individual document.\n",
    "# Returns a summary of the document.\n",
    "map_chain = (\n",
    "    {\"context\": partial_format_document}\n",
    "    | summary_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# A wrapper chain to keep the original Document metadata\n",
    "map_as_doc_chain = (\n",
    "    RunnableParallel({\"doc\": RunnablePassthrough(), \"content\": map_chain})\n",
    "    | (lambda x: Document(page_content=x[\"content\"], metadata=x[\"doc\"].metadata))\n",
    ").with_config(run_name=\"Summarize (return doc)\")\n",
    "\n",
    "# The chain we'll repeatedly apply to collapse subsets of the documents\n",
    "# into a consolidate document until the total token size of our\n",
    "# documents is below some max size.\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(partial_format_document(doc) for doc in docs)\n",
    "\n",
    "collapse_chain = (\n",
    "    {\"context\": format_docs}\n",
    "    | PromptTemplate.from_template(\"Collapse this content:\\n\\n{context}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def get_num_tokens(docs):\n",
    "    return llm.get_num_tokens(format_docs(docs))\n",
    "\n",
    "def collapse(\n",
    "    docs,\n",
    "    config,\n",
    "    token_max=400,\n",
    "):\n",
    "    collapse_ct = 1\n",
    "    while get_num_tokens(docs) > token_max:\n",
    "        config[\"run_name\"] = f\"Collapse {collapse_ct}\"\n",
    "        invoke = partial(collapse_chain.invoke, config=config)\n",
    "        split_docs = split_list_of_docs(docs, get_num_tokens, token_max)\n",
    "        docs = [collapse_docs(_docs, invoke) for _docs in split_docs]\n",
    "        collapse_ct += 1\n",
    "    return docs\n",
    "\n",
    "# The chain we'll use to combine our individual document summaries\n",
    "# (or summaries over subset of documents if we had to collapse the map results)\n",
    "# into a final summary.\n",
    "\n",
    "reduce_chain = (\n",
    "    {\"context\": format_docs}\n",
    "    | PromptTemplate.from_template(\"Combine these summaries:\\n\\n{context}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ").with_config(run_name=\"Reduce\")\n",
    "\n",
    "# The final full chain\n",
    "map_reduce = (map_as_doc_chain.map() | collapse | reduce_chain).with_config(run_name=\"Map reduce\")\n",
    "\n",
    "answer = map_reduce.invoke(\n",
    "    input=documents,\n",
    "    config={\"max_concurrency\": 5},\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent of the question \"Let's go have some food at Wendy's.\" is ordering food.\n"
     ]
    }
   ],
   "source": [
    "intent_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"A question can have an intent of either Booking a flight, Getting a reservation or ordering food.\n",
    "Now tell me which intent the following question has.\n",
    "                                            \n",
    "Question: {input}\"\"\")\n",
    "\n",
    "intent_chain = intent_prompt | llm\n",
    "answer = intent_chain.invoke({\"input\": \"Let's go have some food at Wendy's.\"})\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordering food\n"
     ]
    }
   ],
   "source": [
    "intent_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"A question can have an intent of either Booking a flight, Getting a reservation or ordering food.\n",
    "Now tell me which intent the following question has. Only answer with two/three words.\n",
    "                                            \n",
    "Question: {input}\"\"\")\n",
    "\n",
    "intent_chain = intent_prompt | llm\n",
    "answer = intent_chain.invoke({\"input\": \"Let's go have some food at Wendy's.\"})\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting a reservation\n"
     ]
    }
   ],
   "source": [
    "intent_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"A question can have an intent of either Booking a flight, Getting a reservation or ordering food.\n",
    "\n",
    "Consider the following examples:\n",
    "\n",
    "Question: Let's go to Tokyo next week.\n",
    "Answer: Booking a flight\n",
    "\n",
    "Question: Get some pizza delivered for this evening.\n",
    "Answer: Ordering food\n",
    "\n",
    "Question: How about a movie at 8pm at the cinema?\n",
    "Anmswer: Getting a reservation\n",
    "\n",
    "Now tell me which intent the follolwing question has. Only answer with two/three words.\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "intent_chain = intent_prompt | llm\n",
    "answer = intent_chain.invoke({\"input\": \"Let's go have some food at Wendy's.\"})\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of now, the content of Frank-Walter Steinmeier's Christmas speech for 2023 is not available. If you need information on this topic, I recommend checking the latest news sources or the official website of the German Federal President closer to or after Christmas 2023 for the most accurate and up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(\"What did Frank-Walter Steinmeier say in his christmas speech 2023?\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In his 2023 Christmas address, Federal President Steinmeier appealed to stand and stay together: \"Let us trust in the strength and experience within us\", he said in the message broadcasted on 25 December. \"As rational, responsible individuals, we can together cope with a world that challenges us.\" 12/25/2023. In his Christmas speech, German President Frank-Walter Steinmeier focused on the need for courage and cooperation in the face of challenges in Germany and around the world. Advertisement. Read the speech online: www.bundespräsident.de Page 1 of 3 Christmas address by Federal President Frank-Walter Steinmeier Schloss Bellevue, 25 December 2023 \"I\\'ve stopped watching the news.\" That sentence is probably the one I have heard most often this year. Again and again, wherever I have been, people have expressed 12/25/2023 December 25, 2023. In his annual Christmas television address to the nation, German President Frank-Walter Steinmeier touched on the many conflicts and crises that dominated the news ... At the same time, Frank-Walter Steinmeier calls for solidarity. Berlin - In his traditional Christmas address, German President Frank-Walter Steinmeier called on the people of Germany not to give up hope for peace and to move closer together as a society. In 2023, too, the world had \"shown its dark side\", Steinmeier said.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.tools.ddg_search import DuckDuckGoSearchRun\n",
    "#from langchain.tools.google_scholar import GoogleScholarQueryRun\n",
    "\n",
    "ddg = DuckDuckGoSearchRun()\n",
    "\n",
    "ddg_tool = Tool.from_function(\n",
    "    func = ddg.run,\n",
    "    name = \"DuckDuckGo Search\",\n",
    "    description = \"Search DuckDuckGo for a query about current events.\",\n",
    ")\n",
    "\n",
    "#gsq= GoogleScholarQueryRun()\n",
    "\n",
    "## en\n",
    "#gsq_tool = Tool.from_function(\n",
    "#    func = gsq.run,\n",
    "#    name = \"GoogleScholarQueryRun Search\",\n",
    "#    description = \"Search GoogleScholarQueryRun for a query about current events.\",\n",
    "#)\n",
    "\n",
    "#Liste von Tools\n",
    "tools = [ddg_tool] #wird erst später verwendet vom Agent\n",
    "\n",
    "ddg_tool.run(\"What did Frank-Walter Steinmeier say in his christmas speech 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m'''\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: DuckDuckGo Search\n",
      "Action Input: Frank-Walter Steinmeier Christmas speech 2023\n",
      "'''\u001b[0m\u001b[36;1m\u001b[1;3mIn his 2023 Christmas address, Federal President Steinmeier appealed to stand and stay together: \"Let us trust in the strength and experience within us\", he said in the message broadcasted on 25 December. \"As rational, responsible individuals, we can together cope with a world that challenges us.\" Read the speech online: www.bundespräsident.de Page 1 of 3 Christmas address by Federal President Frank-Walter Steinmeier Schloss Bellevue, 25 December 2023 \"I've stopped watching the news.\" That sentence is probably the one I have heard most often this year. Again and again, wherever I have been, people have expressed 12/25/2023. In his Christmas speech, German President Frank-Walter Steinmeier focused on the need for courage and cooperation in the face of challenges in Germany and around the world. Advertisement. In seiner Weihnachtsansprache 2023 hat Bundespräsident Steinmeier an das Miteinander appelliert: \"Vertrauen wir der Stärke und der Erfahrung, die in uns steckt\", sagte er in der Ansprache, die am 25. Dezember gesendet wurde. \"Als vernünftige und verantwortungsbewusste Menschen können wir gemeinsam mit einer Welt zurechtkommen, die uns fordert.\" About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy & Safety How YouTube works Test new features NFL Sunday Ticket Press Copyright ...\u001b[0m\u001b[32;1m\u001b[1;3mFinal Thought: Do I need to use a tool? No\n",
      "Final Answer: In his 2023 Christmas speech, German President Frank-Walter Steinmeier emphasized the importance of courage and cooperation in addressing challenges both within Germany and globally. He encouraged people to trust in their own strength and experience, and to work together as rational and responsible individuals to navigate a challenging world.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did Frank-Walter Steinmeier say in his christmas speech 2023?',\n",
       " 'output': 'In his 2023 Christmas speech, German President Frank-Walter Steinmeier emphasized the importance of courage and cooperation in addressing challenges both within Germany and globally. He encouraged people to trust in their own strength and experience, and to work together as rational and responsible individuals to navigate a challenging world.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a great AI-Assistant. You have access to tools to help you answer questions:\n",
    "\n",
    "{tools}\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "'''\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat 3 times)\n",
    "'''\n",
    "\n",
    "When you have a response to say or question to ask to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "'''\n",
    "Final Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response or question here]\n",
    "'''\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "agent = create_react_agent(\n",
    "    tools=tools, llm=llm, prompt=agent_prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, max_iterations=30, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What did Frank-Walter Steinmeier say in his christmas speech 2023?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m'''\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: DuckDuckGo Search\n",
      "Action Input: Frank-Walter Steinmeier Christmas speech 2023\u001b[0m\u001b[36;1m\u001b[1;3mIn his 2023 Christmas address, Federal President Steinmeier appealed to stand and stay together: \"Let us trust in the strength and experience within us\", he said in the message broadcasted on 25 December. \"As rational, responsible individuals, we can together cope with a world that challenges us.\" Read the speech online: www.bundespräsident.de Page 1 of 3 Christmas address by Federal President Frank-Walter Steinmeier Schloss Bellevue, 25 December 2023 \"I've stopped watching the news.\" That sentence is probably the one I have heard most often this year. Again and again, wherever I have been, people have expressed 12/25/2023. In his Christmas speech, German President Frank-Walter Steinmeier focused on the need for courage and cooperation in the face of challenges in Germany and around the world. Advertisement. 12/25/2023 December 25, 2023. In his annual Christmas television address to the nation, German President Frank-Walter Steinmeier touched on the many conflicts and crises that dominated the news ... About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy & Safety How YouTube works Test new features NFL Sunday Ticket Press Copyright ...\u001b[0m\u001b[32;1m\u001b[1;3mFinal Thought: Do I need to use a tool? No\n",
      "Final Answer: Steinmeier emphasized unity, courage, and cooperation in his 2023 speech.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did Frank-Walter Steinmeier say in his christmas speech 2023?',\n",
       " 'output': 'Steinmeier emphasized unity, courage, and cooperation in his 2023 speech.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a great AI-Assistant and only answer in 10 words. You have access to tools to help you answer questions:\n",
    "\n",
    "{tools}\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "'''\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat 3 times)\n",
    "'''\n",
    "\n",
    "When you have a response to say or question to ask to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "'''\n",
    "Final Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response or question here]\n",
    "'''\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")\n",
    "agent = create_react_agent(\n",
    "    tools=tools, llm=llm, prompt=new_agent_prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, max_iterations=30, verbose=True)\n",
    "\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What did Frank-Walter Steinmeier say in his christmas speech 2023?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: DuckDuckGo Search\n",
      "Action Input: \"Frank-Walter Steinmeier Christmas speech 2023 transcript\"\u001b[0m\u001b[36;1m\u001b[1;3mIn his 2023 Christmas address, Federal President Steinmeier appealed to stand and stay together: \"Let us trust in the strength and experience within us\", he said in the message broadcasted on 25 December. \"As rational, responsible individuals, we can together cope with a world that challenges us.\" Read the speech online: www.bundespräsident.de Page 1 of 3 Christmas address by Federal President Frank-Walter Steinmeier Schloss Bellevue, 25 December 2023 \"I've stopped watching the news.\" That sentence is probably the one I have heard most often this year. Again and again, wherever I have been, people have expressed In seiner Weihnachtsansprache 2023 hat Bundespräsident Steinmeier an das Miteinander appelliert: \"Vertrauen wir der Stärke und der Erfahrung, die in uns steckt\", sagte er in der Ansprache, die am 25. Dezember gesendet wurde. \"Als vernünftige und verantwortungsbewusste Menschen können wir gemeinsam mit einer Welt zurechtkommen, die uns fordert.\" 12/25/2023. In his Christmas speech, German President Frank-Walter Steinmeier focused on the need for courage and cooperation in the face of challenges in Germany and around the world. Advertisement. 12/25/2023 December 25, 2023. In his annual Christmas television address to the nation, German President Frank-Walter Steinmeier touched on the many conflicts and crises that dominated the news ...\u001b[0m\u001b[32;1m\u001b[1;3mAction: Funky Summary Tool\n",
      "Action Input: In his 2023 Christmas address, Federal President Frank-Walter Steinmeier appealed to stand and stay together: \"Let us trust in the strength and experience within us\", he said in the message broadcasted on 25 December. \"As rational, responsible individuals, we can together cope with a world that challenges us.\"\n",
      "\n",
      "In his Christmas speech, German President Frank-Walter Steinmeier focused on the need for courage and cooperation in the face of challenges in Germany and around the world. He acknowledged the many conflicts and crises that dominated the news throughout the year and urged people to stop fixating on the negatives. Instead, he encouraged them to believe in their inner strength and collective experience to navigate through tough times.\n",
      "\n",
      "Steinmeier also highlighted the importance of unity and working together to overcome global challenges. He stressed that by being rational and responsible, individuals can collectively face and manage the world's demands. The speech was a call for solidarity and mutual support during trying times.\u001b[0m\u001b[33;1m\u001b[1;3mcontent='Alright kiddo, here\\'s the scoop! Imagine you and your friends are on a big adventure and things are getting a bit tricky. The big boss, President Frank-Walter Steinmeier, gave a super-duper Christmas pep talk. He said, \"Hey team, let\\'s stick together and be brave!\"\\n\\nHe knows there\\'s a lot of yucky stuff happening around, but he wants everyone to stop worrying so much. Instead, he wants us to remember that we have lots of smarts and strength inside us. If we work together, we can handle anything!\\n\\nSo, his message was all about teamwork, being responsible, and staying strong together, even when things get tough. High five to that! 🎄✨👊' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 228, 'total_tokens': 373, 'completion_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_80a1bad4c7', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-91309811-d47e-4e0b-8c35-599a31493b3f-0' usage_metadata={'input_tokens': 228, 'output_tokens': 145, 'total_tokens': 373}\u001b[0m\u001b[32;1m\u001b[1;3mFinal Thought: Do I need to use a tool? No\n",
      "Final Answer: Alright kiddo, here's the scoop! Imagine you and your friends are on a big adventure and things are getting a bit tricky. The big boss, President Frank-Walter Steinmeier, gave a super-duper Christmas pep talk. He said, \"Hey team, let's stick together and be brave!\"\n",
      "\n",
      "He knows there's a lot of yucky stuff happening around, but he wants everyone to stop worrying so much. Instead, he wants us to remember that we have lots of smarts and strength inside us. If we work together, we can handle anything!\n",
      "\n",
      "So, his message was all about teamwork, being responsible, and staying strong together, even when things get tough. High five to that! 🎄✨👊\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Funky summarize the christmas speech 2023 of Frank-Walter Steinmeier?',\n",
       " 'output': 'Alright kiddo, here\\'s the scoop! Imagine you and your friends are on a big adventure and things are getting a bit tricky. The big boss, President Frank-Walter Steinmeier, gave a super-duper Christmas pep talk. He said, \"Hey team, let\\'s stick together and be brave!\"\\n\\nHe knows there\\'s a lot of yucky stuff happening around, but he wants everyone to stop worrying so much. Instead, he wants us to remember that we have lots of smarts and strength inside us. If we work together, we can handle anything!\\n\\nSo, his message was all about teamwork, being responsible, and staying strong together, even when things get tough. High five to that! 🎄✨👊'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "simple_summary_prompt = ChatPromptTemplate.from_template(\"\"\"Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old would understand. Keep it funky!\n",
    "\n",
    "Text: {input}\"\"\")\n",
    "simple_summary_chain = {\"input\": RunnablePassthrough()} | simple_summary_prompt | llm\n",
    "\n",
    "summary_tool = Tool(\n",
    "    name=\"Funky Summary Tool\",\n",
    "    func=simple_summary_chain.invoke,\n",
    "    description=\"Use this tool to do a funky summary. Make sure you get the text to do a summary of first.\"\n",
    ")\n",
    "tools.append(summary_tool)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    tools=tools, llm=llm, prompt=agent_prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, max_iterations=30, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Funky summarize the christmas speech 2023 of Frank-Walter Steinmeier?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 + 1234 equals 2234.\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(\"What is 1000 + 1234?\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate \\( 13^{0.3432} \\), you can use a calculator with an exponentiation function or a scientific calculator. Here's the calculation:\n",
      "\n",
      "\\[ 13^{0.3432} \\approx 2.450 \\]\n",
      "\n",
      "So, \\( 13 \\) raised to the power of \\( 0.3432 \\) is approximately \\( 2.450 \\).\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(\"What is 13 raised to the .3432 power?\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a futuristic smart home system setup by \"Tech Invoaters.\" It showcases a high-tech living room where a person is seated on a couch, interacting with various smart devices. The room is filled with interconnected gadgets, screens, and control panels, illustrating a comprehensive smart home ecosystem. There are large digital displays on the walls showing home automation interfaces, security systems, and other smart home functionalities. The environment is sleek and modern, emphasizing the integration of technology into everyday home life. The image also includes a list of tools and components associated with the smart home system.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    # Default to png\n",
    "    if mime_type is None:\n",
    "        mime_type = 'image/png'\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "\n",
    "\n",
    "prompt_template =  HumanMessagePromptTemplate.from_template(\n",
    "            template=[\n",
    "                {\"type\": \"text\", \"text\": \"Summarize this image\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"{encoded_image_url}\",\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "summarize_image_prompt = ChatPromptTemplate.from_messages([prompt_template])\n",
    "\n",
    "gpt4_image_chain = summarize_image_prompt | llm \n",
    "\n",
    "img_file = \"Images/UserGuide.jpg\"\n",
    "page3_encoded = local_image_to_data_url(img_file)\n",
    "\n",
    "answer = gpt4_image_chain.invoke(input={\"encoded_image_url\":page3_encoded})\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Mitbürgerinnen und liebe Mitbürger, wenn ich im Land unterwegs bin, sagen mir gerade auch viele Ältere, so geballt, so Schlag auf Schlag habe ich das alles noch niemals erlebt. Kaum war Corona halbwegs vorbei, brach Russland mitten in Europa einen unerbittlichen Krieg vom Zaun. Kurz darauf dreht uns der russische Präsident den Gasthahn ab. Und im Herbst gab es auch noch den brutalen Terrorangriff der Hamas auf Israel. So viel Leid, so viel Blut vergießen. Unsere Welt ist unruhiger und rauer geworden. Sie verändert sich in geradezu atemberaubender Geschwindigkeit. Auch wir müssen uns deshalb verändern. Vielen von uns bereitet das Sorgen. Bei einigen sorgt das auch für Unzufriedenheit. Ich nehme mir das zu Herzen. Und zugleich weiß ich, wir in Deutschland kommen da durch. Erinnern Sie sich, wo wir vor einem Jahr standen. Drei, vier, fünf Prozent Wirtschaftseinbruch hatten uns viele Expertinnen und Experten vorausgesagt. Viele befürchteten, die Preise würden immer weiter steigen. Es gab die Sorge vor Stromausfällen und kalten Wohnungen. Es ist anders gekommen. Die Inflation ist gesunken, Löhne und Renten steigen. Die Gasspeicher sind für diesen Winter randvoll. Es ist anders gekommen, weil wir uns gegen den Wirtschaftseinbruch gestemmt haben. Weil wir Energie gespart und rechtzeitig vorgesorgt haben. Wir alle, gemeinsam. Wir kommen auch mit Gegenwind zurecht. Das macht die Herausforderung unserer Zeit nicht kleiner. Aber das gibt Mut, dass wir ihnen gewachsen sind. Wer, wenn nicht ihr, in Deutschland kriegt das hin. Das sagen mir viele um uns herum in Europa und auf der Welt. Und da ist etwas dran. Noch nie hatten so viele Frauen und Männer in Deutschland eine Arbeitsstelle wie heute. Das sichert unseren Wohlstand. Das gibt uns die Möglichkeit, kraftvoll in die Zukunft zu investieren. Und das müssen wir auch. Denn wer in diesen Tagen mit der Bahn unterwegs ist oder vor einer maroden Brücke im Stau steht, der merkt, unser Land wurde zu lange auf Verschleiß gefahren. Deshalb investieren wir jetzt in ordentliche Straßen und eine bessere Bahn. In eine saubere Energieversorgung und einen besseren Klimaschutz. In gute Arbeitsplätze. Und zwar in Wirtschaftszweigen, in denen Deutschland schon immer Weltspitze war. Genauso wie in Branchen, wo wir Nachholbedarf haben. Z.B. bei der Herstellung von Computerchips oder Batterien. All das ist vor dem Hintergrund des weitreichenden Urteils des Bundesverfassungsgerichts von Mitte November nicht einfacher geworden. Nicht alle Vorhaben, die wir in den Blick genommen hatten, werden wir umsetzen können. Wir investieren auch im kommenden Jahr eine Rekordsumme in unsere Zukunft. Und unterm Strich entlasten wir auch weiterhin all diejenigen, die jeden Tag aufstehen und zur Arbeit gehen. Die unser Land am Laufen halten. Von morgen an zahlen Arbeitnehmerinnen und Arbeitnehmer in Deutschland 15 Mrd. Euro weniger an Steuern. Eine vierköpfige Familie mit einem normalen Einkommen hat dadurch im nächsten Jahr mehr als 500 Euro zusätzlich zur Verfügung. Zusammen mit der Steuersenkung in diesem Jahr macht das über 1.600 Euro mehr. Dazu kommen das höhere Kindergeld, das Wohngeld und nicht zuletzt die Senkung der Beiträge zur Sozialversicherung für all diejenigen, die wenig verdienen. Die Pakete ausfahren oder Supermarktregale einräumen. Die vorherigen Kinder zur Schule bringen und noch nach der Arbeit den Haushalt schmeißen. Über sie liest man nicht jeden Tag in der Zeitung. Aber mir ist es wichtig, dass ihre Leistung gesehen und anerkannt wird. Liebe Mitbürgerinnen und Mitbürger, auch in Zeiten wie diesen gibt es Dinge, auf die wir uns verlassen können. Wir uns stark machen. Wir haben Freunde in Europa und rund um den Globus. Partner, mit denen ich mich Tag für Tag darüber abstimme, wie wir unsere Sicherheit in Deutschland und Europa gewährleisten. Stark macht uns die Europäische Union. Wenn die EU geschlossen auftritt, dann handelt sie für mehr als 400 Mio. Bürgerinnen und Bürger. In einer Welt mit 8, künftig sogar 10 Mrd. Menschen ist das ein echtes Pfund. Darum ist es so wichtig, dass Europa geeint und gestärkt aus der Europawahl im kommenden Jahr hervorgeht. Denn Russlands Krieg im Osten unseres Kontinents ist ja nicht vorbei. Die kriegerische Auseinandersetzung im Nahen Osten auch nicht. Und in den USA stehen im kommenden Jahr Präsidentschaftswahlen an, möglicherweise mit weitreichenden Konsequenzen, auch für uns hier in Europa. Kurz vor Weihnachten haben wir uns in der Europäischen Union nach 7 Jahren des Stillstands auf eine tiefgreifende Reform des europäischen Asylsystems geeinigt. Künftig können wir die Außengrenzen Europas besser kontrollieren. Und auch an den Grenzen zu unseren Nachbarländern hat die Bundespolizei ihre Kontrollen verstärkt. Das wirkt. Schon in den vergangenen Wochen ist die Zahl derer, die über diese Grenzen kommen, spürbar gesunken. Stark macht uns auch unsere Demokratie. Es ist noch gar nicht allzu lange her, da haben mutige Frauen und Männer auch hier in Deutschland für freie Wahlen gekämpft. Vor 35 Jahren war das, als in der DDR die friedliche Revolution begann. Mitzureden und mitzuentscheiden, das ist ein kostbares Gut. Diskussionen über den richtigen Weg gehören dazu. Das Ringen um faire Kompromisse ebenfalls. Auch wenn ich auf manche laute Debatte in den vergangenen Wochen und Monaten durchaus hätte verzichten können. Zur Wahrheit gehört aber auch, ganz ohne Diskussionen über den richtigen Weg funktioniert Demokratie nicht. Nichts wird besser, wenn wir nur übereinander reden, anstatt miteinander. Stark macht uns unsere Bereitschaft zum Kompromiss und unser Einsatz füreinander. So wie in den Teilen Deutschlands, die in diesen Tagen unter dem schrecklichen Hochwasser und seinen Folgen leiden. Ich denke an alle Betroffenen, denen wir selbstverständlich helfen und die wir in diesen schweren Stunden nicht alleine lassen. Und ich danke all den Frauen und Männern von der Feuerwehr und Bundeswehr, vom THW, den Rettungsdiensten und den vielen freiwilligen Helferinnen und Helfern, die mit ganzer Kraft gegen das Hochwasser kämpfen. Herzlichen Dank an sie alle für ihren Einsatz. Liebe Mitbürgerinnen und Mitbürger, uns macht auch die Einsicht stark, dass jede und jeder gebraucht wird in unserem Land. Die Spitzenforscherin genauso wie der Altenpfleger, die Polizistin genauso wie der Paketbote, die Rentnerin genauso wie der junge Auszubildende. Wenn wir uns das klar machen, wenn wir uns gegenseitig mit diesem Respekt begegnen, dann brauchen wir keine Angst zu haben vor der Zukunft. Dann kann das Jahr 2024 ein gutes Jahr werden für unser Land. Auch wenn manches anders kommt, als wir uns das heute am Vorabend dieses neuen Jahres vorstellen. Ihnen und Ihren Liebsten wünsche ich von ganzem Herzen ein gesundes, ein friedvolles und ein frohes neues Jahr.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    api_key=azure_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    azure_deployment=azure_whisper,\n",
    "    api_version=azure_version,\n",
    ")\n",
    "\n",
    "def get_transcript(audio_file):\n",
    "    if not os.path.exists(audio_file):\n",
    "        audio_file = \"./Audio/\" + audio_file\n",
    "    client.audio.with_raw_response\n",
    "    return client.audio.transcriptions.create(\n",
    "        file=open(audio_file, \"rb\"),            \n",
    "        model=\"whisper\",\n",
    "        language=\"de\",\n",
    "    ).text\n",
    "\n",
    "audio_test_file = \"./Audio/newyear2023.mp3\"\n",
    "print(get_transcript(audio_test_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey kiddo, so this is like a big speech where a grown-up tells everyone in their country about the tough times they’ve been through. They talk about how there were some really hard things like a big sickness, a war, and some scary attacks. But even though things were tough, they all worked together to save energy and keep working. Because of that, things got a little better.\n",
      "\n",
      "They also say that lots of people have jobs now, and that helps everyone have a good life. They’re planning to fix roads and trains, make cleaner energy, and create good jobs. They want to make sure everyone, even those who don’t earn a lot of money, get some help too.\n",
      "\n",
      "The grown-up also talks about how important it is to have friends in other countries and to stick together, especially in Europe. They remind everyone how important it is to talk and work together to make good decisions. They thank all the helpers like firefighters and police who do a lot to keep everyone safe.\n",
      "\n",
      "In the end, they say that everyone in the country is important, from scientists to delivery people, and if they all respect and help each other, the next year can be really good. They wish everyone a happy and peaceful new year.\n"
     ]
    }
   ],
   "source": [
    "# audio\n",
    "def get_audio_doc(input):\n",
    "    return {\n",
    "        \"context\": [Document(\n",
    "            page_content=get_transcript(input),\n",
    "            metadata={\n",
    "                \"source\": \"audio\"\n",
    "            }\n",
    "        )]\n",
    "    }\n",
    "audio_summary_chain = get_audio_doc | summary_chain\n",
    "answer = audio_summary_chain.invoke(\"./Audio/newyear2023.mp3\")\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
